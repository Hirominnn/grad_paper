\chapter{実験}
\label{chap:result}
\fancyhf{}
\rhead{\thepage}
\lhead{第\ref{chap:result}章　実験}
\cfoot{\thepage}


本章では，実験について述べる．

まず，本研究の要である，問題を入力として知識分類を抽出するためのDeep Knowledge Tracingの拡張法と最適化について述べたのち，
次に，実験設定について述べ，
その後，実験結果について述べる．

実験結果においては，
まず，２つのデータセットいずれにおいても，
提案手法である，深層学習によって抽出された知識分類を利用した場合のほうが，
既存の知識分類を利用した場合よりも，高い精度で知識獲得を予測できることを示し，
深層学習によって知識獲得過程をより適切に表現する知識分類が抽出できていることを，定量的に確認する．

さらに，抽出された知識分類を既存の知識分類と比較することにより，
抽出された知識分類の性質を定性的に確認する．
結果としてxxxな性質を持つ知識分類が抽出されていることを示す．
% ２つのデータセットいずれにおいても，離散化する前のモデルでは精度良くて，assistmentsだけ離散化しても勝てた？


\section{Deep Knowledge Tracingの拡張および最適化}
本研究に適用するために，Deep Knowledge Tracingの拡張法を述べたのち，最適化について述べる．
% 最適化についてどこで述べるか？別の説でいいかも．or最適化を５番にする？

DKTの拡張法については，以下のｘつの観点から説明する．
1)同時回答ログの処理
2)タグ空間への写像
3)問題空間とタグ空間の符号化・復号化の整合性確保
4)離散化


\subsection{同時回答ログの処理方法}
既存のDKTの手法においては，同時に１つの問題ないしはスキルに関する回答ログしか発生されないとされているが，
本論文で用いるデータセットは，一つの問題に対し，一つないしは複数の知識分類が事前に紐付けられている．
そのため，同時に複数の回答ログを処理できるように，DKTを拡張する必要がある．

Knowledge Tracingは
生徒の時刻$t$において観測された問題回答結果を$q_{t}$とすれば，
$q_1, q_2, \dots, q_t$から時刻$t+1$において観測される問題回答結果$q_{t+1}$を予測するタスクであった．

同時に複数の問題について回答ログが生じることを許容する場合， 
Knowledge Tracingのタスクは
学習者の時刻$t$において観測された問題回答結果ベクトルを${\bf q}_{t}$とすれば，
${\bf q}_1, {\bf q}_2, \dots, {\bf q}_t$から時刻$t+1$において観測される問題回答結果ベクトル${\bf q}_{t+1}$を予測するというものである．

Deep Knowledge TracingではRNNへの入力はone-hotベクトルに符号化され，入力ベクトルを${\bf x}_t$，
演習問題の数を$M$とすれば，${\bf x}_t$の長さは$2M$であった．
同時に複数の問題が回答されるという設定では，
その同時に回答された問題数を$m_t$とすれば$m_t$-hotベクトルに符号化することで，
\cite{piech2015deep}に近い形でRNNに情報を入力できる．

\begin{table}[ht]
\caption{拡張したDeep Knowledge Tracingにおける回答ログデータと対応する入力ベクトルの例}
\label{tab:samplelog_mod}
\begin{center}
\centerline{
{
\begin{tabular}{crrr|cc}\hline\hline
	\multicolumn{4}{c|}{回答ログ}	&	\multicolumn{2}{c}{入力ベクトル}	\\
	ユーザID	&	ログの順番	&	問題番号	&	正誤	&	変数名			&	値											\\\hline
	A			&	1			&	1			&	1		&	\multirow{2}{*}{${\bf x}_1$}		&	\multirow{2}{*}{$[1 0 0 0 \vdots 0 1 0 0 ]$}	\\
	A			&	1			&	2			&	0		&					   	 	&												\\\hdashline
	A			&	2			&	1			&	1		&	\multirow{2}{*}{${\bf x}_2$}		&	\multirow{2}{*}{$[1 1 0 0 \vdots 0 0 0 0 ]$}	\\
	A			&	2			&	2			&	1		&					   	 	&												\\\hdashline
	A			&	3			&	3			&	0		&	${\bf x}_3$					&	$[0 0 0 0 \vdots 0 0 1 0 ]$			\\\hdashline
	A			&	4			&	3			&	0		&	\multirow{2}{*}{${\bf x}_4$}	&	\multirow{2}{*}{$[0 0 0 1 \vdots 0 0 1 0 ]$}											\\
	A			&	4			&	4			&	1		&							&												\\
\hline\hline
\end{tabular}
}
}
\end{center}
\end{table}

具体例を交えて説明する．
例えば，演習問題の数が4つと仮定する ．$M=4$であり，${\bf x}_t$の長さは$8$である．
ある学習者が，表\ref{tab:samplelog_mod}の回答ログのように問題を回答し正誤が観測されたとすれば，
入力ベクトル${\bf x}_t$は表\ref{tab:samplelog_mod}の入力ベクトルのように符号化される．

出力${\bf y}_t$はDeep Knowledge Tracingと全く同じであり，
問題と同じ長さのベクトルで，
それぞれの要素が当該学習者がそれぞれの問題に正しく回答する確率の予測値となっている．
したがって，$t+1$の回答${\bf q}_{t+1}$の正誤予測は$t+1$に回答される問題${\bf q}_{t+1}$に対応する${\bf y}_t$の要素から読み取れる．



\subsection{問題空間とタグ空間の符号化・復号化}
本研究では，タグに関する回答を入力とする既存のDKTと異なり，
問題に関する回答を入力として，タグを抽出しながら学習をすすめるため，
問題空間の入力をタグ空間へ写像する関数を学習する必要がある．

まず，問題数をMとした場合，モデルへの入力ベクトルの長さは２Mである．
ここで，抽出目的のタグの次元数を事前にNとした場合，写像後のタグ空間のベクトルの長さは２Nとなる．
これは，M次元の問題空間からN次元のタグ空間へ写像する関数を，以下の式により定義し，
その関数を，入力ベクトルの前半である正答部分と，後半である誤答部分にそれぞれ適用することで，
タグ空間におけるN次元の正答ベクトルとN次元の誤答ベクトルを合わせたことにより，長さ２Nのベクトルが生成される．
（式書く）
ここで，WxuはMxNの大きさの重み行列であり，buは長さNのバイアス項である．
% 一般的なembeddingとして書く？
% 同じ重みを使う理由or decodeは違っても良い理由書く　


こうして得られたタグ空間ベクトルは，
一般的なRNN同様，隠れ層を経由して時系列情報を反映した後，再び２N次元のタグ空間ベクトルに戻る．
このタグ空間ベクトルは，時刻ｔまでの回答情報を反映した，生徒のタグ空間における知識状態を表していると言える．

このタグ空間ベクトルから，予測結果としてN次元の問題回答予測ベクトルを算出する．
このベクトルは０から１の間の値を取り，次の時刻における各問題に正答する確率を表しており，
既存のDKTと同じ予測表現となっている．
% 他にもactivationとかどこに書く？



\subsection{最適化}
既存のDKTにおける最適化手法は，
次の時刻の問題回答予測ベクトルと，実際の次の時刻の問題回答ベクトルの誤差を最小化するものである．
\begin{eqnarray}
	\log(p_1 \times p_2 \times \dots \times p_{m_t}) = \sum_{k}^{m_t} \log(p_k)
\end{eqnarray}
であるため，
${\bf\tilde{ \delta}}({\bf q}_{t+1})$を時刻$t+1$にどの問題が回答されたかの$m_t$-hotベクトルとし，
${\bf a}_{t+1}$を時刻$t+1$に対応する問題で正答したか否か（$1$か$0$）のベクトルとすれば，
誤差関数は
\begin{eqnarray}
L &=& \sum_t l({\bf y}_t^T {\bf \tilde{\delta}}({\bf q}_{t+1}), {\bf a}_{t+1})
\end{eqnarray}
である．
この誤差関数を，問題回答予測に関する誤差関数とする．
% 交差エントロピーの解説？


本研究では，この問題回答予測に関する誤差関数に加え，
問題空間とタグ空間の符号化・復号化の整合性を担保するため，
Reconstruction Errorと呼ばれる誤差関数も導入する．
これは，一般的にはモデルに良い初期値を与えるための事前学習のためのオートエンコーダに用いられる誤差関数であり，
以下の式で表される．
（式）
% オートエンコーダのこと先行研究で書く
本研究では，このオートエンコーダの構造を，事前学習ではなく，RNNと同時に学習させるモデル構造になっている．
オートエンコーダの構造を，事前学習ではなく同時学習において適用することは，
必ずしも精度向上につながるわけではないため，一般的なRNNには利用されない．
本研究では，純粋な入力の低次元へのembeddingではなく，問題の正答率とタグ空間の知識状態は相互に変換できるものであるはずだという，
教育学的な知識分類の性質を考慮して，Reconstruction Errorを誤差関数に導入している．
この誤差関数を導入することにより，教育学的な整合性が確保されるだけでなく，
知識獲得の予測精度も向上することを確認した．詳細については結果で述べる．

結果的に，モデル全体の誤差関数は以下の式によって定められ，
この誤差関数を最小化するようにモデルが学習される．
(式)



学習時は\cite{piech2015deep}と同様にミニバッチごとに確率的勾配降下法で目的関数を最小化する．



\subsection{離散化}
% chapter3とどう合わせるか？
学習後のモデルからは，
知識獲得の過程を最もよく説明するような，
問題空間からタグ空間への写像関数が抽出できる．

この関数は，M個の問題の，N個のタグそれぞれへの関連性の強さが表現されていると言える．
この写像行列は連続値表現であり，そのままでは，既存の離散的な知識分類表現との比較ができない．
よって，離散表現に改める必要がある．
この離散化の手法としては，
各問題に対して最も関係性の強い知識分類のみを１とし，その他を０にする方法が，
最も高い精度で知識獲得を予測できることを確認したため
この手法に基づいて問題と知識分類の関係行列を離散化し，
抽出された知識分類を既存の知識分類と比較する．



以上，Deep Knowledge Tracingの拡張およびその最適化について述べた．
次に，実験設定について述べる．




\section{実験設定}

ここでは，知識獲得の予測の実験設定について述べる．

まず，２つのデータセットいずれにおいても，
訓練：検証：テスト = 8：1：1となるようにユーザを分け，
訓練ユーザのデータでモデルを構築し，
検証ユーザのデータでハイパーパラメタを調整し， 
検証ユーザのデータで精度が最も高かったモデルを
テストユーザのデータに適用し当該モデルの最終的な精度とする．


ハイパーパラメタについては，
%対象データが多いため学習コストの削減を狙いRNNの部分にはGRNNを用いる．
学習率の初期値を$200$，
モーメントを$0.98$，
1エポックごとに，
減衰率$0.99$として学習率を最小学習率$10$まで減衰させる．
また，勾配のノルムの最大値を$0.00001$として\cite{pascanu2013difficulty}に従い勾配に制約を設けた．
dropoutは\cite{piech2015deep}と同様に${\bf y}_t$の方向にのみかけ，
dropout率は$0.5$とした．
隠れ層のユニット数は$400$として，
各重み行列の初期化は\cite{glorot2010understanding}にしたがった．
時系列方向の誤差逆伝搬は最長で$200$まで伝搬するように制約を設けた．

これらのハイパーパラメタは実験的に高い予測性能を発揮したため設定しており，
網羅的に探索したわけではない．
通常，深層学習の手法はハイパーパラメタの数が非常に大きく，また，
計算コストが大きいため大規模な探索は行えない．
Grid SearchやRandom Search\cite{bergstra2012random}といった探索手法が提案されているが，
専門家が手で調整した方が優れていることが報告されている\cite{larochelle2007empirical, bergstra2012random}．


実装には
Theanoを用いた\cite{bergstra+al:2010-scipy,Bastien-Theano-2012}．
Theanoは多次元行列を含む数学的表現の定義や計算，最適化を効率的に行えるPythonのライブラリで，
深層学習の研究ではよく利用される．



以上，実験設定について述べた．
次に，実験結果について述べる．



\section{結果}
実験結果について述べる．
まず，２つのデータセットいずれにおいても，
提案手法である，深層学習によって抽出された知識分類を利用した場合のほうが，
既存の知識分類を利用した場合よりも，高い精度で知識獲得を予測できることを示し，
深層学習によって知識獲得過程をより適切に表現する知識分類が抽出できていることを，定量的に確認する．

さらに，抽出された知識分類を既存の知識分類と比較することにより，
抽出された知識分類の性質を定性的に確認する．
結果としてxxxな性質を持つ知識分類が抽出されていることを示す．



% 提案手法として，単純なエンベディングとオートエンコーディングの比較も含める
\subsection{各データセットにおける予測性能}
\begin{table}[!htb]
\caption{各データセットに対する各手法の予測性能}
\label{tab:result1}
\begin{center}
\centerline{
{
\begin{tabular}{crrrr|rrr}
\hline

\multicolumn{5}{c|}{データセット} 							&	\multicolumn{3}{c}{AUC}\\

 
 & 生徒数 & 問題数 & タグ数 & ログ数 							&	 Marginal & DKT & 提案手法\\\hline

ASSISTments 2009-2010 & 2000 & 967 & 31 & 60000				&	 0.66 & 0.81 & {\bf 0.86}\\\hline

bridge to algebra 2006-2007 & 1000 & 3000 & 200 & 600000	&	 0.71 & 0.81 & {\bf 0.85}\\

\hline
\end{tabular}
}
}
\end{center}
\end{table}



一般的なDeep Knowledge Tracing（以下，既存手法）と本研究で適用したDKTの拡張モデル（以下，提案手法）を各データセットに適用した結果を表\ref{tab:result1}に示す．
Marginalは各問題についてそれぞれ正解の周辺確率を予測結果とするものである．
\cite{piech2015deep}にも記載されていたため，本稿でも同様にベースラインとして記載した．
また，
値が大きい箇所は太字で記載した．


２つのデータセットいずれにおいても，
提案手法を用いた場合の方が，既存手法を用いた場合より高いAUCを記録した．
% どっかでAUC説明する？

%提案手法である，深層学習によって抽出された知識分類を利用した場合のほうが，
%既存の知識分類を利用した場合よりも，高い精度で知識獲得を予測できることを示し，
%深層学習によって知識獲得過程をより適切に表現する知識分類が抽出できていることを，定量的に確認する．





\subsection{抽出した知識分類の分析}
抽出された知識分類を既存の知識分類と比較することにより，
抽出された知識分類の性質を定性的に確認する．
xxx





\vvspace
以上，実験について述べた．
次章では，考察について述べる．



