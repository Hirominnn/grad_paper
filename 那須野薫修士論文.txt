平成２７年度 修士論文
深層学習を用いた MOOCs の学習者の知識構造の分析
平成２８年３月 指導教員 松尾豊 特任准教授 東京大学大学院工学系研究科技術経営戦略学専攻
37-146856  那須野薫

概要
伝統的に，知識は学習や指導の設計において重要な役割を担っており，心理学 では知識について多角的に議論が行われていた．知識の属性や性質から知識を比 較する研究や，学習者の知識の獲得や活用の仕組みを説明する研究，また，それ らを基に効率的な知識獲得の方法を開発する研究，など幅広い．
知識の属性や性質という点では，一般知識と領域知識，宣言的知識と手続き的 知識，具体的知識と抽象的知識，暗黙知，メタ知識など，さまざまな属性や性質， あるいはその対比を切り口に議論が行われてきたが，このなかでも，宣言的知識と 手続き的知識を対比し知識を議論する研究は多い．宣言的知識は内容や概念を表 現する知識であり，knowing that という言葉でも表現され，対象（A）がどう（B） であるかに関する知識である．例えば，「東京は日本の首都である」という知識が 該当し，この場合，A が東京であり，B が日本の首都である．一方で，手続き的知 識は，手続きを表現する知識であり，knowing how という言葉でも表現され，タス クをどう達成するかに関する知識である．特に，数学やプログラミングを対象に 議論されることが多い．例えば，「1 次方程式 ax + b = 0 を解く」ための知識が該 当し，この場合，b を移行し a で両辺を割るという手続きにより問題を解くことが できる．知識を宣言的知識と手続き的知識に分けて議論することで，人間の知識 の獲得や活用を内容と内容を基にした手続きでよく記述できる．
特に，学習者の知識獲得の点でも，宣言的知識と手続き的知識を対比的に扱い説 明する研究は多い．宣言的知識は，学習者が保有する知識に結合する形で獲得さ れるため，獲得対象の知識に既に獲得しているものが含まれている方が獲得され やすいといわれている．例えば，「東京は日本の首都である」という知識であれば， 東京，首都，日本のうち，より多くについて既知であるほど獲得しやすく，逆に， 「地球は丸い」という知識が獲得していたとしても必ずしも獲得しやすいわけでは ない，ということである．一方で，手続き的知識は，タスクが複数の細かいサブ
2

タスクに分解されるため，学習者が分解後の全てのサブタスクを達成するための 知識を保有している場合に獲得されるといわれている．「1 次方程式 ax + b = 0 を 解く」ための知識は，「項を移行する」ための知識と「両辺を定数で割る」ための 知識に分解され，さらに，「ある定数を引く」ための知識や「ある定数で割る」た めの知識に分解され，というように階層的に分解された知識を全て保有している 場合に，はじめて「1 次方程式 ax + b = 0 を解く」ための知識を獲得していると いえる，ということである．宣言的知識と手続き的知識はその獲得のされやすさ が学習者が既に獲得している知識に依るところは共通するが，宣言的知識は関連 の強い知識間で局所的にその獲得に影響を与え合い，一方で，手続き的知識は分 解された知識がその掛け合わせで構成される知識の獲得に影響を与えるため，知 識獲得における知識構造は，手続き的知識のものは宣言的知識のものと比べると， 階層的になると考えられていた．
心理学の領域で，この考えを支持する研究報告は少なくない．領域知識をよく 分析し階層的に知識間関係を構築し，階層構造上より水準の高い知識に着手する 前に，予め獲得するべき知識が確実に獲得されるように学習体験を構造化するこ とで，習熟学習を効率化できるという仮説に基づいて，数学やプログラミングの 習熟の効率化を狙った研究が報告された．こうした研究は，当初の期待よりは効 果が低かったものの，よく分析し階層的に構造化した知識間関係に基づいて学習 を設計することで学習を効率化できることを実験で示し，知識獲得における対象 科目の知識構造が階層的であることを示唆するというものであった．
しかし，実験より示唆する研究報告はあるものの，宣言的知識と手続き的知識 の対比において，知識獲得における知識構造を定量的に比較し分析した研究はま だない．これは，こうした心理学の研究が行われていたのが 20 年以上も前で，当 時は，定量評価を実施できる学習者の知識獲得に関するデータの収集が困難であ り，知識獲得に関するデータから知識獲得における知識構造を抽出することも難 しく，また，抽出した知識構造を分析する方法もなかったからだと推察される．
さて，こうした知識間関係のように対象間の関係を明らかにしようとする分析 として，ネットワーク分析というものがある．ネットワーク分析はウェブやそれ ソーシャルメディアの普及に伴い注目が高まり，ウェブページ間の関係や人と人の 関係を分析するためにしばしば用いられている．ネットワーク分析は対象をノー
3

ド，対象間の関係をエッジとするグラフを構築し，その構造から関係を評価しよ うというものである．ネットワークの構造を捉えるための指標や手法が開発され ており，例えば，ネットワークのモジュール性を評価するモジュラリティという指 標や階層性を評価するフロー階層や GRC という指標等，多くの指標がある．
また，学習や教育に関する領域では，近年，Massive Open Online Courses（以 下，MOOCs）が注目を集めている．MOOCs は，従来の教室で時間割通りに一斉 授業形式で提供される学習機会とは異なり，数多くの多様な講座のオンライン上 での提供を通じて，いつでもどこでも自分のペースでさまざまな講座から自分の 学習したいものを選択し学習できるというこれまでにない学習機会を提供してお り，多くの学習者が利用している．
MOOCs は単にこれまでにない学習機会を提供しているというだけでなく，これ まで難しかった大規模な学習効果分析の可能性も高めている．学習者はオンライ ン上で提供された講義動画や演習問題を通して学習するが，オンライン上で実施 されているため学習行動ログをデータとして蓄積でき，さらに，そのデータを分 析に活用できる．また，多くの多様な学習者が利用するため，多様な学習者の大 規模な学習行動ログから多様な講座の学習効果の分析が可能となりつつある．特 に，演習問題の回答ログはその演習問題により評価される知識を学習者が獲得し ているか否かを表現しているため，知識獲得の分析に利用できる．
また，ここ数年，特に学習や教育に関する領域に限らず，多くの研究領域で深 層学習が注目されている．深層学習は多層のニューラルネットワークによる機械 学習のことで，従来の機械学習では難しかった対象データの表現抽出を最適化の 過程で行うことができる．深層学習の活用により画像認識，機械翻訳，質問応答 文生成，音声認識等さまざまな研究領域で飛躍的な進展が報告がされている．
特に，学習者の知識獲得を予測する研究も，深層学習により大きく進展してい る．2015 年に，数学における知識獲得の予測に深層学習を活用し，高い精度で知 識獲得を予測できること，予測モデルを分析することで知識間関係をネットワー クとして抽出できることが報告された．学習者が獲得している知識から，ある知 識の獲得されやすさをそのまま予測しており，得られた知識間関係から抽出した ネットワークは知識獲得における知識構造を表現しているといえる．
これまで，心理学で議論されていたものの定量的な分析が困難だった宣言的知
4

識と手続き的知識の獲得における知識構造の違いは，MOOCs の登場によりさま ざまな科目について問題回答ログがデータとして蓄積されるようになり，その蓄 積された学習者の知識獲得の軌跡から深層学習により知識間関係を抽出できるよ うになり，さらに，ネットワーク分析の発展により抽出した知識構造を分析でき るようになった今，定量的に分析できる可能性が高まっている．
本論文では，心理学で議論されていた宣言的知識と手続き的知識の獲得におけ る知識構造の違いを定量的に分析し，知識獲得における宣言的知識の知識構造は 手続き的知識の知識構造と比べてよりモジュール性が高く，逆に，手続き的知識 の知識構造は宣言的知識の知識構造と比べてより階層性が高いことを検証する．
まず，データセットを小学生と中学生を対象とした国内最大級の MOOCs であ る「勉強サプリ」における問題回答ログより作成する．特に，地理と歴史に関する 5 つの講座の問題回答ログから作成した 5 つのデータセットを宣言的知識の獲得を 主目的とするデータセットとし，算数や数学に関する 6 つの講座の問題回答ログ から作成した 6 つのデータセットを手続き的知識の獲得を主目的とするデータセッ トとして，合計 11 のデータセットに対して分析を行う．次に，各データセットに 深層学習を活用した知識獲得の予測手法を適用し，それぞれ知識間関係をネット ワークとして抽出する．そして，抽出したネットワークのモジュール性をモジュ ラリティで評価し，階層性をフロー階層と GRC で評価する．
検証実験の結果，地理と歴史に関する講座から抽出したネットワークのモジュラ リティは算数や数学に関する講座のものより有意水準 0.05 で有意に高かった．逆 に，算数や数学に関する講座から抽出したネットワークのフロー階層と GRC は地 理と歴史に関する講座のものより有意水準 0.05 で有意に高かった．したがって，心 理学で議論されていたように，知識獲得において宣言的知識の知識構造は手続き 的知識のものと比べてモジュール性が高く，逆に，手続き的知識の知識構造は宣 言的知識のものと比べて階層性が高いことが検証された．
検証結果を踏まえ，本研究で用いた知識構造の分析手法の他 MOOCs への適用 可能性や，研究の拡張として適用対象や知識間関係抽出手法の拡張を考察した．
本研究は，MOOCs の登場，ネットワーク分析の発展，深層学習の躍進等，ここ 数年の幅広い領域のさまざまな成果によって，初めてその実施が可能になったも のである．本研究が，人間の学習や知能の解明の一助になると信じている.
5

目次

第 1 章 序論 1.1 背景 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 研究目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 本論文の構成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 1 6 6

第 2 章 先行研究

9

2.1 心理学における知識 . . . . . . . . . . . . . . . . . . . . . . . . . . 9

2.1.1 知識の属性や性質 . . . . . . . . . . . . . . . . . . . . . . . . 9

2.1.2 知識の獲得や活用 . . . . . . . . . . . . . . . . . . . . . . . . 11

2.2 Massive Open Online Courses . . . . . . . . . . . . . . . . . . . . . 14

2.3 深層学習 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

2.4 知識獲得の予測 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

2.4.1 Knowledge Tracing の定式化 . . . . . . . . . . . . . . . . . . 24

2.4.2 Bayesian Knowledge Tracing . . . . . . . . . . . . . . . . . . 25

2.4.3 Performance Factor Analysis . . . . . . . . . . . . . . . . . . 27

2.4.4 Deep Knowledge Tracing . . . . . . . . . . . . . . . . . . . . 27

2.5 ネットワーク分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

第 3 章 分析手法

34

3.1 知識獲得における知識間関係の抽出 . . . . . . . . . . . . . . . . . . 36

3.2 データの要件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

3.3 知識間関係ネットワークの構造評価 . . . . . . . . . . . . . . . . . . 39

第 4 章 データセット

42

4.1 勉強サプリ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.2 データセットの作成 . . . . . . . . . . . . . . . . . . . . . . . . . . 44

i

4.3 データセットの概観 . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4.4 個々のデータセットの具体的説明 . . . . . . . . . . . . . . . . . . . 47

第 5 章 実験

57

5.1 Deep Knowledge Tracing の拡張および最適化 . . . . . . . . . . . . 57

5.2 設定 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

5.3 結果 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

5.3.1 各データセットにおける予測性能 . . . . . . . . . . . . . . . 61

5.3.2 抽出した知識間関係ネットワークの可視化 . . . . . . . . . . 62

5.3.3 ネットワーク構造の分析 . . . . . . . . . . . . . . . . . . . . 71

第 6 章 考察

74

6.1 データセットと知識構造 . . . . . . . . . . . . . . . . . . . . . . . . 74

6.2 知識構造分析手法の他 MOOCs への適用可能性 . . . . . . . . . . . 75

6.3 今後の展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

6.3.1 対象データの多様化，結合，長期化 . . . . . . . . . . . . . . 76

6.3.2 知識間関係抽出手法の拡張 . . . . . . . . . . . . . . . . . . . 77

第 7 章 結論

79

参考文献

80

謝辞

90

発表文献

93

ii

図目次
2.1 ACT*理論の構成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2 Coursera のイメージ . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.3 KhanAcademy のイメージ . . . . . . . . . . . . . . . . . . . . . . . 15 2.4 RNN の構造のイメージ . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.5 フロー階層の適用事例 . . . . . . . . . . . . . . . . . . . . . . . . . 33
3.1 分析手法全体の流れ . . . . . . . . . . . . . . . . . . . . . . . . . . 35
4.1 勉強サプリのマイページ . . . . . . . . . . . . . . . . . . . . . . . . 43 4.2 勉強サプリの講義一覧ページ . . . . . . . . . . . . . . . . . . . . . 43 4.3 勉強サプリの講義視聴ページ . . . . . . . . . . . . . . . . . . . . . 43 4.4 勉強サプリの問題演習ページ . . . . . . . . . . . . . . . . . . . . . 43 4.5 小学 4 年社会の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 48 4.6 小学 4 年社会の平均着手順と回答ログ数の XY プロット . . . . . . . 48 4.7 小学 4 年算数の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 48 4.8 小学 4 年算数の平均着手順と回答ログ数の XY プロット . . . . . . . 48 4.9 小学 5 年社会の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 49 4.10 小学 5 年社会の平均着手順と回答ログ数の XY プロット . . . . . . . 49 4.11 小学 5 年算数の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 50 4.12 小学 5 年算数の平均着手順と回答ログ数の XY プロット . . . . . . . 50 4.13 小学 6 年社会の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 50 4.14 小学 6 年社会の平均着手順と回答ログ数の XY プロット . . . . . . . 50 4.15 小学 6 年算数の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 51 4.16 小学 6 年算数の平均着手順と回答ログ数の XY プロット . . . . . . . 51 4.17 中学 1 年数学の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 52
iii

4.18 中学 1 年数学の平均着手順と回答ログ数の XY プロット . . . . . . . 52 4.19 中学 2 年数学の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 53 4.20 中学 2 年数学の平均着手順と回答ログ数の XY プロット . . . . . . . 53 4.21 中学 3 年数学の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . 53 4.22 中学 3 年数学の平均着手順と回答ログ数の XY プロット . . . . . . . 53 4.23 中学地理の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . . . 54 4.24 中学地理の平均着手順と回答ログ数の XY プロット . . . . . . . . . 54 4.25 中学歴史の問題と回答選択肢の例 . . . . . . . . . . . . . . . . . . . 55 4.26 中学歴史の平均着手順と回答ログ数の XY プロット . . . . . . . . . 55 5.1 小学 4 年社会の知識間関係ネットワーク . . . . . . . . . . . . . . . 63 5.2 小学 5 年社会の知識間関係ネットワーク . . . . . . . . . . . . . . . 64 5.3 小学 6 年社会の知識間関係ネットワーク . . . . . . . . . . . . . . . 64 5.4 中学地理の知識間関係ネットワーク . . . . . . . . . . . . . . . . . . 65 5.5 中学歴史の知識間関係ネットワーク . . . . . . . . . . . . . . . . . . 66 5.6 小学 4 年算数の知識間関係ネットワーク . . . . . . . . . . . . . . . 67 5.7 小学 5 年算数の知識間関係ネットワーク . . . . . . . . . . . . . . . 67 5.8 小学 6 年算数の知識間関係ネットワーク . . . . . . . . . . . . . . . 68 5.9 中学 1 年数学の知識間関係ネットワーク . . . . . . . . . . . . . . . 69 5.10 中学 2 年数学の知識間関係ネットワーク . . . . . . . . . . . . . . . 70 5.11 中学 3 年数学の知識間関係ネットワーク . . . . . . . . . . . . . . . 71
iv

表目次
2.1 Deep Knowledge Tracing における回答ログデータと対応する入力 ベクトルの例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
4.1 11 データセットの統計量 . . . . . . . . . . . . . . . . . . . . . . . . 46 5.1 拡張した Deep Knowledge Tracing における回答ログデータと対応
する入力ベクトルの例 . . . . . . . . . . . . . . . . . . . . . . . . . 58 5.2 各データセットに対する各手法の予測性能とそれらの関係性 . . . . 62 5.3 各ネットワークにおける構造指標 . . . . . . . . . . . . . . . . . . . 71
v

第1章 序論
本章では，本論文の背景，研究目的および本論文の構成について述べる．
1.1 背景
伝統的に，知識は学習や指導の設計において重要な役割を担っており，心理学で は知識について多角的に議論が行われていた．知識の属性や性質から知識を比較 する研究 [Ryle, 1945, De Jong and Ferguson-Hessler, 1996] や，学習者の知識の獲 得や活用の仕組みを説明する研究 [Anderson, 1982, Anderson, 1993]，また，それ らを基に効率的な知識獲得の方法を開発する研究 [Corbett and Anderson, 1994]， など幅広い．
知識の属性や性質という点では，一般知識と領域知識，宣言的知識と手続き的 知識，具体的知識と抽象的知識，戦略的知識，暗黙知，メタ知識など，さまざま な属性や性質，あるいはその対比を切り口に議論が行われていた [De Jong and Ferguson-Hessler, 1996] が，このなかでも，宣言的知識と手続き的知識の 2 つを 対比し知識を議論する研究は多い [Anderson, 1982, McCormick, 1997, Ten Berge and Van Hezewijk, 1999]．宣言的知識は内容や概念を表現する知識であり，knowing that [Ryle, 1945] という言葉でも表現され，対象（A）がどう（B）であるかに関 する知識である．例えば，「東京は日本の首都である」という知識が該当し，この 場合，A が東京であり，B が日本の首都である．一方で，手続き的知識は，手続き を表現する知識であり，knowing how [Ryle, 1945] という言葉でも表現され，タス クをどう達成するかに関する知識である．特に，数学やプログラミングを対象に 議論されることが多い．例えば，「1 次方程式 ax + b = 0 を解く」ための知識が該 当し，この場合，b を移行し a で両辺を割るという手続きにより問題を解くことが できる．
1

第 1 章 序論

2

特に，学習者の知識獲得の点でも，宣言的知識と手続き的知識を対比的に扱い説 明する研究は多い [Anderson, 1982, Anderson, 1990]．宣言的知識は連想による意 味ネットワークの形式で保持され，学習者が保有する知識に結合する形で獲得さ れるため，獲得対象の知識に既に獲得しているものが含まれている方が獲得され やすいといわれている．例えば，「東京は日本の首都である」という知識であれば， 東京，首都，日本のうち，より多くについて既知であるほど獲得しやすく，逆に， 「地球は丸い」という知識が獲得していいたとしても必ずしも獲得しやすいわけで はない，ということである．一方で，手続き的知識は，タスクが複数の細かいサブ タスクに分解されるため，学習者が分解後の全てのサブタスクを達成するための 知識を保有している場合に獲得されるといわれている．「1 次方程式 ax + b = 0 を 解く」ための知識は，「項を移行する」ための知識と「両辺を定数で割る」ための 知識に分解され，さらに，「ある定数を引く」ための知識や「ある定数で割る」た めの知識に分解され，というように階層的に分解された知識を全て保有している 場合に，はじめて「1 次方程式 ax + b = 0 を解く」ための知識を獲得していると いえる，ということである．宣言的知識と手続き的知識はその獲得のされやすさ が学習者が既に獲得している知識に依るところは共通するが，宣言的知識は関連 の強い知識間で局所的にその獲得に影響を与え合い，一方で，手続き的知識は分 解された知識がその掛け合わせで構成される知識の獲得に影響を与えるため，知 識獲得における知識構造は，手続き的知識のものは宣言的知識のものと比べると， 階層的になると考えられていた．
心理学の領域で，この考えを支持する研究報告は多い．習熟学習に関する研究と しては，領域知識をよく分析し階層的に知識間関係を構築し，階層構造上より水準 の高い知識に着手する前に，予め獲得するべき知識が確実に獲得されるように学習 体験を構造化することで，ほとんど全ての学習者がスキルを十分に習熟できるとい う考えを報告するもの [Keller, 1968, Bloom, 1968] もある．また，その報告を受け て実験を行い，当初の期待よりは効果は小さかったものの，よく分析し階層的に構 造化した知識間関係に基づいて学習を設計することで学習を効率化できると報告す る研究も少なくない [Block et al., 1971, Cohen and Hyman, 1979, Resnick, 1977]． また，[Anderson, 1982, Anderson, 1990] では，ACT*理論（Adaptive Charactor of Thought Theory）という認知構造に関する理論が提案され，手続き的知識の獲得

2

第 1 章 序論

3

を，解釈を必要とする宣言的知識の適用から生成規則の適用への置き換えの過程 （手続き化）として表現し，より複雑な手続きの獲得を生成規則の系列の結合とし て位置付けた．
また，こうした習熟学習の研究や ACT*理論をプログラミングの学習支援システ ムに応用して知識獲得を予測し学習の効率化を狙った研究も報告されている．Corbett ら [Corbett and Anderson, 1994] は，知識獲得の予測のタスクとして Knowledge Tracing というタスクを提案した．Knowledge Tracing は過去の問題回答ログ データから次に解く問題の正誤を予測するというタスクである．次に解く問題の 正誤を予測し，スキルを獲得しているか否かを推定する仕組みを学習支援システ ムに導入することで，階層構造上より水準の高いプログラミングスキルに着手す る前に，予め獲得するべきプログラミングスキルが確実に獲得されるように学習 体験を構造化し，学習の効率化を狙った研究である．
しかし，実験より示唆する研究報告はあるものの，宣言的知識と手続き的知識 の対比において，知識獲得における知識構造を定量的に比較し分析した研究はま だない．これは，こうした心理学の研究が行われていたのが 20 年以上も前で，当 時は，定量評価を実施できる学習者の知識獲得に関するデータの収集が困難であ り，知識獲得に関するデータから知識獲得における知識構造を抽出することも難 しく，また，抽出した知識構造を分析する方法もなかったからだと推察される．
さて，こうした知識間関係のように対象間の関係を明らかにしようとする分析 として，ネットワーク分析というものがある．ネットワーク分析は対象をノード， 対象間の関係をエッジとするグラフを構築し，その構造から個々の対象や関係あ るいは全体を評価しようというものである．ネットワーク分析はウェブやそれを 活用するソーシャルメディアの普及に伴い注目が高まり，ウェブページやユーザ を分析するためにしばしば用いられている．応用事例として，ウェブページ検索 エンジンの性能向上のためノードの重要度を評価するページランクという指標を 開発する研究 [Page et al., 1999] やソーシャルメディアにおけるユーザ間の関係性 から友人関係を推定し推薦への活用を試みる研究 [Dong et al., 2012] 等がある．
ネットワークを評価する指標という点でも多くのものが存在する．ネットワー クにおける個々のノードやエッジの特徴を評価する指標として，中心度という点 でノードを評価する次数中心性や近接中心性，経路における中心度という点でエッ

3

第 1 章 序論

4

ジを評価する媒介中心性等がある．また，ネットワークの構造を捉えるための指 標も開発されており，例えば，ネットワークのモジュール性を評価するモジュラリ ティという指標 [Newman, 2006] や階層性を評価するフロー階層という指標 [Luo and Magee, 2011] や GRC という指標 [Mones et al., 2012]，ネットワークの大きさ を評価するネットワーク直径という指標等がある．
また，学習や教育に関する領域では，近年，Massive Open Online Courses（以 下，MOOCs）[McAuley et al., 2010, Pappano, 2012, Siemens, 2013] が注目を集 めている．MOOCs はオンライン上で誰もが受講できる大規模な講座群のことであ る．講座を運営するプラットフォームサービスを指して MOOCs と呼ぶこともあ る．MOOCs はオンライン上でさまざまな講座を提供し，また各講座ごとに講義動 画や演習システム，掲示板等が提供されている．従来の教室で時間割通りに一斉授 業形式で提供される学習機会とは異なり，数多くの多様な講座のオンライン上で の提供を通じて，いつでもどこでも自分のペースでさまざまな講座から自分の学 習したいものを選択し学習できるというこれまでにない学習機会を提供しており， 多くの学習者が利用している．例えば，有名な MOOCs の 1 つである Coursera1 で は 2016 年 1 月の時点で，コンピュータサイエンス，数学や論理，社会科学などに 関する 1500 以上の講座を提供し，1700 万人以上が利用している 2．
MOOCs は単にこれまでにない学習機会を提供しているというだけでなく，こ れまで難しかった大規模な学習効果分析の可能性も高めている．学習者はオンラ イン上で提供された講義動画や演習問題を通して学習するが，オンライン上で実 施されているため学習行動ログをデータとして蓄積することができ，さらに，そ のデータを分析に活用することができる．また，多くの多様な学習者が利用する ため，多様な学習者の大規模な学習行動ログから多様な講座の学習効果の分析が 可能となりつつある．特に，演習問題の回答ログはその演習問題により評価され る知識を学習者が獲得しているか否かを表現しているため，知識獲得の分析に利 用できる．例えば，MOOCs の演習問題の回答ログを利用して知識獲得の予測を 行う研究 [MacHardy and Pardos, 2015] では，有名な MOOCs の 1 つである Khan Academy3 から収集したデータを利用していたが，その問題回答ログ数は 100 万件
1https://www.coursera.org/ 2 講座数と利用者数はトップページの記載より引用． 3https://www.khanacademy.org/
4

第 1 章 序論

5

以上であり，大規模なデータを対象に分析がなされていた． さて，ここ数年，特に学習や教育に関する領域に限らず，多くの研究領域で深層
学習が注目されている．深層学習は多層のニューラルネットワークによる機械学習 のことで，従来の機械学習では難しかった対象データの表現抽出を最適化の過程で 行うことができる．深層学習の活用により画像認識 [Schroﬀ et al., 2015, Szegedy et al., 2014]，機械翻訳 [Sutskever et al., 2014, Dong et al., 2015]，質問応答文生 成 [Yin et al., 2015]，画像説明文生成 [Xu et al., 2015, Vinyals et al., 2014]，音 声認識 [Hinton et al., 2012, Bahdanau et al., 2015] 等さまざまな研究領域で飛躍 的な進展が報告がされている．画像認識では深層学習により例えば犬の表現とし て目や鼻，口の表現が抽出できると報告する研究 [Zeiler and Fergus, 2014] や，人 間より高い精度で人の顔を見分けられたと報告する研究 [Schroﬀ et al., 2015] もあ る．また，機械翻訳の領域では，可変長の英語を可変長のフランス語に翻訳する 研究 [Sutskever et al., 2014] やフランス語とオランダ語，スペイン語の共通表現を 抽出し英語から 1 つのモデルで翻訳する研究もある [Dong et al., 2015]．また，こ れらを掛け合わせた画像説明文生成の領域では，説明文の単語 1 つずつを生成す る際に画像のどの部分に着目すべきかという表現を抽出し，説明文を生成する研 究 [Xu et al., 2015] もある．このように，深層学習は多くの研究領域で大きな進展 をもたらしている．
特に，学習者の知識獲得を予測する研究も，深層学習により大きく進展した． Piech らは Knowledge Tracing に深層学習を活用する Deep Knowledge Tracing と いう手法を発表した [Piech et al., 2015]．数学における知識獲得の予測に時系列分 析でよく用いられる深層学習モデルである Recurrent Neural Networks を活用し， 高い性能で知識獲得を予測できること，予測モデルを分析することで知識間関係 をネットワークとして抽出できることが報告された．学習者が獲得している知識 から，ある知識の獲得されやすさをそのまま予測しており，得られた知識間関係か ら抽出されたネットワークは知識獲得における知識構造を表現しているといえる．
これまで，心理学で議論されていたものの定量的な分析が困難だった宣言的知 識と手続き的知識の獲得における知識構造の違いは，MOOCs の登場によりさまざ まな科目について問題回答ログがデータとして蓄積されるようになり，その蓄積 された学習者の知識獲得の軌跡から深層学習により知識間関係を抽出できるよう

5

第 1 章 序論

6

になり，さらに，ネットワーク分析の発展により抽出した知識構造の構造を分析 できるようになった今，定量的に分析できる可能性が高まっていると考えられる．
以上，本研究の背景について述べた．次に，上記の背景を踏まえた研究目的に ついて説明する．

1.2 研究目的
本論文の目的は，心理学で議論されていた宣言的知識と手続き的知識の獲得に おける知識構造の違いを定量的に分析することとで下記の 2 つを検証することで ある．
• 知識獲得における宣言的知識の知識構造は手続き的知識の知識構造と比べて よりモジュール性が高い．
• 逆に，知識獲得における手続き的知識の知識構造は宣言的知識の知識構造と 比べてより階層性が高い．
従来心理学で議論され，実際の教育や学習にも活用されているものの，定量的 に検証されていないこれら知識構造について明らかにすることは，学術的な意義 が大きいと考える．
以上，本研究の目的について述べた．次に，背景と目的を踏まえて本論文の構 成について述べる．

1.3 本論文の構成
以降の本論文の構成について述べる． 2 章では，先行研究について述べる．まず，心理学における知識について詳細に 述べる．次に，MOOCs について，比較事例を挙げ，種類や効果，問題点等につい て述べる．さらに，深層学習について概説したのうち，特に本論文と関わりが深い Recurrent Neural Networks について詳細に述べる．そして，知識獲得の予測につ
6

第 1 章 序論

7

いて伝統的な手法と最先端の手法について整理し，最後に，ネットワーク分析に ついて，特に，モジュール性を捉える指標と階層性を捉える指標について述べる．
3 章では，宣言的知識と手続き的知識の知識獲得における知識構造の違いを分析 するための手法について説明する．まず，分析手法全体の流れを概説し，手法全 体が 3 つのブロックから構成されることを述べる．その後，まず，既存の知識間関 係の抽出手法の中で，Deep Knowledge Tracing が最適であることを説明する．次 に，分析対象の問題回答ログデータについて要件があることを述べ，その要件と して，比較検証できる複数のデータセットを作成できること，各データセットが 大規模であること，初等中等教育水準の数学や地理，歴史に関する科目であるこ と，について説明する．最後に，抽出した知識間関係ネットワークのモジュール 性と階層性を評価するために，ネットワーク構造指標の中でもモジュラリティと フロー階層および GRC を用いること，また，これらの各指標について，宣言的知 識によるネットワークと手続き的知識によるネットワーク間で有意差検定を実施 し，構造の違いを検証することを述べる．
4 章では，実験で用いるデータセットについて述べる．データセットは，小学 4 年生から中学 3 年生を対象とする国内最大級の MOOCs「勉強サプリ 4」で提供 される 11 の講座の問題回答ログデータから作成する．まず，勉強サプリから収集 されたログデータが分析に利用するためのデータ要件を満たした本分析に最適な データであることを述べる．次に，実験で用いる宣言的知識の獲得を主目的とす るデータセットと手続き的知識の獲得を主目的とするデータセットの作成につい て述べる．特に，歴史や地理に関する講座の問題が主に宣言的知識の獲得の有無 を評価する問題であることを指摘し，歴史や地理に関する 5 講座から宣言的知識 の獲得を主目的とするデータセットとして 5 つのデータセットを作成する．また， 算数や数学に関する講座の問題が主に手続き的知識の獲得の有無を評価する問題 であることを指摘し，算数や数学に関する 6 講座から手続き的知識の獲得を主目 的とするデータセットとして 6 つのデータセットを作成する．
5 章では，実験について述べる．まず，データセットへの適合のための Deep Knowledge Tracing の拡張法を述べたのち，次に，実験設定について述べ，最後に 実験結果について述べる．実験結果においては，まず，11 のデータセットのいずれ

4https://benkyosapuri.jp/

7

第 1 章 序論

8

のデータセットにおいても，Deep Knowledge Tracing の予測性能が知識間関係を 考慮しない Bayesian Knowledge Tracing よりも高いことを示し，Deep Knowledge Tracing により知識獲得における知識間関係を抽出できていることを定量的に確認 する．さらに，11 の知識間関係ネットワークを可視化し，ネットワーク全体にお けるノード集合の配置やその関係を内容の側面から分析し，知識獲得における知 識間関係を抽出できていることを定性的に確認する．そして，宣言的知識の知識 構造を表現する 5 つのネットワークと手続き的知識の知識構造を表現する 6 つの ネットワークのモジュラリティとフロー階層，GRC を算出し，知識獲得における 知識構造について，宣言的知識のモジュール性が手続き的知識のモジュール性よ り統計的に有意に高く，逆に，手続き的知識の階層性が宣言的知識の階層性より 統計的に有意に高いことを示す．
6 章では，実験結果を踏まえた考察を述べる．検証過程で得られた知見に基づい て，本研究で用いた知識構造の分析手法の他 MOOCs への適用可能性について議 論し，講座の科目や問題へのタグの有無に依らず知識構造を分析できる可能性が あること，および，特に，大学水準の難易度を扱う MOOCs については検証実験 を行う必要があることを指摘する．また，本研究の拡張として，適用対象の拡張 という点で対象データの多様化，結合，長期化の 3 つの拡張を述べる．また，知 識間関係抽出法である Deep Knowledge Tracing の拡張という点で，カリキュラム 学習による拡張，および，スキルタグ自動抽出による拡張の 2 つについて述べる． 最後に，7 章で結論を述べる．
以上，序論について述べた．次に，先行研究について述べる．

8

第2章 先行研究
本章では，先行研究について述べる．まず，心理学における知識について詳細 に述べる．次に，MOOCs について，比較事例を挙げ，種類や効果，問題点等につ いて述べる．さらに，深層学習について概説したのうち，特に本論文と関わりが 深い Recurrent Neural Networks について詳細に述べる．そして，知識獲得の予測 について伝統的な手法と最先端の手法について整理し，最後に，ネットワーク分 析について，特に，モジュール性を捉える指標と階層性を捉える指標について述 べる．
2.1 心理学における知識
伝統的に，知識は学習や指導の設計において重要な役割を担っており，心理学で は知識について多角的に議論がなされていた．知識の属性や性質から知識を比較 する研究 [Ryle, 1945, De Jong and Ferguson-Hessler, 1996] や，学習者の知識の獲 得や活用の仕組みを説明する研究 [Anderson, 1982, Anderson, 1993]，また，それ らを基に効率的な知識獲得の方法を開発する研究 [Corbett and Anderson, 1994]， など幅広い．それぞれ，説明していく．
2.1.1 知識の属性や性質
まず，知識の属性や性質から知識を比較する研究について説明する．知識の属 性や性質という点では，一般知識と領域知識，宣言的知識と手続き的知識，具体 的知識と抽象的知識，戦略的知識，暗黙知，メタ知識など，さまざまな属性や性 質，あるいはその対比を切り口に議論されてきた．属性や性質は多様であるが，例 えば，[De Jong and Ferguson-Hessler, 1996] では物理学を事例とし，これまで先 行研究で議論されてきたさまざまな名称の知識を質と種類の 2 つの軸を導入して
9

第 2 章 先行研究

10

整理した．質の軸は深さ，構造性，自動性，様相，一般性の 4 軸を設け，種類の軸 は，状況的，概念的，手続き的，戦略的の 4 軸を設けた．例えば，浅い手続き的 知識であれば，ルールや操作が該当し，構造化された戦略的知識であれば，一貫 した系列の行動が該当する，というように知識を 32 = 2 × 4 × 4 種類に分けて整 理している．
このような知識を整理する研究の中でも，宣言的知識と手続き的知識の 2 つを 対比し知識を議論する研究は多い [Anderson, 1982, McCormick, 1997, Ten Berge and Van Hezewijk, 1999]．宣言的知識は内容や概念を表現する知識であり，knowing that [Ryle, 1945] という言葉でも表現され，対象（A）がどう（B）であるかに関 する知識である．例えば，「東京は日本の首都である」という知識が該当し，この 場合，A が東京であり，B が日本の首都である．一方で，手続き的知識は，手続き を表現する知識であり，knowing how [Ryle, 1945] という言葉でも表現され，タス クをどう達成するかに関する知識である．特に，数学やプログラミングを対象に 議論されることが多い．例えば，「1 次方程式 ax + b = 0 を解く」ための知識が該 当し，この場合，b を移行し a で両辺を割るという手続きにより問題を解くことが できる．
また，宣言的知識と手続き的知識の対比は，しばしば類似した他の名前の知識 の対比によって表現されることがある．特に，宣言的知識について，他に事実的知 識と概念的知識等の複数類似した内容をさす用語が存在して紛らわしい．そこで， それぞれ違いをここで整理しておく．宣言的知識が概念や命題，系列を表現し，意 味ネットワークという形式を取る [Anderson, 1990] が，事実的知識は事実に関す る知識であり，必ずしも系列や概念を含まない．この場合，宣言的知識は事実的知 識を含む．この他にも，事実的知識は対象が事実であるかどうか判断する知識を指 す場合もある [Unger, 1968]．概念的知識は特に数学や理科，プログラミングに関 する内容を扱う場合によく使われる用語である [McCormick, 1997, Rittle-Johnson and Alibali, 1999, Hiebert, 2013]．数学や理科，プログラミングの対象は多くの場 合，数や記号で表現される概念を対象としているからだと考えられる．宣言的知 識との違いとして，概念的知識は知識間の関連に焦点を当てている点，概念的知 識は活発なプロセスの一部であるという点が挙げられている [McCormick, 1997]． 宣言的知識と手続き的知識の対比に加えて，構造化や抽象化を行う論理的知識の

10

第 2 章 先行研究

11

特異性を主張し，3 つを対比する研究もある [Cauley, 1986]．しかし，宣言的知識 と手続き的知識を対比する研究 [Anderson, 1982, Anderson, 1990] では，手続き的 知識に推論や構造化に関する知識が含まれているおり，議論が終わっていないよ うな側面もある．本研究は，特に，ACT*理論 [Anderson, 1982, Anderson, 1990] における宣言的知識と手続き的知識の定義を採用している．ACT*理論の詳細は後 述する．

2.1.2 知識の獲得や活用
次に，学習者の知識の獲得や活用の仕組みを説明する研究について説明する．特 に，学習者の知識獲得の点でも，宣言的知識と手続き的知識を対比的に扱い説明 する研究は多い [Anderson, 1982, Anderson, 1990]．宣言的知識は連想による意味 ネットワークの形式で保持され，学習者が保有する知識に結合する形で獲得され るため，獲得対象の知識に既に獲得しているものが含まれている方が獲得されや すいといわれている．例えば，「東京は日本の首都である」という知識であれば，東 京，首都，日本のうち，より多くについて既知であるほど獲得しやすく，逆に，「地 球は丸い」という知識が獲得していいたとしても必ずしも獲得しやすいわけでは ない，ということである．一方で，手続き的知識は，タスクが複数の細かいサブ タスクに分解されるため，学習者が分解後の全てのサブタスクを達成するための 知識を保有している場合に獲得されるといわれている．「1 次方程式 ax + b = 0 を 解く」ための知識は，「項を移行する」ための知識と「両辺を定数で割る」ための 知識に分解され，さらに，「ある定数を引く」ための知識や「ある定数で割る」た めの知識に分解され，というように階層的に分解された知識を全て保有している 場合に，はじめて「1 次方程式 ax + b = 0 を解く」ための知識を獲得していると いえる，ということである．宣言的知識と手続き的知識はその獲得のされやすさ が学習者が獲得している知識との関係に依るところは共通するが，宣言的知識は 関連の強い知識間で局所的にその獲得に影響を与え合い，一方で，手続き的知識 は分解された知識がその掛け合わせで構成される知識の獲得に影響を与えるため， 知識獲得における知識構造は，手続き的知識のものは宣言的知識のものと比べる と，階層的になると考えられていた．
11

第 2 章 先行研究

12

心理学の領域で，この考えを支持する研究報告は多い．習熟学習に関する研究と しては，領域知識をよく分析し階層的に知識間関係を構築し，階層構造上より水 準の高い知識に着手する前に，予め獲得するべき知識が確実に獲得されるように 学習体験を構造化することで，ほとんど全ての学習者がスキルを十分に習熟でき るという考えを報告するもの [Keller, 1968, Bloom, 1968] もある．また，その報告 を受けて実験を行い，当初の期待よりは効果は小さかったものの，よく分析し階層 的に構造化した知識関係に基づいて学習を設計することで学習を効率化できると 報告する研究も少なくない [Block et al., 1971, Cohen and Hyman, 1979, Resnick, 1977]．
また，[Anderson, 1982, Anderson, 1990] では，ACT*理論（Adaptive Charactor of Thought Theory）という知識の獲得と活用を含む認知構造に関する理論が提案 された．本研究では，特に，ACT*理論における宣言的知識と手続き的知識の定義 を採用している．そのため，ACT*理論について詳細に述べる．まず，ACT*理論 の構成について述べる．ACT*理論の構成を図 2.1 に示す．ACT*理論には 3 種類

宣言的メモリ

適合

手続き的メモリ

検索・取得 保存

適合 実行

ワーキングメモリ

符号化 外界

遂行

図 2.1: ACT*理論の構成

8

のメモリがある．宣言的知識を格納する宣言的メモリ（Declarative Memory）と 12

第 2 章 先行研究

13

手続き的知識を格納する手続き的メモリ（Procedural Memory），ワーキングメモ リ（Working Memory）の 3 つのメモリである．宣言的メモリは連想により概念や 命題，系列を結合する意味ネットワークの形式をとる．手続き的メモリは生成規 則（Production Rule）の形式で表現される．それぞれの生成規則は宣言的メモリ に格納されている条件と行動のペア（IF-THEN-）をもつ．手続き的メモリはそれ ぞれで活性化の程度があり，ワーキングメモリが最もよく活性化されるメモリで ある．ACT*理論には基本的な学習の仕組みが 3 つある．1 つは，「一般化」で，生 成規則が適用される幅が広がるというものである．1 つは，「差別化」で，生成規則 の適用される幅がせばまるというものである．1 つは，「強化」で，いくつかの生成 規則が適用される頻度が向上し，また，既存の生成規則の結合あるいは分離によ り新しい生成規則が形成される，というものである．
次に，ACT*理論における知識の獲得と活用について述べる．まず，全ての知識 は宣言的な情報から始められる．手続き的知識は既に存在する宣言的知識から推 論を行うという問題解決の過程で学習される．あるタスクが実行されると，解釈を 必要とした宣言的知識の適用が徐々に，当該タスクを直接実行する生成規則によっ て置き換えられていく．この過程は手続き化と呼ばれる．例えば，初めて 2 + 4 や 1 + 5 等の数字の足し算を実行するときには，右手と左手の指を立てたり折ったり して，最終的に残った指の本数を数えるということがしばしば行われる [Gersten and Chard, 1999] が，繰り返し行うことによって，当該生成規則を認知し実行す る生成規則に徐々に置き換えられていく．つまり，明示的な宣言的知識の適用が 手続き的知識の直接的適用に置き換えられていくということである（習熟すると いうことでもある）．生成規則の系列が結合して，ひとつの生成規則になることも ある．また，知識が生成規則の形式に変換されると適用の早さや安定性が向上し ワーキングメモリへの負担が減る．特に，新しい生成規則の獲得が既存の生成規 則との掛け合わせである場合，その掛け合わせが知識獲得における手続き的知識 の階層性を表現しているといえる．
また，こうした習熟学習の研究や ACT*理論をプログラミングの学習支援システ ムに応用して知識獲得を予測し学習の効率化を狙った研究も報告されている．Corbett ら [Corbett and Anderson, 1994] は，知識獲得の予測のタスクとして Knowledge Tracing というタスクを提案した．Knowledge Tracing は過去の問題回答ログ

13

第 2 章 先行研究

14

データから次に解く問題の正誤を予測するというタスクである．次に解く問題の 正誤を予測し，スキルを獲得しているか否かを推定する仕組みを学習支援システ ムに導入することで，階層構造上より水準の高いプログラミングスキルに着手す る前に，予め獲得するべきプログラミングスキルが確実に獲得されるように学習 体験を構造化し，学習の効率化を狙った研究である．また，この研究の拡張は多 いが，知識獲得の予測に関する詳細については後述する．
以上，心理学における知識について述べた．次に，MOOCs について述べる．

2.2 Massive Open Online Courses
MOOCs は Massive Open Online Courses [McAuley et al., 2010, Pappano, 2012, Siemens, 2013] の略称で，特に日本語で表記する場合は大規模公開オンライン講座 と記述することがある．MOOCs はオンライン上で誰もが受講できる大規模な講座 群のことである．講座を運営するプラットフォームサービスを指して MOOCs と 呼ぶこともある．MOOCs という概念の登場は 2008 年に主に履修登録をした学生 向けに講座をオンラインで開催したら，学生だけでなく 2000 人以上の人がその講 座に参加したことがきっかけだと言われている [Yuan et al., 2013]．以前から大学 はオープンコースウェア [Abelson, 2008] という形で講義の動画や資料を公開して いたが，MOOCs は，参加人数が非常に大規模であるという点や，高等教育水準の 内容の講座だけでなく初等中等教育水準の内容の講座も含まれるという点でオー プンコースウェアとは異なる．また，これまでもオンライン講座というものは存 在していたが，MOOCs は，参加人数が非常に大規模であるという点や公開して いる講座の数が大規模である点，また，その内容が多様であるという点，利用が 無料，あるいは無料に近いという点で，これまでのオンライン講座とは異なる．
MOOCs ではオンライン上でさまざまな講座を提供され，また各講座ごとに講 義動画や演習システム，掲示板等が提供されている．従来の教室で時間割通りに 一斉授業形式で提供される学習機会とは異なり，数多くの多様な講座のオンライ ン上での提供を通じて，いつでもどこでも自分のペースでさまざまな講座から自 分の学習したいものを選択し学習できるというこれまでにない学習機会を提供し ており，多くの学習者が利用している．
14

第 2 章 先行研究

15

MOOCs は場所や時間に学習ペース，内容に縛られないこれまでにない学習機会 を提供しているという点で，社会や産業への影響が期待されている．例えば，大学 生だけでなく社会人も自分の専門領域に関する講座を受講することで理解を深め たり，あるいは，専門領域とは大きく関わりのない幅広い講座を受講することで 教養を高めたりすることができる．また，特に，公教育の整備がまだ追いついてい ない発展途上国においては MOOCs の影響は大きく，その影響や位置付け，可能 性を分析する報告は多い [Trucano et al., 2013, Liyanagunawardena et al., 2013]．

図 2.2: Coursera のイメージ

図 2.3: KhanAcademy のイメージ

MOOCs の有名な事例としては，Coursera1 や Khan Academy2 が挙げられる． MOOCs と Khan Academy のイメージを図 2.2，2.3 に示す．Coursera は主に大学 の講座を提供する MOOCs で 2016 年 1 月の時点で，コンピュータサイエンス，数 学や論理，社会科学などに関する 1500 以上の講座を提供し，世界中から 1700 万 人以上が利用している 3．図 2.2 では，データサイエンス，ビッグデータ，機械学 習，ビジネスアナリティクス等の講座が人気講座として表示されているが，この ように提供されている講座は専門性が高いものも多い．Khan Academy は 2008 年 にサービスを開始し，主に初等中等教育水準の講座を提供する MOOCs で 2016 年 1 月の時点で，数学，生物，芸術史，地理などに関する多くの講座を提供し，また，
1https://www.coursera.org/ 2https://www.khanacademy.org/ 3講座数と利用者数はトップページの記載より引用．
15

第 2 章 先行研究

16

演習問題については 10 万以上が提供されており 4，世界中の学習者が利用してい る．初等中等教育水準の講座への提供ということもあり，図 2.3 にあるように保護 者や先生と連携する仕組みもある．
MOOCs はそのプラットフォームや運営者に応じて内容や性質が異なり，それら を体系化する研究も多い．[Yuan et al., 2013] では，MOOCs を 4 つの項目 1) サー ビスが営利目的か否か，2) アクセスが有料か否か，3) 修了証が有料か否か，4) 単位取得できるか否か，で整理した．この整理では，例えば，Coursera は営利目 的のサービスであり，アクセスは無料で，修了証の発行は有料で，単位取得は一 部可能というように整理される．また，MOOCs の設計の背後にある教育学的立 場の違いからしばしば xMOOCs と cMOOCs に分けて議論される [Daniel, 2012]． cMOOCs は connectivist MOOCs の略称で学習者間のやり取りを通した学習を重 視した MOOCs であり，xMOOCs はコンテンツベースの学習を重視した MOOCs である．
このように，MOOCs は，その登場より多くの学習者が利用しており期待も高 かったが，MOOCs はその登場当初に期待されていたほど，教育や学習に効果が あったというわけではない．特に，MOOCs における大きな課題の 1 つとして学習 の継続性が非常に低いということが挙げられる．さまざまな MOOCs で提供され ている講座の受講完了率を集計した報告 [Jordan, 2013] によると，MOOCs の講座 完了率は 15%程度であるという．また，[Rivard, 2013] によると，Coursera で提供 されたデューク大学の生体電気に関する講座の履修状況は当該講座に履修登録し た 12,700 人の受講者の中で，最終テストを受けた受講者は 350 人と全体の 3%程 度だったという．これまでにない学習の機会を提供しているという点で非常に期 待されていたが，継続的に勉強しなければ継続的な学習効果は期待できず，した がって，学習の継続性が低いということは MOOCs における大きな課題であると いえる．
また，初等中等教育への影響に懐疑的な意見もある．学習者のやる気や多様性 の観点から考察して報告した研究 [Bock and O DEA, 2013] では，オンライン学 習はやる気の強い学習者にとってはよく機能するがそうでない学習者は辞めてし まうことや，異なる教育背景を持つ多様な学習者に対応できるだけの柔軟性がま

4トップページの記載より引用．

16

第 2 章 先行研究

17

だ MOOCs にないが，特に初等中等教育水準の学習ではそれが重要であることが が指摘された．
MOOCs はこうした学習者に学習の機会を提供するという側面だけでなく，こ れまで難しかった大規模な学習効果分析の可能性を高めるという側面もある．学 習者はオンライン上で提供された講義動画や演習問題を通して学習するが，オン ライン上で実施されているため学習行動ログをデータとして蓄積することができ， さらに，そのデータを分析に活用することができる．また，多くの多様な学習者 が利用するため，多様な学習者の大規模な学習行動ログから多様な講座の学習効 果の分析が可能となりつつある．特に，演習問題の回答ログはその演習問題によ り評価される知識を学習者が獲得しているか否かを表現しているため，知識獲得 の分析に利用できる．例えば，MOOCs の演習問題の回答ログを利用して知識獲 得の予測を行う研究 [MacHardy and Pardos, 2015] では，Khan Academy から収 集したデータを利用していたが，その問題回答ログ数は 100 万件以上であり，こ れまでにないほど大規模なデータを対象に分析が実施されたといえる．
また，MOOCs は多くの学習者が利用しており，こうした分析に基づいた学習の 効率化や学習の継続を促進する教材推薦システムの開発は効果大きいと考えられ る．従来，e ラーニングによる学習支援システムは，例えば大学であれば大学に所 属する学生が利用者の中心で大学に所属していない人の利用が難しかったように， 学習支援システムの利用者が限定されており，したがって，教材推薦による学習 の効率化の活用可能性も限定的であったと考えられる．しかし，MOOCs における 学習効果の改善は，単に一部の限られた学習者がその恩恵を享受できるというこ とに留まらず，世界中の幅広い利用者がその恩恵を享受できるため，その社会的 な影響は小さくないと考えられる．
以上，MOOCs について述べた．次に，深層学習について述べる．

2.3 深層学習
深層学習は多層のニューラルネットワークによる機械学習のことで，従来の機械 学習では難しかった対象データの抽象的表現の抽出を最適化の過程で行うことが できる．深層学習の活用により画像認識 [Schroﬀ et al., 2015, Szegedy et al., 2014]，
17

第 2 章 先行研究

18

音声認識 [Hinton et al., 2012, Bahdanau et al., 2015]，会話認識 [Sak et al., 2015]， 機械翻訳 [Sutskever et al., 2014, Dong et al., 2015]，質問応答文生成 [Yin et al., 2015]，画像説明文生成 [Xu et al., 2015, Vinyals et al., 2014] 等さまざまな研究領 域で飛躍的な進展が報告がされている．
画像認識では深層学習により例えば犬の表現として目や鼻，口の表現が抽出で きると報告する研究 [Zeiler and Fergus, 2014] や，人間より高い精度で人の顔を見 分けられたと報告する研究 [Schroﬀ et al., 2015] もある．また，機械翻訳の領域で は，翻訳前の文章の長さと翻訳後の文章の長さが可変の場合でも利用でき，文章 の長さに依らない特徴を抽出する機械翻訳モデルを開発し，英語からフランス語 への翻訳を試みる研究 [Sutskever et al., 2014] やフランス語とオランダ語，スペイ ン語の共通表現を抽出し英語からただ 1 つのモデルで 3 言語に翻訳する研究もあ る [Dong et al., 2015]．また，これらを掛け合わせた画像説明文生成の領域では， 説明文の単語 1 つずつを生成する際に画像のどの部分に着目すべきかという表現 を抽出し，説明文を生成する研究 [Xu et al., 2015] もある．このように，深層学習 は多くの研究領域で大きな進展をもたらしている．
深層学習モデルを学習させるときには，大規模な訓練データが必要となる．深層 学習モデルの内部変数は非常に膨大で数十万や数百万以上となることも多く，膨 大な変数を学習させるためには，通常，大規模な訓練デーが必要である．例えば， 人間より高い精度で人の顔を見分けらると報告する顔認識の研究 [Schroﬀ et al., 2015] では，数百万人の 2 億枚以上の顔画像を訓練データに利用している．英語か らフランス語に翻訳する機械翻訳の研究 [Xu et al., 2015] では，1200 万もの文章 を訓練データとして利用している．
深層学習のネットワークには，いくつかの種類があるが，特に，画像処理に利用 される Convolutional Neural Networks [LeCun et al., 1998] というネットワークと 系列データの処理に利用される Recurreut Neural Networks [Williams and Zipser, 1989]（以下，RNN）というネットワークがよく利用される．ここでは，知識獲得 の予測に深層学習を用いた手法 [Piech et al., 2015] に用いられていたニューラル ネットワークである RNN について説明する．
近年，RNN はデータの大規模化や計算機性能の向上などにより幅広い領域の 系列データに対して適用されるようになった．具体的には，機械翻訳 [Sutskever

18

第 2 章 先行研究

19

et Rale.,c2u0r1r4e,nDt oNneguertaal lN.,e2t0w1o5]r，ks手  書き文字認識 [Graves and Schmidhuber, 2009, Lou系ra列do方u向r aにnd展K開erすmるorvとan系t,列20に14対]，し音て声多認層識で[静Hi的ntなonニetュaーl.,ラ20ル12ネ, Bッaトhdワanーauクeにt al., 2015]，ユーザログ解析 [Hidasi et al., 2015]，画像説明文生成 [Xu et al., 2015,
Vinyals et al., 2014]，医療診断 [Choi et al., 2015, Lipton et al., 2015] 等の領域で
高い性能を発揮することが報告されている．

出力層

隠れ層
入力層 時刻

t=1

t=2

t=T

図 2.4: RNN の構造のイメージ

伝統的な RNN の構造は図 2.4 のように，入力層，隠れ層，出力層の 3 層から構 成東さ京大れ学松て尾研い究室る 那．須野系薫 列方向を時刻とすれば，時刻 t の隠れ層 ht の計算に時2刻015年t7−月301日 の隠れ層の情報を入力する ht = f (xt, ht−1) の式ように，一つ前の情報を繰り返 し（recurrent）入力するという構造である．関数 f は，入力である xt や ht−1 をア フィン変換して足しあわせた後，活性化関数にかけるというものがよく利用され る．活性化関数はシグモイド関数や tanh（Hyperbolic Tangent 関数），Relu [Nair and Hinton, 2010]，ELUs [Clevert et al., 2015] など多く提案されており，通常，非 線形関数である．
RNN の 1 つの特徴として，効果的に長期的な表現を学習させることが難しいとい うことが挙げられる [Bengio et al., 1994]．RNN の学習には勾配法に基づいた確率的 勾配降下法 [Robbins and Monro, 1951, Kushner and Yin, 2003] や Adam [Kingma and Ba, 2014]，AdaDelta [Zeiler, 2012] など，さまざまな手法が利用可能である． しかし，いずれの勾配法を用いるにせよ，勾配が爆発して学習モデルが壊れてし まうという勾配爆発 [Bengio et al., 1994, Pascanu et al., 2013] という問題や，勾 配が消滅して対象データの長期的な特徴量を捉えることができないという勾配消 滅 [Pascanu et al., 2013, Hochreiter, 1998] という問題がしばしば発生する．これ

5

19

第 2 章 先行研究

20

は，ht = f (xt, ht−1) の式に表れるように同じ変換を繰り返し行うためであり，こ のため，特に，長い系列データを RNN で学習する場合，効果的に長期的な表現を 学習させることが難しい
こうした問題を解決もしくは緩和するため，ゲート付き活性化関数の利用や学習 時の勾配に制約を加える方法が提案されている．勾配消滅の緩和に対しては，ゲー ト付き活性化関数の利用が有効であるが，詳細は後述する．勾配爆発の緩和に対 しては，学習時の勾配に制約を加える方法が有効である．具体的には，[Mikolov, 2012] では学習させるパラメタの勾配の絶対値の最大値を予め決めておき，最大値 以上の場合には，勾配の最大値になるように勾配の値を置き換えることで勾配爆 発の影響を緩和する方法が報告された．また，[Pascanu et al., 2013] では学習さ せるパラメタの勾配のノルムの最大値を予め決めておき，最大値以上の場合には， ノルムが最大値以下になるように疑似コード 1 に従いノルムを抑制することで勾 配爆発の影響を緩和する方法が報告された．

Algorithm 1 勾配爆発を防ぐための勾配ノルム抑制の疑似コード

gˆ

←

δε δθ

if ∥gˆ∥ ≥ threshold then

gˆ

←

threshold ∥gˆ∥

gˆ

end if

先に，言及したが，RNN には異なる活性化関数を利用するという形でいくつか の種類がある．うまく設計された活性化関数を利用することで，データの長期的 な特徴をよく捉えられたり，計算コストを削減することができたりする．以降で は，よく研究報告で取り上げられる Simple RNN（以下，SRNN）[Williams and Zipser, 1989]，Long Short Term Momory RNN（以下，LSTM-RNN）[Hochreiter and Schmidhuber, 1997]，Gated Recurrent Neural Networks（以下，GRNN）[Cho et al., 2014] の 3 つについて詳細に説明する．

SRNN
SRNN はゲート付き活性化関数を用いない簡単な構造の RNN である．[Le et al., 2015, Krueger and Memisevic, 2015] で報告される工夫を取り入れることで，デー タの長期的な特徴を効果的に捉えることができるようになるが，多くの場合で，
20

第 2 章 先行研究

21

LSTM-RNN や GRNN のようにゲート付き活性化関数を用いる RNN の方がモデ ルの性能という点で優れている．
SRNN によるモデルの定式はいくつか種類が存在するが，シンプルなものは例 えば下記の式で定義される．

ht = tanh(Wxhxt + Whhht−1 + bh) yt = σ(Whyht + by)

(2.1) (2.2)

ここでは，t は時刻を指し，xt は時刻 t の入力ベクトルを指し，ht は時刻 t の隠れ層 を指し，yt は時刻 t+1 の各問題の正誤確率の予測値を指し，Wxh，Whh はそれぞれ 重み行列を指し，bh，by はそれぞれバイアス項を指し，tanh は (ex−e−x)/(ex+e−x) で定義される Hyperbolic Tangent 関数を指し，σ は 1/(1 + e−x) で定義されるシグ モイド関数を指す．訓練時には，重み行列 Wxh，Whh とバイアス項 bh，by を学 習する．

LSTM-RNN
LSTM-RNN は Long Short Term Memory という活性化関数を用いる RNN で， その名前の通り，SRNN では捉えることが難しかったデータの長期的表現と短期 的表現の両方の獲得を目的に開発されたものである [Hochreiter and Schmidhuber, 1997]．LSTM-RNN は SRNN と比較すると，モデルの性能という点で優れている が，内部のパラメタの数が非常に大きく学習コストは大きい．最先端の成果を報告 する研究でしばしば利用されているが，LSTM-RNN 自体が開発されたのは 1997 年であり LSTN-RNN が新しいというわけではない．
LSTM-RNN によるモデルの定式にはいくつか種類が存在するが，特に，後述す る Deep Knowledge Tracing [Piech et al., 2015] で用いられる LSTM-RNN は下記

21

第 2 章 先行研究

22

の式で定義される．

it = σ(Wxixt + Whiht−1 + bi) gt = σ(Wxgxt + Whght−1 + bg) ft = σ(Wxf xt + Whf ht−1 + bf ) ot = σ(Wxoxt + Whoht−1 + bo) mt = ft ⊙ mt−1 + it ⊙ gt ht = ot ⊙ mt yt = σ(Wmymt + by)

(2.3) (2.4) (2.5) (2.6) (2.7) (2.8) (2.9)

ここでは，it は Input Gate を指し，ft は Forget Gate を指し，gt はメモリセルへ の入力を指し，ot は Output Gate を指し，mt はメモリセルを指し，Wxi，Whi， Wxg，Whg，Wxf ，Whf ，Wxo，Who，Wmy はそれぞれ重み行列を指し，bi，bg， bf ，bo，by はそれぞれバイアス項を指し，⊙ は要素積を指す．
式 2.7 にあるように，メモリセルへの入力は 1 つ前のメモリセルの状態 mt−1 と 入力 gt であり，それぞれの入力に対して，過去のメモリセルからの情報を捨てる Forget Gate と現在からの情報を調整する Input Gate を作用させ，mt をえる．新 しい隠れ層 ht は式 2.8 のようにメモリセルからの出力を Output Gate で調整した ものを入力として受け取る．これらのゲートにより，長期的な特徴の短期的な特 徴が捉えられるとされている．

GRNN
GRNN は Gated Recurrent Unit [Cho et al., 2014] というゲート付き活性化関 数を用いる RNN のことで，GRU は LSTM のように，長期的な表現と短期的な 表現を捉えるために提案された活性化関数である．Cho ら [Cho et al., 2014] が 2014 年に発表して以来，GRNN 自体や GRNN の活用に関する研究が多く報告さ れている [Chung et al., 2014, Zaremba, 2015, Chung et al., 2015, Karpathy et al., 2015, Biswas et al., 2015, Pezeshki, 2015]．LSTM よりもゲートの数が少なく学習 コストが小さい傾向にあるが，LSTM-RNN，GRNN の性能を比較した研究 [Chung

22

第 2 章 先行研究

23

et al., 2014, Zaremba, 2015] において LSTM-RNN と GRNN が同程度の性能であ ることが報告されている．
GRNN は下記の式により定義される．

rt = σ(Wxrxt + Whrht−1 + br) zt = σ(Wxzxt + Whzht−1 + bz) h˜t = tanh(Wxhxt + Whh(rt ⊙ ht−1 + bh)) ht = zt ⊙ ht−1 + (1 − zt) ⊙ h˜t yt = σ(Whyht + by)

(2.10) (2.11) (2.12) (2.13) (2.14)

ここでは，Wxr, Whr, Wxz, Whz, Wxh, Whh は重み行列で，br, bz, bh はバイアス 項である．rt が Reset Gate(LSTM における Forget Gate に相当する機構) で，zt が Update Gate(LSTM におけるメモリセルに相当する機構) である．rt が 0 に近 いほど前の隠れ層からの入力よりも現在の入力をより強く考慮するようになり，zt が 0 に近いとほど前の隠れ層をより大きく更新するようになる．
以上，深層学習について述べた．次に，知識獲得の予測について述べる．

2.4 知識獲得の予測
知識獲得の予測は，学習者が対象の知識を獲得しているか否かを予測するとい うものである．通常，知識を獲得しているか否かは問題回答の正誤を基に評価され るため，知識獲得の予測のタスクは過去の学習者の問題回答履歴から次に解く問 題の正誤を予測するというものである．最初の定式化の事例は，1994 年に Corbett らによって報告された Knowledge Tracing [Corbett and Anderson, 1994] である． スキルの習熟学習において，領域知識をよく分析し階層的に知識間関係を構築し， 階層構造においてより水準の高い知識に着手する前に予め獲得するべき知識が確 実に獲得されるように学習体験を構造化することで，ほとんどの学習者がスキル を十分に習熟できるとする仮説 [Keller, 1968, Bloom, 1968] や，コンピュータサイ エンスの発展を受けて，予め獲得すべき知識が確実に獲得されるように学習者の 知識の獲得有無を予測するというのが主な目的であった．Knowledge Tracing にお
23

第 2 章 先行研究

24

ける学習者とモデルは，学習者が勉強し知識を獲得したら，モデルがそれを予測 することで学習者の知識を追跡する（Knowledge Tracing），という関係になって いる．
伝統的に，知識獲得の予測には知識獲得の時系列性を重視するものと，知識間の 関係性を重視するものがある．[Corbett and Anderson, 1994] で報告された Bayesian Knowledge Tracing という手法は知識獲得の時系列性を重視するもので，問題に予 めスキルを割り当て個々のスキルに習熟過程に関する 4 つの確率変数を定義しモ デル化するというもので，スキル間の関係性は考慮しないが，個々のスキルの習 熟，つまり時系列性を考慮する手法である．[Pavlik Jr et al., 2009] で報告された Performance Factor Analysis という手法は知識間の関係性を重視するもので，個々 の知識（あるいは，スキル）に関する過去の回答の正誤を重み付けして，次の問 題の正誤を予測しようというもので，Performance Factor Analysis は知識獲得の 時系列性より知識間の関係性を重視する手法である．いずれの手法も本論文と関 連が深い．
以降では，まず，Knowledge Tracing の定式化について述べ，Bayesian Knowledge Tracing と Performance Factor Analysis の 2 つの手法を説明し，最後に，深層学習 を活用した Deep Knowledge Tracing について説明する．

2.4.1 Knowledge Tracing の定式化
Knowledge Tracing は過去の学習者の問題回答履歴から学習者が次に解く問題の 正誤を予測するというものである．学習者の時刻 t において観測された問題回答結果 を qt とすれば，q1, q2, . . . , qt から時刻 t + 1 において観測される問題回答結果 qt+1 を 予測するタスクと表現できる．特に，過去の観測された問題の正誤から将来の正誤 確率を算出する場合は，q1, q2, . . . , qt が観測された場合の時刻 t+1 に着手する問題に おいて当該学習者の回答正解となる事後確率 p(qt+1 = correct|q1, q2, . . . , qt) を求め るタスクであるといえる．予測性能の評価は [Yudelson et al., 2013, FALAKMASIR et al., 2015] では Accuracy で，[Piech et al., 2015] では AUC で行っており，目的 に応じてさまざまである．
なお，モデルの入力次元である問題の粒度はさまざまである．問題はその問題
24

第 2 章 先行研究

25

を回答するのに必要な知識を学習者が獲得しているか否かを評価するという点で， 問題は知識集合を表現していて，また，その粒度もさまざまである．個々の問題 をそのままモデルの入力次元とするものや，問題に予めタグを割り当て問題によ り評価される知識の粒度をある程度整え，そのタグをモデルの入力次元とするこ ともある．例えば，[Piech et al., 2015] ではモデルの入力次元は演習タグもしくは スキルタグと呼ばれるものであり，演習問題に割り当てられ，それぞれの演習問 題で扱われる学習要素を説明するものである．通常，こうしたタグは専門家によっ て設計され，利用される．本論文では個々の問題をそのままモデルの入力次元と して用いる．

2.4.2 Bayesian Knowledge Tracing
Bayesian Knowledge Tracing [Corbett and Anderson, 1994]（以下，BKT）はベイ ズの定理の事前確率と事後確率の関係に基づいて正解確率 p(qt+1 = correct|q1, q2, . . . , qt) をモデリングする手法である．BKT には 4 つの確率変数がある．1 つは，初めか ら当該スキル理解している確率 p(L0)（もしくは p-init），1 つは，学習者が当該 スキルを理解していない状態から理解している状態へ遷移する確率 p(T )（もしく は p-transit），1 つは，学習者が当該スキルを理解しているが誤答する確率 p(S) （もしくは p-slip），1 つは，学習者が当該スキルを理解していないが推測で正解 する確率 p(G)（もしくは p-guess）で，これらの 4 つの確率変数がすべてのスキ ルに定義されている．つまり，スキル数を N とすれば，確率変数の合計数は 4N である．学習者 u がスキル k の問題を時刻 t に解いた場合に正解する確率は下記の 式に基づいて更新される．

25

第 2 章 先行研究

26

p(L1)ku = p(L0)k

(2.15)

p(Lt|obs = correct)uk

=

p(Lt−1)ku · (1 − p(S)k) p(Lt−1)uk · (1 − p(S)k) + (1 − p(Lt−1)uk) · p(G)k

(2.16)

p(Lt|obs = wrong)uk

=

p(Lt−1)ku · p(S)k p(Lt−1)uk · p(S)k + (1 − p(Lt−1)uk) · (1 − p(G)k)

(2.17)

p(Lt)ku = p(Lt|obs)ku + (1 − p(Lt|obs)ku) · p(T )k

(2.18)

p(Ct)uk = p(Lt−1)ku · (1 − p(S)k) + (1 − p(Lt−1)ku) · p(G)k (2.19)

右上の k はスキル番号を示し，右下の u はユーザ番号を示すことに注意された い．まず，学習者 u が初めから当該スキル k を身につけている確率は式 2.15 の通 り定義する．正解が観測され，正しく当該スキルを身につけている確率は，式 2.16 で与えられ，不正解が観測されたが，正しく当該スキルを身につけている確率は， 式 2.17 で与えられ，それらを合わせて，次の時刻に当該スキルを身につけている 確率は，式 2.18 で与えられる．このように定めることで，理解しているがうっか り間違ってしまう場合や， 理解していないがあてずっぽうで正解してしまう場合 を考慮できる．なお当該モデルでは，身につけたスキルの忘却は無視している．最 後に，学習者 u がスキル k の問題を時刻 t に解いた場合に正解する確率 p(Ct)ku は 式 2.19 のように算出され，この値を次の問題の正誤予測に利用する．
上記に説明したモデルの学習にはいくつかの方法が適用され報告されている． 1 つは [Corbett and Anderson, 1994] にあるように HMM を用いて生成モデルと して学習させる方法であり，1 つは [Yudelson et al., 2013] にあるように勾配法を 用いて識別モデルとして学習させる方法である．それぞれ長所と短所があるが， 特に，大規模データへの適用という観点では HMM に基づいた生成モデルの手 法では計算量が大きく学習に非常に多くの時間がかかってしまうということもあ り，[Yudelson et al., 2013] では勾配法に基づいた識別モデルとして学習させてい る．具体的には，[Yudelson et al., 2013] では，目的関数に負の対数尤度（Negative Log Likelihood）を利用し，勾配降下法（Gradient Descent）で学習させている．

26

第 2 章 先行研究

27

2.4.3 Performance Factor Analysis

Performance Factor Analysis [Pavlik Jr et al., 2009]（以下，PFA）も過去の学 習者の問題回答履歴から学習者が次に解く問題の正誤を予測するための手法であ る．しかし，知識獲得の時系列性を考慮する BKT と異なり，知識獲得の順番を考 慮せず知識間の関係性を考慮して予測する手法である．PFA は下記のように定義 される．

∑

p(i, j ∈ KCs, s, f ) = σ(βj +

(γksi,k + ρkfi,k))

k∈KCs

(2.20)

ここでは，s は事前に正答した問題回答，f は事前に誤答した問題回答，p はユー ザ i が知識 j に正答する確率，βj は知識 j の簡単さ，γk と ρk はそれぞれ知識 k の 正答と誤答の重み，si,k と fi,k はそれぞれユーザ i が知識 k に事前に正答した問題 回答，事前に誤答した問題回答である．σ はシグモイド関数，過去の各知識の正 誤を重み付けしシグモイド関数にかけ，別の問題の正誤を予測するというもので ある．
PFA は知識間の関係性を考慮できない場合に複数の知識がないと獲得できない 知識のモデルが難しいという Bayesian Knowledge Tracing やその拡張手法の問題 を解決するために提案された．PFA は知識間の関係性を重み付けして考慮してい るが，問題回答の順番は考慮しない．

2.4.4 Deep Knowledge Tracing
Deep Knowledge Tracing [Piech et al., 2015]（以下，DKT）は RNN を利用し Knowledge Tracing を行う手法である．2015 年 6 月に発表された．数学の問題回 答ログのデータセットで実験され，高い性能で将来の知識獲得を予測できること， 予測モデルを分析することで知識間関係をネットワークとして抽出できることが 報告された．学習者が獲得している知識から，ある知識の獲得されやすさをその まま予測しており，得られた知識間関係から抽出されたネットワークは知識獲得 における知識構造を表現しているといえる．DKT の構造と最適化，および知識間 関係の抽出手法について順に説明していく．
27

第 2 章 先行研究

28

構造
まず，DKT の構造について述べる．DKT の構造は伝統的な RNN の構造に基づ いている．伝統的な RNN は入力のベクトル系列 x1, . . . , xT を出力のベクトル系列 y1, . . . , yT に写像する．この写像は，隠れ状態 h1, . . . , hT を計算することで達成さ れるが，一連の写像の過程で過去観測から得られる関連情報を将来予測のために 連続的に符号化している，とみなせる．確率変数は下記の式で定義されるネット ワークにより関連付けられる．

ht = f (xt, ht−1) yt = g(ht)

(2.21) (2.22)

モデルは関数 f と g によって定義されており，これらの関数 f, g には SRNN の式 2.1，2.2 や LSTM-RNN の式 2.3–2.9，GRNN の式 2.10–2.14 を利用できる．
RNN で学習者の学習行動の観測結果をモデリングするため観測結果を固定長の 入力ベクトル xt の系列に変換する必要があるが，DKT ではシンプルな変換を行っ ている．具体的には，学習者の学習行動の観測結果を one-hot ベクトルに符号化し xt とする，というものである．観測結果は演習問題と正誤の組み合わせで表現で きるため，演習問題の数を M とすれば，xt の長さは 2M となる．

表 2.1: Deep Knowledge Tracing における回答ログデータと対応する入力ベクト ルの例

回答ログ

入力ベクトル

ユーザ ID ログの順番 問題番号 正誤 変数名

値

A 1 1 0 x1 [0000...1000] A 2 1 1 x2 [1000...0000]

A 3 2 1 x3 [0100...0000] A 4 3 0 x4 [0000...0010] A 5 3 1 x5 [0010...0000]

A 6 4 1 x6 [0001...0000]

具体例を交えて説明する．例えば，演習問題の数が 4 つで，問題回答は 1 つず 28

第 2 章 先行研究

29

つしかできないと仮定する ．M = 4 であり，xt の長さは 8 である．ある学習者 が，表 2.1 の回答ログように問題を回答し正誤が観測されたとする．この時に，例 えば，表 2.1 に記載のような入力ベクトルの系列となる．このようにして，回答行 動の観測結果を符号化することで，どの演習問題をいつ正解もしくは不正解した のかを RNN に入力できる．
出力 yt は問題と同じ長さのベクトルで，それぞれの要素が当該学習者がそれぞ れの問題に正しく回答する確率の予測値となっている．したがって，t + 1 の回答 qt+1 の正誤予測は t + 1 に回答される問題 qt+1 に対応する yt の要素から読み取れる．

最適化

次に，DKT の最適化について述べる．訓練時に用いられる目的関数は，モデル において学習者の回答行動の観測系列の負の対数有度（Negative Log Likelihood） である．δ(qt+1) を時刻 t + 1 にどの問題が回答されたかの one-hot ベクトルとし， at+1 を時刻 t + 1 に当該問題で正答したか否か（1 か 0）とし，l をクロスエントロ ピーとすれば，当該予測結果に対するロス関数は l(yT δ(qt+1), at+1) であり，学習 者一人のロスは下記の式で与えられる．

∑

L=

l(ytT δ(qt+1), at+1)

t

(2.23)

学習時はミニバッチごとに確率的勾配降下法で目的関数を最小化する．[Piech et al., 2015] では，モデル学習時には過学習を防ぐため yt への入力としての ht に は dropout [Srivastava et al., 2014] を適用している（ht+1 の方向には dropout を 適用しない）．また，系列方向の誤差逆伝搬 [Werbos, 1990] において勾配が爆発 するのを防ぐため，閾値以上のノルムの勾配は [Pascanu et al., 2013] にしたがい， 制約を設けている．

知識間関係抽出法
次に，DKT のモデルを利用した知識間関係（あるいは，問題間関係）抽出法に ついて述べる．DKT のモデルは，従来ではよく人間の専門家が行っていたデータ の潜在的な構造や概念を発見するタスクに応用できる．問題 i と j のすべての有向
29

第 2 章 先行研究

30

ペアのうち下記の条件を満たすものに対して下記の影響度 Jij を割り当てる．

条件 有効ペア (i, j) について，問題 i が出現した後に残りの問題系列の中で問題 j が出現する系列数が問題 i が出現する問題系列数全体の V % 以上であること．

影響度

Jij

=

∑y(j|i) k y(j|k)

ここでは，y(j|i) は，ある学習者が最初に問題 i に正答した場合に，RNN によっ て割り当てられる次の時刻に問題 j に正答する確率である．[Piech et al., 2015] で は，問題間影響行列からのネットワーク抽出には，V = 1 を用いた．また，ネット ワークの可視化に際しては，影響度が 0.1 以上であればエッジを引くというように してネットワークを構築した．
さらに，[Piech et al., 2015] は，得られたネットワークは，単に学習者の問題 (i, j) 間の遷移率から構築したネットワークや問題 i の正解が観測された後に問題 j の正解が観測される条件付き確率から構築したネットワークよりよく知識間関係 を捉えていることを指摘している．
こうして得られた行列 J は，問題 i で評価される知識が既に獲得されている場 合に，問題 j で評価される知識の獲得されやすさを表現しており，J は知識間関係 行列であるといえ，この知識間関係行列から構築したネットワークは知識獲得に おける知識構造を表現していると考えられる．
以上，知識獲得の予測について述べた．次に，ネットワーク分析について述べる．
2.5 ネットワーク分析
ネットワーク分析は現実世界に存在するさまざまな複雑なネットワークの特徴 を明らかにするための分析である．従来，ネットワーク分析は社会の信頼関係や 社会規範といった社会関係資本を分析するために用いられており，社会学の研究
30

第 2 章 先行研究

31

領域であった [Putnam, 1993, Coleman and Coleman, 1994] が，ウェブやそれを活 用するソーシャルメディアの普及に伴い注目が高まり，ウェブページやユーザを 分析するためにしばしば用いられるようになった．事例として，ウェブページ検 索エンジンの性能向上のためウェブページの重要度を評価するページランクとい う指標を報告した研究 [Page et al., 1999] や生物学における論文の共著ネットワー クの構造を分析する研究 [Sun et al., 2011]，ソーシャルメディアにおけるユーザ 間の関係性から友人関係を推定し友人推薦に活用しようとする研究 [Dong et al., 2012] 等がある．
ネットワーク分析の対象となるネットワークには，予め明示的に対象間の関係 がネットワークとして与えられているもの（Explicit Networks）と，明示的には 与えられておらず対象間の類似性や関係性の強度からネットワークを構築し利用 するもの（Implicit Networks）がある．例えば，ウェブページのハイパーリンクに よる関係，ソーシャルメディアの友人関係，論文の共著関係が Explicit Networks に該当する．ネットワーク上でエッジとして表現されたこれらの関係はそれぞれ ウェブページ同士を友人同士を著者同士の明示的な関係を表している．一方で，明 示的ではない関係を分析する場合は，対象間の類似性や関係性の強度を表す行列 に基づいて閾値以上の強度の対象間にエッジを張るという方法や，各対象から一 定数のエッジを強度の大きい対象間に引いていく方法で，ネットワークを構築し， そのネットワークを対象にネットワーク分析を行う．例えば，説明文の語の共起の 類似性を表現する行列から説明対象のネットワークを構築するもの [Buzydlowski et al., 2002] や，知識間関係の影響度行列からネットワークを構築する [Piech et al., 2015] が該当する．
ネットワーク構造を評価する指標は多くのものが存在する．ネットワークにお ける個々のノードやエッジの特徴を分析する指標として，中心度という点でノー ドを評価するノードの媒介中心性やノードの次数中心性，経路における中心度と いう点でエッジを評価するエッジの媒介中心性などがある．ノードの媒介中心性 とは，当該ノードを通る経路数で表現され，ノードの次数中心性とは当該ノード に接続しているエッジ数で表現され，エッジの媒介中心性は当該エッジがノード の組の最短パスに含まれている割合で表現される．また，ネットワークの構造を 捉えるための指標も開発されており，例えば，ネットワークのクラスタへの分割

31

第 2 章 先行研究

32

におけるモジュール性を評価するモジュラリティという指標 [Newman, 2006] や 階層性を評価するフロー階層という指標 [Luo and Magee, 2011] や GRC という指 標 [Mones et al., 2012]，等がある．

∑

M odularity =

(eii− ai2)

i

(2.24)

モジュラリティは式 2.24 で与えられる．ここでは，eii はクラスタの隣接行列の (i, i) 成分を，ai は隣接行列の i 行の和を示す．この指標はクラスタ内のエッジ割 合とクラスタ間のエッジ割合の差を表現した指標だといえる．

F lowHierarchy

=

∑L
i=1

ei

L

(2.25)

フロー階層は式 2.25 で与えられる．ここでは，L はネットワークに含まれるエッ ジの数を，ei はエッジ i が環状構造に含まれていたら ei = 0 でそれ以外は ei = 1 となるような指標を示す．この指標は階層性を，環状構造がない，という側面か ら捉えようとした指標だといえる．
また，[Luo and Magee, 2011] では，サンプルネットワークに適用した結果につ いても紹介しており，図 2.5 における (A, B, C, D, E) に対するフロー階層の値は (1, 1, 1, 0.40, 0.67) であったという．このことからも，フロー階層が環状構造がな い方が指標の値が高くなり，したがって，ネットワークの階層性をを表現できる 指標であることを確認していた．

GRC

=

∑
i∈V

[CRmax

−

CR(i)]

N −1

(2.26)

GRC は Global Reaching Centrality のことで，式 2.26 で与えられる．ここでは， CR(i) が Local Reaching Centrality という指標を，V はネットワークに含まれる ノードの集合を，CRmax は V に含まれる全ノード i について CR(i) の最大値を，N は V の大きさであるノード数を示す．CR(i) はノード i から出力されるエッジを

32

第 2 章 先行研究

33

A) Pure Tree: regular link

B) Mixed Tree: regular link

C) Mixed Tree: level-skipping or in-layer link

D) Layers: in-layer link

E) Cycles: backward link

図 2.5: フロー階層の適用事例
辿って，ノード i から到達できるノードの割合を指す．GRC = 1 の場合，Local Reaching Centrality が 0 でないノードがたかだか 1 つしか存在せず，したがって， 当該ネットワークはスター状のネットワークということになる．この指標は階層 性を一部のノードが他のノードより到達できるノードが多い構造にある，という 側面から捉えようとして指標だと言える．
以上，先行研究について述べた．次に，分析手法について述べる．

9

33

第3章 分析手法
本章では，宣言的知識と手続き的知識の知識獲得における知識構造の違いを分 析するための手法について説明する．まず，分析手法全体の流れを概説し，手法全 体が 3 つのブロックから構成されることを述べる．その後，まず，既存の知識間関 係の抽出手法の中で，Deep Knowledge Tracing が最適であることを説明する．次 に，分析対象の問題回答ログデータについて要件があることを述べ，その要件と して，比較検証できる複数のデータセットを作成できること，各データセットが 大規模であること，初等中等教育水準の数学や地理，歴史に関する科目であるこ と，について説明する．最後に，抽出した知識間関係ネットワークのモジュール 性と階層性を評価するために，ネットワーク構造指標の中でもモジュラリティと フロー階層および GRC を用いること，また，これらの各指標について，宣言的知 識によるネットワークと手続き的知識によるネットワーク間で有意差検定を実施 し，構造の違いを検証することを述べる．
まず，分析手法全体の流れを説明する．手法全体の流れを図 3.1 に示す．手法は データセットの作成，知識間関係行列の算出，ネットワーク構築及び有意差検定 の 3 つのブロックから構成される．本論文では，学習者の知識獲得について分析 を行うが，学習者が知識を獲得しているか否かを評価するためには，通常，その 学習者の問題への回答を評価する．問題への回答結果は，その問題によって評価 される知識を学習者が既に獲得しているか否かを表現しており，回答結果が正解 であれば，その問題によって評価される知識を既に獲得しており，回答結果が不 正解であれば，その問題によって評価される知識は未だ獲得していないと評価で きる．したがって，分析では，問題回答ログデータを対象データに用いる．
問題回答ログデータからデータセットを作成するわけだが，データセットは比 較検証に用いるため，知識獲得の予測に利用できる複数のデータセットを作成す る．また，データは問題回答ログであれば何でもいいというわけではなく，いく
34

第 4 章 分析手法

35

データセット作成

知識間関係行列の算出

問題回答 ログデータ

ユーザ：問題：正誤  X.XX.. XXXXユXX..XXX. XXXX.ユXー.：：：.XXX XXーザ：：：XXXXXザXXX：：：XXXXXX：XXX問XX：：：XXXXX問題：：：XXXXX題：XXX：：XXXXXX：正XXXXX  XXX正XX誤  XX誤     
XXX：XXX：XXX 宣言的知識に関するデータ
XX.Xユ.. XXXーX.XXユ.XXX. XXXユXX.ザー.：：：.XXX XXー：ザXXX：：：XXザXXX：問：：XXXXXX：XXX問題XX：：：XXXXX問題：：X：X：XXX題：正XXX：：XXXXXX：誤正XXXXX  XXX正XX誤    XX誤      XXX：XXX：XXX
手続き的知識に関するデータ

ネットワーク構築+有意差検定

図 3.1: 分析手法全体の流れ
つかの要件を満たすものを利用する．その要件については，後述する． そして，作成した複数のデータセットに知識獲得における知識間関係を抽出で
きる手法を適用し知識間関係行列を算出する．また，知識間関係を抽出する手法 も特に Deep Knowledge Tracing が最適であるが，その理由について後で詳細に述 べる．
最後に，行列として定義された知識間関係からネットワークを構築し，ネット ワークのモジュール性や階層性を表現する指標について有意差検定を実施し，宣 言的知識の知識構造と手続き的知識の知識構造の階層性やモジュール性に有意に 差があることを検証する．
以上が，分析手法全体の流れである．以降では，知識獲得における知識間関係 の抽出，データセットに利用できるデータの要件，知識間関係ネットワーク構築 とその構造評価を順に説明していく．

35

第 4 章 分析手法

36

3.1 知識獲得における知識間関係の抽出
これまでの知識間関係を抽出する手法のなかでも，Deep Knowledge Tracing（以 下，DKT）が最適であること説明する．まず，知識間関係を抽出する手法として は，過去に獲得した知識から知識獲得を予測する過程で行うものと，そうでない ものがある．後者については，専門家が作成するという手法や，テキスト解析よ り概念関係ネットワークを構築するという手法 [Chen et al., 2008] がある．しか し，これらはどちらかといえば，専門家や研究者の「こういう関係になっている はずだ」という仮説に基づいたものであり，必ずしも知識獲得における知識と知 識の関係を表現しているわけではなく，また，本研究はそうした背後にある仮説 を検証しようというものであるため，こうした手法の利用は本末転倒である．一 方で，過去に獲得した知識から知識獲得を予測する過程で行うものは，学習者が 既に獲得している知識を基にある知識が獲得されやすいかを予測しているという 点で，学習者の知識獲得における知識間関係を表している可能性が高い．したがっ て，知識間関係を抽出する手法としては，過去に獲得した知識から知識獲得を予 測する過程で知識間関係を抽出する手法に絞る．
次に，知識間関係の抽出を，過去に獲得した知識から知識獲得を予測する過程で 行う手法として，先行研究の説明において，Performance Factor Analysis（以下， PFA）と DKT について述べた．いずれの手法も知識間関係を考慮して予測に利用 しているが，DKT の方が有効性が高いと考える．なぜなら，[Piech et al., 2015] で は言及されていなかったが，DKT は PFA の拡張になっているためである．DKT は RNN を利用しており，

ht = f (xt, ht−1) pt = σ(ht−1 · Whp + bp)

(3.1) (3.2)

で与えられる．一方で PFA は

∑

p(i, j ∈ KCs, s, f ) = σ(βj +

(γksi,k + ρkfi,k))

k∈KCs

(3.3)

36

第 4 章 分析手法

37

で与えられる．したがって，

f (xt, ht−1) = xt + ht−1 h0 = [0, 0, · · · , 0]

(3.4) (3.5)

とすると，ht がこれまでの各問題についての正答回数を表現するベクトルと各問題 についての誤答回数を表現するベクトルを結合したベクトルになるが，これは，ベ クトル s と f を結合したものと同じである．したがって，PFA は DKT 内部の RNN の繰り返しの部分を表現する関数 f を式 3.4 にした特殊なケースであり，DKT は PFA の拡張になっている．したがって，PFA より DKT の方がより適している．逆 に，DKT を利用するということを考えた時に，[Piech et al., 2015] で，既に知識 間関係を抽出できることが報告されているため，DKT を利用することが最適であ ると考えられる．

3.2 データの要件
データセットは問題回答ログデータから作成するが，問題回答ログデータは，特 に，下記の要件を満たすものが適切である．1) 比較検証できる複数のデータセッ トを作成できること，2) 各データセットが大規模であること，さらに，3) 初等中 等教育水準の数学，地理，歴史に関する問題回答ログであること，の 3 つである．
まず，比較検証できる複数のデータセットを作成できることが必要であること について述べる．本論文では，宣言的知識と手続き的知識の知識獲得における知 識構造を比較するが，そのためには，宣言的知識と手続き的知識それぞれ複数の ネットワークで比較検証できた方がいい．逆に，1 つずつを比較しただけでは，想 定していなかったデータセットの特徴やノイズの影響を受け必ずしもよく検証で きたとは言えないからである．したがって，データは，複数の宣言的知識あるい は手続き的知識の獲得を主目的とする問題回答ログのデータセットを作成できる ものであることが必要である．
次に，各データセットが大規模であることが必要であることに説明する．深層学 習モデルを十分学習させるためには，大規模なデータが必要である．これは，RNN を活用する Deep Knowledge Tracing についても同様である [Piech et al., 2015]．
37

第 4 章 分析手法

38

したがって，作成した複数の問題回答ログのデータセットはいずれも大規模であ る必要がある．実際には，十分学習させるだけのデータセットが得られているか は実験を通して構築した予測モデルの性能を評価して判断できることであるため， 既存研究のデータセットを目安にできるだけ大規模な問題回答ログデータを利用 し，実験にて深層学習が有効であったかを確認する．
最後に，初等中等教育水準の数学や地理，歴史に関する問題回答ログであるこ とが重要であることについて述べる．本論文では，宣言的知識と手続き的知識の 知識獲得における知識構造を比較するが，そのためには，複数のデータセットが 特に宣言的知識あるいは手続き的知識の獲得を主目的とするように偏りが大きい ことが必要である．この要件に合致するデータについて，科目と難易度という 2 軸 で整理する．
まず，科目について，従来より，数学やプログラミング等の問題はその多くが 手続き的知識の獲得しているか否かを評価するものとされたおり，どちらかとい えば，手続き的知識の獲得を主目的とするといえる．一方で，しばしば暗記科目 と呼ばれるような地理や歴史等の問題はその多くがある特定の地域の過去の出来 事の事実について知識を扱っており，どちらかといえば，宣言的知識の獲得を主 目的としていると考えられる．
次に，難易度について，科目が同じでも難易度が変わると知識の獲得のされ方 も変わってくる．歴史を例に挙げて説明する．歴史について学ぶ時に，難易度が 低い時は，例えば「江戸幕府を築いたのは誰か．」や「江戸時代の次は何時代か．」 という問題では，特に事実に関する知識を獲得するのが中心である．一方で，難 易度が高い時は，例えば「なぜ，徳川家康は江戸幕府を築けたのかを文章で説明 せよ．」や「江戸時代と明治時代についてまとめよ．」という問題であれば，この問 題を解くためには，単に歴史的な事実を知っているということだけでなくそれら を伝わる形式に構造化したり，分からない内容を推論したりする作業が必要であ ろう．
簡単に言うと，科目が同じでも難しい問題はいろいろなことを知っていて，分 かりやすく伝える練習をしていないと正解できないということである．知識構造 という点では，科目が同じでも難易度が高いと，目的志向の知識である手続き的 知識の有無が問題回答の正誤に影響を与える可能性が高く，知識構造もより階層

38

第 4 章 分析手法

39

的になる可能性が高い．したがって，例えば，Coursera のように大学水準の内容 を扱う MOOCs における問題回答ログデータはあまり適していないと推察される．
科目と難易度の整理を踏まえると，難易度が高すぎないこと，また，その範囲 内で数学やプログラミング等の手続き的知識の獲得を主目的とする科目，地理や 歴史などの宣言的知識の獲得を主目的とする科目であること，は要件に合致する データであると考えられる．逆に難易度が高すぎないものでかつ，大規模データ が利用できるとなると，数学や地理，歴史のように公教育に導入されており，よ く学習されているものに限られてくると推察される．
これらの 3 つの要件が満たされていた時に，Deep Knowledge Tracing のモデル を十分学習させることで知識獲得における知識間関係を複数のデータセットから 抽出することができ，また，抽出した知識間関係を宣言的知識と手続き的知識の 対比において比較することができる．
こうした要件に合致するを可能があるデータとしては特に，初等中等教育水準 の MOOCs の問題回答ログデータがある．初等中等教育水準の MOOCs であれば， 算数や数学，地理や歴史の科目の講座が存在し，かつ，それらが難しすぎない可 能性が高く，また，MOOCs では非常に多くの学習者が利用しているため，多くの 問題回答ログデータが収集できる可能性が高い．

3.3 知識間関係ネットワークの構造評価
Deep Knowlege Tracing より抽出した知識間関係を分析するために，知識間関係 からネットワークを構築する方法を述べ，その構造におけるモジュール性と階層 性を評価し違いを明らかにするために，ネットワーク分析指標の中でもモジュラ リティとフロー階層，GRC が用いること，また，各データセットから構築した知 識間関係ネットワークの指標について，宣言的知識および手続き的知識のネット ワーク集合間で有意差検定を実施することを説明する．
まず，ネットワーク構築法について述べる．知識構造はネットワークとして明 示的に与えられておらず行列として与えられており，ネットワークを構築する必 要があるためである．構築方法には，知識間の影響度に基づいて閾値以上の強度 の知識間にエッジを張るという方法や，各知識から一定数のエッジを影響度の大
39

第 4 章 分析手法

40

きい知識間に引いていく方法がある．前者は [Piech et al., 2015] で用いられてい た方法であるが，ここでは，後者の方法を用いる．具体的には，問題 j への影響 度の大きい問題群 i ̸= j を Jij が大きいものから M 個選択し，i から j にエッジを 引く，という方法である．各問題が扱う知識の獲得にどの知識が有効かの関係抽 出に際して，議論の焦点は，ネットワーク全体における近さ（グローバルな関係） というよりは各問題間の近さ（ローカルな関係）であり，知識結合という局所的 な関係から構築したネットワークの方が，どちらかといえば，よく知識構造を表 現していると考えられるからである．ここでは，M = 3 とし，つまり，構築する ネットワークは 1 つの問題に対して 3 つの問題からエッジが入力される有向グラ フである．
次に，ネットワーク構造におけるモジュール性と階層性の評価に，ネットワー ク分析指標の中でもモジュラリティとフロー階層，GRC が有効でありそれらを用 いること説明する．本論文では，知識構造を表現するネットワークのモジュール 性と階層性を分析するが，ここでいう知識構造のモジュール性とは，特に，ある 知識を予め獲得しているか否かが他の知識獲得に及ぼす影響が小さくなるように 知識が構造化されている度合いのことであり，また，知識構造の階層性とは，そ の獲得が順序付けられるように知識が構造化されている度合いのことである．
これらのモジュール性と階層性の評価には先行研究の説明の際に紹介したモジュ ラリティやフロー階層，GRC が有効である．まず，モジュール性について述べる． 例えば，縄文時代に関する知識と江戸時代に関する知識はそれぞれ時代における 知識間（石器と土器，江戸幕府と徳川家康等）は相互に関連しあっている可能性 が高いと考えられる．一方で，時代をまたいだ知識間（石器と江戸幕府，土器と 徳川家康等）の影響は弱いと考えられる．ネットワークに存在するエッジの数が 一定の場合，モジュール性は適当に分割した知識集合（江戸時代に関する知識集 合）内でのエッジが多く，逆に知識集合間（縄文時代に関する知識と江戸時代に 関する知識）のエッジが少ない度合いのことであるが，これは，式 2.24 で表現さ れるモジュラリティと同じである．したがって，モジュラリティは知識構造のモ ジュール性の表現に有効であると考えられる．
次に，階層性について述べる．例えば，1 次方程式を解く知識と 2 次方程式を解 く知識の 2 つの知識においては，先に 1 次方程式を解くためのさまざまな知識が

40

第 4 章 分析手法

41

獲得され，その後，2 次方程式を解く知識が獲得される，というようにその獲得が 順序付けられていると考えられる．この関係性をネットワークにした場合，1 次方 程式を解く知識ノードと 2 次方程式を解く知識ノードによる環状構造がなく，1 次 方程式を解く知識ノードからエッジを辿ることで 2 次方程式を解く知識ノードに 到達できるが，その逆はできないネットワークとなっているはずである．したがっ て，環状構造の少なさを評価するフロー階層や一部のノードが他のノードより到 達できるノードが多い度合いを評価する GRC は知識構造における階層性の一部を 表現できる可能性がある．そこで，階層性の評価については，フロー階層と GRC の 2 つを用いる．
最後に，各データセットから構築した知識間関係ネットワークの指標について， 宣言的知識および手続き的知識のネットワーク集合間で t 検定を実施することを説 明する．本研究の目的は知識獲得における知識構造を，宣言的知識と手続き的知 識を対比し，知識獲得における宣言的知識の知識構造の方が手続き的知識の知識 構造よりもモジュール性が高く逆に，知識獲得における手続き的知識の知識構造 の方が宣言的知識の知識構造よりも階層性が高いことを検証することである．こ れを達成するために 3 つのネットワーク構造指標の平均が宣言的知識の知識構造 と手続き的知識の知識構造の間で異なることを示す．そのため独立した 2 集合へ の t 検定により 3 つのネットワーク構造指標の平均それぞれにおいて統計的に有意 差があることを検証する．
以上，分析手法について述べた．次章では，実験で利用するデータセットにつ いて述べる．

41

第4 章 データセット
本章では，実験で用いるデータセットについて述べる．データセットは，小学 4 年生から中学 3 年生を対象とする国内最大級の MOOCs「勉強サプリ 1」で提供さ れる 11 の講座の問題回答ログデータから作成する 2．まず，勉強サプリから収集 されたログデータが分析に利用するためのデータ要件を満たした本分析に最適な データであることを述べる．次に，実験で用いる宣言的知識の獲得を主目的とす るデータセットと手続き的知識の獲得を主目的とするデータセットの作成につい て述べる．特に，歴史や地理に関する講座の問題が主に宣言的知識の獲得の有無 を評価する問題であることを指摘し，歴史や地理に関する 5 講座から宣言的知識 の獲得を主目的とするデータセットとして 5 つのデータセットを作成する．また， 算数や数学に関する講座の問題が主に手続き的知識の獲得の有無を評価する問題 であることを指摘し，算数や数学に関する 6 講座から手続き的知識の獲得を主目 的とするデータセットとして 6 つのデータセットを作成する．
4.1 勉強サプリ
ここでは，勉強サプリより収集された問題回答ログデータが本分析に最適なデー タであることを述べるため，まず，勉強サプリについて説明する．勉強サプリは 主に小学 4 年生から中学 3 年生を対象とした国内最大級の大規模オンライン講座 である．リクルートマーケティング (株) が運営している．サービスは 2015 年に開 始された．学習者はオンライン上で問題回答形式によるドリル演習や動画視聴形 式による授業聴講を通して勉強する．小学生には各学年ごとに国語，社会，算数， 理科の 4 科目が，中学生には各学年ごとに国語，数学，英語の 3 科目と学年共通で
1https://benkyosapuri.jp/ 2本論文の研究は勉強サプリを運営するリクルートマーケティング (株) との共同研究プロジェ クトの一環で行われている．
42

第 4 章 データセット

43

地理，歴史，公民，理科 1，理科 2 の 5 科目が提供されており合計 26 の講座が提 供されている．無料で利用できるコンテンツもある．
勉強サプリは提供教材，利用者数，学習行動ログ数の点でサービスの規模が非 常に大きい．4,000 以上の授業動画と 7,000 近い演習問題を提供しており，サービ ス開始から 1 年経たずして，利用者は 5 万人以上おり，講義視聴ログ数は 100 万以 上，問題回答ログ数は総計で 1,000 万以上である 3．

図 4.1: 勉強サプリのマイページ

図 4.2: 勉強サプリの講義一覧ページ

図 4.3: 勉強サプリの講義視聴ページ

図 4.4: 勉強サプリの問題演習ページ

サービスの具体を利用画面を交えて説明する．図 4.1，4.2，4.3，4.4 にページの イメージを記載する．図 4.1 はログイン後のマイページを示している．学習に関す
32015 年 11 月 31 日時点．
43

第 4 章 データセット

44

るコンテンツだけでなく，利用継続性の向上を狙って，ポイントというシステム やサプモン（勉強サプリのモンスター）というアバターを用いたゲームを大きく 表示している．図 4.2 は中学 1 年向け数学の講義一覧ページを示している．ユーザ は講義視聴のドリル演習の両方あるいはどちらかを勉強できる．図 4.3 は講義視聴 ページを示している．講義視聴ページは視聴しやすいように細かく分割されてい る．図 4.4 は問題演習ページを示している．問題演習はテスト形式で提供されて おり，一度に複数の問題が提供され，また，その採点も同時に行われる．この問 題回答から収集されるログデータの仕様は同時に 1 つの問題しか回答ログが入ら ないという Deep Knowledge Tracing で想定されている設定と異なるため，Deep Knowledge Tracing を拡張する必要があるが，その拡張法については実験説明の際 に合わせて述べる．
現在の学習指導要領 [文部科学省, 2011] によると，小学 4 年生の社会では社会基 盤や地域社会など地理に近い内容を扱い，小学 5 年生の社会では地域の山地山脈, 気候など地理に近い内容を扱い，小学 6 年生の社会では日本の歴史に関する内容を 扱うとしており，また，実際に，勉強サプリの学習内容も概ねそれに従っている．
勉強サプリは小学生から中学生が対象で，その難易度は難しすぎず，収集され た問題回答ログデータは 1,000 万以上と膨大であり，また，先に指摘したような地 理や歴史といったいわゆる暗記系の科目と数学に関する科目が複数提供されてい るため，データの要件を満足している可能性が高い．そこで，以降では，勉強サ プリから収集された問題回答ログデータのなかで，特に地理と歴史に関する 5 講 座（小学 4 年社会，小学 5 年社会，小学 6 年社会，中学地理，中学歴史）のデータ と，算数や数学に関する 6 講座（小学 4 年算数，小学 5 年算数，小学 6 年算数，中 学 1 年数学，中学 2 年数学，中学 3 年数学）のデータの 11 データよりデータセッ トを作成し，これらのデータセットをそれぞれ，宣言的知識の獲得を主目的とす るデータセットと手続き的知識の獲得を主目的とするデータセットとする．

4.2 データセットの作成
データセットの作成について述べる．データセットは問題回答ログデータから 作成する．対象期間は 2015 年 4 月から 2015 年 11 月の 8ヶ月である．
44

第 4 章 データセット

45

勉強サプリでは学習者の回答は自動採点される．いずれの講座も回答は選択方 式で，1 つの回答欄には選択肢の中から 1 つの数字や文字を選択する．1 つの問題 に複数の回答欄が存在する場合は当該問題のすべての回答欄が正解の場合に当該 問題を正解した，と扱う．同時に 1 つの問題しか提示されないという形式だけで なく，同時に複数の問題が提示される場合もあり，その場合，採点は提示された 問題群に対して同時に行われる．つまり，同時に複数の問題回答ログが発生しう るデータである．
データセットを作成する際に，前処理として回答行動ログデータから下記に該 当するログデータをノイズとみなして除去した．
条件 同時に回答された複数の問題のログデータ群について，すべての問題の回答 欄が空白で投稿されているもの．
これは，オンライン講座ではサービス上の学習者の行動には大きな制約はなく，1 クリックで簡単に問題演習ページを開けてしまえる状況にあるということや，す べての回答欄が未記入で投稿された回答は直前に着手した問題群と同じ問題群で あることが多いこと，特に回答時間が短く誤って当該問題演習ページを開いてし まったと推察されるログが多かったからである．
以上，データセットの作成について述べた．11 データセット全体を概観する．

4.3 データセットの概観
作成した 11 データセットを概観する．11 データセットそれぞれについてユーザ 数，問題数，回答ログ数とそれらの関係性を表 4.1 に整理した．それぞれについて 順に説明していく．
まず，ユーザ数について，全体として，数千以上のユーザのログデータに基づ いたものとなっており，最も差の大きい 2 つのデータセット（中学 1 年の数学と中 学 3 年の数学）間で差は 2.6 倍程度である．特に，ユーザ数が多いのは 7,000 ユー ザ以上の中学 1 年の数学で，それに続いて，6,000 ユーザ以上の中学の地理，歴史 である．
次に，問題数について，全体として，数十から数百の問題に基づいたものとなっ ており，最も差の大きい 2 つのデータセット（小学 4 年の社会と中学 1 年の数学）
45

第 4 章 データセット

46

表 4.1: 11 データセットの統計量

学年

回答ログ数 回答ログ数 科目 ユーザ数 問題数 回答ログ数 ÷ ユーザ数 ÷ 問題数

社会 3,045

76 227,409

小学 4 年

算数 4,318 182 505,917

社会 2,833 197 388,521 小学 5 年
算数 3,380 257 411,957

75 2,992 117 2,780 137 1,972 122 1,603

社会 2,891 202 434,324 小学 6 年
算数 3,225 245 395,276

150 2,150 123 1,613

中学 1 年 数学 7,137 365 659,237 中学 2 年 数学 3,931 278 238,241 中学 3 年 数学 2,667 343 177,295

92 1,806 61 857 66 517

地理 6,499 308 660,882 中学
歴史 6,381 364 853,419

102 2,146 134 2,345

間で差は 4.8 倍程度である．小学生のデータセットよりは中学生のデータセットの 方が問題数が大きい傾向にあり，特に，問題数が多いのは 360 以上の中学 1 年の数 学と中学歴史である．
回答ログ数については，全体として，数十万以上であり， 最も差の大きい 2 つ のデータセット（中学歴史と中学 3 年の数学）間で差は 4.8 倍程度である．特に回 答ログ数が最も大きい中学歴史のデータセットは 85 万以上と大規模な問題回答ロ グデータからなる．
さらに，これら 3 つの統計量の関係性を捉えるために，ログの密度という観点 からユーザ 1 人あたりの平均回答ログ数と問題 1 問あたりの回答ログ数の 2 つの 指標を評価した．まず，ユーザ 1 人あたりの平均回答ログ数について，全体とし て，数十から百数十となっており，最も差の大きい 2 つのデータセット（小学 6 年 社会と中学 2 年数学）間で差は 2.5 倍程度である．また，いずれのデータセットで も平均回答ログ数は問題数を下回っている．
次に，問題 1 問あたりの平均回答ログ数について，全体としては，数百から数 千程度の値となっており，最も差の大きい 2 つのデータセット（小学 4 年社会と中 学 3 年数学）間で差は 5.8 倍程度である．特に，中学 2 年数学と中学 3 年数学が小

46

第 4 章 データセット

47

さい傾向にある．平均回答ログ数が最も大きい小学 4 年社会のデータセットは 1 問 あたり 3,000 近いログデータが存在する．
以上，改めてデータセット間の各統計量について整理すると，いずれのデータ セットも非常に大規模な問題回答ログから構成されており，問題あたりのログ数 という点でも十分を大きいと考えられる．また，いずれの統計量もデータセット 間においても 10 倍以上の開きはなく，特に，ログ数の偏りによる今後の議論の影 響は小さいと考えられる．
以上，11 データセット全体を概観した．次に，個々のデータセットを具体的に 説明する．

4.4 個々のデータセットの具体的説明
本論文の対象である 11 データセットについて，それぞれのデータセットの性質 について 1 つずつ述べる．具体的には，問題群の概要，問題とその回答選択肢の 具体例，問題ごとの何番目に着手されるかの平均値と回答ログ数の関係の 3 つで ある．各問題について何番目に着手されるかの平均値は各ユーザごとに当該講座 の各問題を何番目に着手したかを算出し，それらをユーザ全体で平均した値を用 いる．各問題について何番目に着手されるかの平均値と回答ログ数の関係を見る ことで，ユーザが講座の問題全体を均一に着手しているのか，もしくは，一部に 偏っているのかを捉えることができる．XY プロットとして可視化し，図のデータ 点はそれぞれひとつの問題に相当する．
小学 4 年社会
小学 4 年社会では，主に，警察，消防，浄水場，ダム，汚水処理，発電所，ゴ ミ処理，リサイクル，水不足，地図の見方などの社会基盤や社会問題に関する基 本内容が扱われる．図 4.5 に，問題と回答選択肢の例を示す．図の問題は社会ルー ルのうち道路交通法に関する問題であり，その回答を選択肢のなかから選択する， という回答形式である．次に，各問題について何番目に着手されるかの平均値と 回答ログ数の関係を図 4.6 に示す．全体として，概ね 1500 件以上の回答ログ数が
47

第 4 章 データセット

48

6000

4500

回答ログ数

3000

1500

00.00

15.00

30.00

45.00

何番目に着手されるかのユーザ平均

60.00

図 4.5: 小学 4 年社会の問題と回答選択 図 4.6: 小学 4 年社会の平均着手順と回

肢の例

答ログ数の XY プロット

あり，最初の問題の方が回答ログが大きい傾向にあるが大きく偏っているという わけではない．

小学 4 年算数

8000

6000

回答ログ数

4000

2000

0 0.00

35.00

70.00

105.00

何番目に着手されるかのユーザ平均

140.00

図 4.7: 小学 4 年算数の問題と回答選択 図 4.8: 小学 4 年算数の平均着手順と回

肢の例

答ログ数の XY プロット

小学 4 年算数では，主に，大きな数や小数など桁の認識，四則演算，数直線，折 れ線グラフ，角度，分度器，垂直，並行，面積，単位，などの数理演算の基本内 容が扱われる．図 4.7 に，問題と回答選択肢の例を示す．図の問題は分配法則に関 する問題であり，その回答を選択肢のなかから選択する，という回答形式である．
48

第 4 章 データセット

49

次に，各問題について何番目に着手されるかの平均値と回答ログ数の関係を図 4.8 に示す．全体として，概ね 1500 件以上の回答ログ数があり，最初の問題の方が回 答ログが大きい傾向にあるが大きく偏っているというわけではない．

小学 5 年社会

5000

3750

回答ログ数

2500

1250

00.00

40.00

80.00

120.00

何番目に着手されるかのユーザ平均

160.00

図 4.9: 小学 5 年社会の問題と回答選択 図 4.10: 小学 5 年社会の平均着手順と回

肢の例

答ログ数の XY プロット

小学 5 年社会では，主に，首都，地球儀，緯度経度，山地山脈，気候，平野，海 流，特産物，農林水産業，輸出入，自給率，自動車などの社会基盤や社会問題に 関する基本内容が扱われる．図 4.9 に，問題と回答選択肢の例を示す．図の問題は 社会問題のうち近年しばしば議論されている個人情報とインターネットに関する 問題であり，その回答を選択肢のなかから選択する，という回答形式である．次 に，各問題について何番目に着手されるかの平均値と回答ログ数の関係を図 4.10 に示す．全体として，概ね 500 件以上の回答ログ数があり，回答ログの分布につい ては小学 4 年の社会と概ね同じである．
小学 5 年算数
小学 5 年算数では，主に，整数，約数，倍数，平行四辺形，内角，外角，展開 図，円，柱，などの基本内容が扱われる．図 4.11 に，問題と回答選択肢の例を示 す．図の問題は小数の割り算に関する問題であり，その回答を選択肢のなかから
49

第 4 章 データセット

50

7000

5250

回答ログ数

3500

1750

00.00

50.00

100.00

150.00

何番目に着手されるかのユーザ平均

200.00

図 4.11: 小学 5 年算数の問題と回答選択 図 4.12: 小学 5 年算数の平均着手順と回

肢の例

答ログ数の XY プロット

選択する，という回答形式である．特に，回答の桁数が指定されているだけで，回 答欄への自由記述に近い回答形式である．次に，各問題について何番目に着手さ れるかの平均値と回答ログ数の関係を図 4.12 に示す．最後の方の問題他の問題と 比べると回答ログ数がかなり小さい．

小学 6 年社会

6000

4500

回答ログ数

3000

1500

00.00

40.00

80.00

120.00

何番目に着手されるかのユーザ平均

160.00

図 4.13: 小学 6 年社会の問題と回答選択 図 4.14: 小学 6 年社会の平均着手順と回

肢の例

答ログ数の XY プロット

小学 6 年社会では，主に，旧石器・縄文・弥生・古墳時代から昭和時代までの幅 広い期間の歴史に関する内容が扱われる．図 4.13 に，問題と回答選択肢の例を示
50

第 4 章 データセット

51

す．図の問題は江戸時代の鎖国に関する問題であり，その回答を選択肢のなかから 選択する，という回答形式である．次に，各問題について何番目に着手されるか の平均値と回答ログ数の関係を図 4.14 に示す．小学 4 年，小学 5 年の社会と同様 に，概ね一定の割合で後半の問題の回答ログ数が減っていっていることがわかる．

小学 6 年算数

7000

5250

回答ログ数

3500

1750

0 0.00

50.00

100.00

150.00

何番目に着手されるかのユーザ平均

200.00

図 4.15: 小学 6 年算数の問題と回答選択 図 4.16: 小学 6 年算数の平均着手順と回

肢の例

答ログ数の XY プロット

小学 6 年算数では，主に，ならべ方と組み合わせ方，倍と割合，円の面積，分数 のかけ算，分数のわり算，小数と分数の計算，拡大図と縮図，文字と式，比とそ の利用，比例と反比例，点対称，立体の体積，線対称，資料の調べ方，速さ，量 と単位の基本内容が扱われる．図 4.15 に，問題と回答選択肢の例を示す．図の問 題は立体の体積のうち特に円柱の体積に関する問題であり，その回答を選択肢の なかから選択する，という回答形式である．特に，回答の桁数が指定されている だけで，回答欄への自由記述に近い回答形式である．次に，各問題について何番 目に着手されるかの平均値と回答ログ数の関係を図 4.16 に示す．小学 4 年，小学 5 年の算数と比べ，分布が下に凸の形になっており，最初の方の問題への回答ログ の偏りが大きいことが分かる．

51

第 4 章 データセット

52

10000

7500

回答ログ数

5000

2500

00.00

75.00

150.00

225.00

何番目に着手されるかのユーザ平均

300.00

図 4.17: 中学 1 年数学の問題と回答選択 図 4.18: 中学 1 年数学の平均着手順と回

肢の例

答ログ数の XY プロット

中学 1 年数学
中学 1 年数学では，主に，1 次式，1 次方程式，2 平面の関係 面の動き，代入 と式の値，作図のしかた，円，反比例，図形の移動，対称移動，平面上の 2 直線， 度数の分布，座標，数の集合と四則計算，文字式の活用，方程式，正負の数の利 用，比と比例式，立体の体積，角錐と円錐などに関する内容が扱われる．図 4.17 に，問題と回答選択肢の例を示す．図の問題は文字式を活用した問題であり，そ の回答を選択肢のなかから選択する，という回答形式である．次に，各問題につ いて何番目に着手されるかの平均値と回答ログ数の関係を図 4.18 に示す．回答ロ グは最初の方の問題に大きく偏っており，特に後半の一部は数十程度のログしか ないことが分かる．

中学 2 年数学
中学 2 年数学では，主に，1 次方程式，1 次関数，三角形の合同条件，二等辺三 角形，仮定と結論，単項式と多項式，合同な三角形，平行四辺形，証明，連立方 程式などを扱う．扱う内容は中学 1 年数学のデータセットのものと概ね同様であ るが，難易度が高い．図 4.19 に，問題と回答選択肢の例を示す．図の問題は数連 立方程式に関する問題であり，その回答を選択肢のなかから選択する，という回 答形式である．次に，各問題について何番目に着手されるかの平均値と回答ログ 数の関係を図 4.20 に示す．グラフの外見は中学 1 年数学に近いが，回答ログ数の
52

第 4 章 データセット

53

5000

3750

回答ログ数

2500

1250

00.00

40.00

80.00

120.00

何番目に着手されるかのユーザ平均

160.00

図 4.19: 中学 2 年数学の問題と回答選択 図 4.20: 中学 2 年数学の平均着手順と回

肢の例

答ログ数の XY プロット

スケールが半分程度である．また，一部の問題については，ログが数十程度と他 と比べると非常に少なくなっている．

中学 3 年数学

4000

3000

回答ログ数

2000

1000

0 0.00

75.00

150.00

225.00

何番目に着手されるかのユーザ平均

300.00

図 4.21: 中学 3 年数学の問題と回答選択 図 4.22: 中学 3 年数学の平均着手順と回

肢の例

答ログ数の XY プロット

中学 3 年数学では，たすき掛け，一次関数，三平方の定理，中点連結定理，乱数 表，二次方程式，二次関数，円の面積，円周角，分配法則，回転体の体積，因数 分解，増加関数，変域，外接円，媒介変数，展開，平方完成，平方根，平行線，循 環小数，指数，接線の定義，放物線，文字式，有理数，根号，標本調査，母集団，
53

第 4 章 データセット

54

減少関数，無理数，相似の三角形，相似比，立方体，等差数列の和，約数，素因 数分解，素数，解と係数の関係などの内容が扱われる．図 4.21 に，問題と回答選 択肢の例を示す．図の問題は図形のうち相似の三角形に関する問題であり，その 回答を選択肢のなかから選択する，という回答形式である．次に，各問題につい て何番目に着手されるかの平均値と回答ログ数の関係を図 4.22 に示す．グラフの 外観は中学 2 年数学に類似しているが，後半の問題の回答ログ数は非常に少ない．

中学地理

9000

6750

回答ログ数

4500

2250

0 0.00

45.00

90.00

135.00

何番目に着手されるかのユーザ平均

180.00

図 4.23: 中学地理の問題と回答選択肢 図 4.24: 中学地理の平均着手順と回答

の例

ログ数の XY プロット

中学地理では，主に，アジア，アフリカ，オセアニア，ヨーロッパ，北アメリカ， 南アメリカ，世界と日本の関係，世界の地域区分と特色，世界の衣食住・宗教，地 域の調査，日本の地域区分，日本の工業と商業・サービス業，日本の農林水産業， 東北地方，近畿地方，関東地方，中部地方，九州地方，北海道地方，中国・四国 地方などが地域や地域の性質，地域間の関係性が扱われる．図 4.23 に，問題と回 答選択肢の例を示す．図の問題はヨーロッパに関する問題であり，その回答を選 択肢のなかから選択する，という回答形式である．次に，各問題について何番目 に着手されるかの平均値と回答ログ数の関係を図 4.24 に示す．全体として，概ね 500 以上の回答ログ数があり，前半の問題から後半の問題にかけてほぼ線形に回答 ログ数が減少している．

54

第 4 章 データセット

55

中学歴史

9000

6750

回答ログ数

4500

2250

00.00

55.00

110.00

165.00

何番目に着手されるかのユーザ平均

220.00

図 4.25: 中学歴史の問題と回答選択肢 図 4.26: 中学歴史の平均着手順と回答

の例

ログ数の XY プロット

中学歴史では，主に，ルネサンスと大航海時代，世界恐慌と国際情勢の悪化，世 界文明の発生，国際協調体制，第一次世界大戦とロシア革命，欧米の市民革命と 産業革命，旧石器・縄文・弥生時代，安土桃山時代，大和時代，奈良時代，平安時 代，鎌倉時代，室町時代，江戸時代，明治時代，昭和時代，大正時代，平成時代， など内容が扱われる．図 4.25 に，問題と回答選択肢の例を示す．図の問題はルネ サンスと大航海時代に関する問題と推察される．その回答を選択肢のなかから選 択する，という回答形式である．次に，各問題について何番目に着手されるかの 平均値と回答ログ数の関係を図 4.26 に示す．全体として，概ね 500 以上の回答ロ グ数があり，前半の問題から後半の問題にかけてほぼ線形に回答ログ数が減少し ている．外観は中学地理と概ね合致している．
以上，個々のデータセットおよびデータが収集された講座を具体的に説明した． 具体的な内容から，地理と歴史に関する 5 講座（小学 4 年社会，小学 5 年社会，小 学 6 年社会，中学地理，中学歴史）のデータセットがどちらかというと，宣言的 知識の獲得を主目的としているデータセットであり，算数や数学に関する 6 講座 （小学 4 年算数，小学 5 年算数，小学 6 年算数，中学 1 年数学，中学 2 年数学，中 学 3 年数学）のデータセットがどちらかというと，手続き的知識の獲得を主目的 としているデータセットであることが分かる．
また，データセットの一部の問題については他の問題と比べてログ数が数十程
55

第 4 章 データセット

56

度と少なかったが，それでも数十程度のログデータがあり，そうした問題が一部に 限られていることから知識構造を抽出できると考え，このまま全ての問題をデー タセットに利用する．
以上，データセットについて述べた．次章では，実験について述べる．

56

第5章 実験
本章では，実験について述べる．まず，データセットへの適合のための Deep Knowledge Tracing の拡張法を述べたのち，次に，実験設定について述べ，その後， 実験結果について述べる．実験結果においては，まず，11 データセットのいずれ のデータセットにおいても，Deep Knowledge Tracing の予測性能が知識間関係を 考慮しない Bayesian Knowledge Tracing よりも高いことを示し，Deep Knowledge Tracing により知識獲得における知識間関係を抽出できていることを定量的に確認 する．さらに，11 の知識間関係ネットワークを可視化し，ネットワーク全体にお けるノード集合の配置やその関係を内容の側面から分析し，知識獲得における知 識間関係を抽出できていることを定性的に確認する．そして，宣言的知識の知識 構造を表現する 5 つのネットワークと手続き的知識の知識構造を表現する 6 つの ネットワークのモジュラリティとフロー階層，GRC を算出し，知識獲得における 知識構造について，宣言的知識のモジュール性が手続き的知識のモジュール性よ り統計的に有意に高く，逆に，手続き的知識の階層性が宣言的知識の階層性より 統計的に有意に高いことを示す．
5.1 Deep Knowledge Tracing の拡張および最適化
データセットへの適合のための Deep Knowledge Tracing の拡張法を述べ，その 後その最適化について述べる．勉強サプリの問題演習はテスト形式で提供されて おり，一度に 1 つ以上の問題が提供され，また，それらの採点も同時に行われる ため，同時に複数の問題の回答ログデータが発生する可能性があり，同時に 1 つ の問題しか回答ログデータが発生しないという Deep Knowledge Tracing で想定さ れている設定と異なる．そのため，Deep Knowledge Tracing をデータセットに適 合するように拡張する．
57

第 5 章 実験

58

Knowledge Tracing は学習者の時刻 t において観測された問題回答結果を qt とす れば，q1, q2, . . . , qt から時刻 t + 1 において観測される問題回答結果 qt+1 を予測す るタスクであった．
同時に複数の問題について回答ログが生じることを許容する場合，Knowledge Tracing のタスクは学習者の時刻 t において観測された問題回答結果ベクトルを qt とすれば，q1, q2, . . . , qt から時刻 t + 1 において観測される問題回答結果ベクトル qt+1 を予測するというものである．
Deep Knowledge Tracing では RNN への入力は one-hot ベクトルに符号化され， 入力ベクトルを xt，演習問題の数を M とすれば，xt の長さは 2M であった．同時 に複数の問題が回答されるという設定では，その同時に回答された問題数を mt と すれば mt-hot ベクトルに符号化することで，[Piech et al., 2015] に近い形で RNN に情報を入力できる．

表 5.1: 拡張した Deep Knowledge Tracing における回答ログデータと対応する入 力ベクトルの例

回答ログ

入力ベクトル

ユーザ ID ログの順番 問題番号 正誤 変数名

値

A A

1 1

1 2

1 0

x1

[1000...0100]

A A

2 2

1 2

1 1

x2

[1100...0000]

A 3 3 0 x3 [0000...0010]

A A

4 4

3 4

0 1

x4

[0001...0010]

具体例を交えて説明する．例えば，演習問題の数が 4 つと仮定する ．M = 4 で あり，xt の長さは 8 である．ある学習者が，表 5.1 の回答ログのように問題を回答 し正誤が観測されたとすれば，入力ベクトル xt は表 5.1 の入力ベクトルのように 符号化される．
出力 yt は Deep Knowledge Tracing と全く同じであり，問題と同じ長さのベク トルで，それぞれの要素が当該学習者がそれぞれの問題に正しく回答する確率の 予測値となっている．したがって，t + 1 の回答 qt+1 の正誤予測は t + 1 に回答さ
58

第 5 章 実験

59

れる問題 qt+1 に対応する yt の要素から読み取れる． 最適化手法は [Piech et al., 2015] のものとほとんど同じである．

∑mt log(p1 × p2 × · · · × pmt) = log(pk)
k

(5.1)

であるため，δ˜(qt+1) を時刻 t + 1 にどの問題が回答されたかの mt-hot ベクトルと し，at+1 を時刻 t + 1 に対応する問題で正答したか否か（1 か 0）のベクトルとす れば，ロス関数は

∑

L=

l(ytT δ˜(qt+1), at+1)

t

(5.2)

である．学習時は [Piech et al., 2015] と同様にミニバッチごとに確率的勾配降下 法で目的関数を最小化する．
ハイパーパラメタについては，対象データが多いため学習コストの削減を狙い RNN の部分には GRNN を用いる．学習率の初期値を 200，モーメントを 0.98，1 エポックごとに，減衰率 0.8 として学習率を最小学習率 10 まで減衰させる．また， 勾配のノルムの最大値を 0.00001 として [Pascanu et al., 2013] に従い勾配に制約を 設けた．dropout は [Piech et al., 2015] と同様に yt の方向にのみかけ，dropout 率 は 0.5 とした．隠れ層のユニット数は 200 として，各重み行列の初期化は [Glorot and Bengio, 2010] にしたがった．時系列方向の誤差逆伝搬は最長で 200 まで伝搬 するように制約を設けた．
これらのハイパーパラメタは実験的に高い予測性能を発揮したため設定してお り，網羅的に探索したわけではない．通常，深層学習の手法はハイパーパラメタの 数が非常に大きく，また，計算コストが大きいため大規模な探索は行えない．Grid Search や Random Search [Bergstra and Bengio, 2012] といった探索手法が提案され ているが，専門家が手で調整した方が優れていることが報告されている [Larochelle et al., 2007, Bergstra and Bengio, 2012] ．
実装には Theano を用いた [Bergstra et al., 2010, Bastien et al., 2012]．Theano は多次元行列を含む数学的表現の定義や計算，最適化を効率的に行える Python の ライブラリで，深層学習の研究ではよく利用される．
以上，Deep Knowledge Tracing の拡張およびその最適化について述べた．次に，

59

第 5 章 実験 実験設定について述べる．

60

5.2 設定
ここでは，特に Deep Knowledge Tracing による知識獲得の予測の実験設定，お よび，構築したネットワークの可視化の設定，ネットワーク構造指標の計算につ いて述べる．
まず，Deep Knowledge Tracing による知識獲得の予測の実験設定について，11 のデータセットそれぞれについて，訓練：検証：テスト = 8：1：1 となるように ユーザを分け，訓練ユーザのデータでモデルを構築し，検証ユーザのデータでハ イパーパラメタを調整し，検証ユーザのデータで精度が最も高かったモデルをテ ストユーザのデータに適用し当該モデルの最終的な精度とする．小学生や中学生 が学習する内容は国が定める学習指導要領 [文部科学省, 2011] に従っており，学習 内容が高い頻度で入れ替わっていくというわけではないため，勉強サプリの学習 教材もまた，更新頻度は高くない．したがって，Knowledge Tracing のモデルは商 品推薦や広告推薦の領域でしばしば問題となるアイテムに関するコールドスター ト問題 [Schein et al., 2002] の影響を受けにくく，こうして同じ時期のユーザを分 割する評価方法でもモデルの性能を十分評価できると考えられる．
次に，構築したネットワークの可視化の設定およびネットワーク構造指標の計 算について述べる．ネットワークの可視化には Gephi [Bastian et al., 2009] を用い た．Gephi はネットワーク可視化用のソフトウェアであり，豊富なレイアウト手法 やネットワークの統計量計算ツールが提供されている．ノードは問題を，エッジ は影響関係を示すように可視化する．ノードの色はデータセットの説明の際に用 いた平均問題着手番号について，番号が小さいものから大きいものにかけて青色 から赤色になるようにする．ノードの大きさはノードの出力次数に比例するよう に可視化する．ノードのラベルはそのノードが指す問題が提供される授業名とそ の問題に割り振った適当な数字を結合した文字列を利用する．また，一見してク ラスタだと判断できそうなノード集合には，ノードやその結合が分かりにくくな らない範囲で扱われている内容の説明を近くに記載する．ネットワークのレイア ウト手法には，ForceAtlas [Jacomy, 2009] を用いる．また，モジュラリティの計算
60

第 5 章 実験

61

は Gephi で行い，フロー階層と GRC の計算は NetworkX [Hagberg et al., 2008] と いうネットワーク解析や探索及びネットワークアルゴリズムを提供する Python の ライブラリを用いた．
以上，実験設定について述べた．次に，実験結果について述べる．

5.3 結果
実験結果について述べる．まず，11 データセットのいずれのデータセットにお いても，Deep Knowledge Tracing の予測性能が知識間関係を考慮しない Bayesian Knowledge Tracing よりも大きく高いことを示し，Deep Knowledge Tracing によ り知識獲得における知識間関係を抽出できていることを定量的に確認する．さら に，11 の知識間関係ネットワークを可視化し，ネットワーク全体におけるノード 集合の配置やその関係を内容の側面から分析し，知識獲得における知識間関係を 抽出できていることを定性的に確認する．そして，宣言的知識の知識構造を表現 する 5 つのネットワークと手続き的知識の知識構造を表現する 6 つのネットワー クのモジュラリティとフロー階層，GRC を算出し，知識獲得における知識構造に ついて，宣言的知識のモジュール性が手続き的知識のモジュール性より統計的に 有意に高く，逆に，手続き的知識の階層性が宣言的知識の階層性より統計的に有 意に高いことを示す．
5.3.1 各データセットにおける予測性能
Deep Knowledge Tracing（以下，DKT）と Bayesian Knowledge Tracing（以下， BKT）を 11 データセットに適用した結果を表 5.2 に示す．Marginal は各問題につ いてそれぞれ正解の周辺確率を予測結果とするものである．[Piech et al., 2015] に も記載されていたため，本稿でも同様にベースラインとして記載した．また，値 が大きい箇所は太字で記載した．
まず，すべてのデータセットにおいて DKT の AUC は BKT の AUC よりも大 きく高かった．また，DKT−BKT の値の平均も宣言的知識の獲得を主目的とする データセットと手続き的知識の獲得を主目的とするデータセットでほとんど差は
61

第 5 章 実験

62

表 5.2: 各データセットに対する各手法の予測性能とそれらの関係性

データセット

分類

科目

宣言的知識 の獲得を 主目的とする データセット

地理・社会 歴史・社会

手続き的知識 の獲得を
主目的とする データセット

算数・数学

学年 小学 4 年 小学 5 年
中学 小学 6 年
歴史 小学 4 年 小学 5 年 小学 6 年 中学 1 年 中学 2 年 中学 3 年

AUC Marginal BKT
0.701 0.739 0.647 0.680 0.655 0.681 0.642 0.657 0.635 0.670 0.696 0.707 0.714 0.724 0.734 0.749 0.738 0.750 0.675 0.696 0.729 0.735

DKT 0.791 0.765 0.764 0.773 0.766 0.828 0.804 0.836 0.807 0.773 0.804

DKT − BKT 値 平均
0.052 0.085 0.083 0.086 0.116 0.096 0.121 0.081 0.087
0.082 0.057 0.077 0.069

なかった．つまり，宣言的知識の獲得を主目的とするデータセットと手続き的知 識の獲得を主目的とするデータセットともに，DKT により知識獲得における知識 間関係を抽出できていると考えられる．
次に，特に，算数や数学の 6 つのデータセットにおいて，中学 2 年のデータセッ トを除く 5 つのデータセットにおいて DKT の AUC は 0.8 を超えており，[Piech et al., 2015] で示されたように，確かに，DKT が数学のデータセットに対して有効 であった．地理や歴史の社会関係のデータセットにおいても DKT の AUC は 0.76 を超えており，DKT が地理や歴史の社会関係のデータセットに対して有効であり， 宣言的知識の獲得を主目的とするデータセットに対しても有効であることが示さ れた．
以上，11 データセットのいずれのデータセットにおいても，Deep Knowledge Tracing により知識獲得における知識間関係を抽出できていることを確認した．

5.3.2 抽出した知識間関係ネットワークの可視化
11 の知識間関係をネットワークとして可視化し，ネットワーク全体におけるノー ド集合の配置やその関係を内容の側面から分析し，これらのネットワークが，知
62

第 5 章 実験

63

識獲得における知識構造を表現しているものであることを定性的に確認する． まず，宣言的知識について知識間関係ネットワークを順に可視化していく．

小学 4 年社会

郷土開拓

きょう土を開く:65

きょう土を開く:58

きょう土を開く:56

きょう土を開く:59

きょう土を開く:60

きょう土を開く:64

きょう土を開く:63

きょう土を開く:61

きょう土を開く:57

きょう土を開く:62

ごみのしょりと利用②:51
ごみのしょりと利用②:50 ごみのしょりと利用②:55 ごみのしょりと利用②:54
ごみのしょりと利用②:53 ごみのしょりと利用②:52
ゴミ処理

地図の見方 地図の見方:74

地図の見方:69 地図の見方:6地7図の見方:72
地図の見方:68

地図の見方:70

地図の見方:66

地図の見方:75 地図の見方:73

火事からくらしを守る:7

火事からくらしを守火る事か:5らくらしを守る:8

火事からくらしを守る:9 火事からくらしを守る:6事件や事故からく火ら事しかをら守くるら:1し2を事守件るや:事3 故からくらしを守る:11

火事からくらしを守る:2 火事からくらしを守る:1
事件や事故からくらしを守る:14

火事からくらしを守る:4

火事からくらしを守る:0

事件や事故からくらしを守る:13 事件や事故からくらしを守る:16

事件や事故からくらしを守る:10

防災

事件や事故からくらしを守る:19

事件や事故からくらしを守る:18

みずはどこから？:20

みずはどこから？:24

事件や事故からくらしを守る:15 事件や事故からくらしを守る:17

みずはどこから？:27

ごみのしょりと利用①:44

ごみのしょりと利用①:41

みずはどこから？:23

みずはどこから？:28 みずはどこから？:21
みずはどこから？:26

水源

みずはどこから？:29

みずはどこから？:22
みずはどこから？:25

地図の見方:71

ごみのしょりと利用①:49

ごみのしょりと利用①:45

ごみのしょりと利用①:48

ごみのしょりと利用①:40 ごみのしょりと利用①:43

ごみのしょりと利ご用み①の:4し7 ょりと利用①:42 ごみのしょりと利用①:46

ゴミ処理

くらしをささえる電気:32

電気

くらしをささえる電気:30

くらしをささえる電気:33 くらしをささえる電気:38

くらしをささえる電気:37

くらしをささえる電気:39

くらしをささえる電気:35

くらしをささえる電気:34 くらしをささえる電気:31

くらしをささえる電気:36

図 5.1: 小学 4 年社会の知識間関係ネットワーク

小学 4 年社会のネットワークを図 5.1 に示す．ノードは内容ごとでクラスタを形 成していることが分かる．クラスタ間の関係は弱い関係となっていそうである．特 筆すべき点は，防災とラベル付けしたクラスタは火事に関するものと事故や事件 に関するものが 1 つとなってできているということである．
小学 5 年社会 小学 5 年社会のネットワークを図 5.2 に示す．ノードは内容ごとでクラスタを形
成している．特に，国土，北海道，沖縄のクラスタが近くにあることは，国土に おける地理関係において北海道と沖縄の関連が強いからかもしれない．また，工 業と近い環境問題と自動車と近い環境問題があることも，それぞれの文脈におい て環境問題があることと関連があるのかもしれない．
63

第 5 章 実験

貿易・運輸:147

貿易・運輸:142

貿易・運輸:146 貿易・運輸:138

貿易・運輸:145

貿易・運輸:134

貿易・運輸:144

貿易・運輸:139

貿易・運輸:141

貿易・運輸:136

貿易・運輸:135

貿易・運輸:143

貿易・運輸

貿易・運輸:140

北海道

北海道のくらし:31

北海道のくらし:39 北海道のくらし:30

北海道のくらし:38

北海道のくらし:36 北海道のくらし:35

北海道のくらし:33

北海道のくらし:34 北海道のくらし:40

北海道のくらし:37

北海道のくらし:32

国土

国土の様子②:22

国土の様子②:26

国土の様子②:17

国土の様子②:19

国土の様子②:16 国土の様子②:20 国土の様子②:15

国土の様子②:25

国土の様子②:29

国土の様子②:21 国土の様子②:28

国土の様子②:23 国土の様子②:18

国土の様子②:24

国土の様子②:27

国土の様子①:14

国土 国土の様子①:13

国土の様子①:10

国土の様子①:9 国土の様子①:11

国土の様子①:5

国土の様子①:6

国土の様子①:12

国土の様子①:2

国土の様子①:8

工業:133

工業:124

工業

工業:128

工業:130 工業:126

工業:125

工業:131

工業:132 工業:127

工業:129 工業:123

工業:120 工業:119

工業:118 工業:121

工業:116

工業:117

国土の様子①:7

国土の様子①:3

国土の様子①:0

国土の様子①:4

情報と私たちの暮らし:149

情報と私たちの暮らし:156
情報

情報と私たちの暮らし:148 情報と私たちの暮らし:153

情報と私たちの暮らし:152

情報と私たちの暮らし:155

工業:122

環境問題①:162

環境問題①:164

環境問題①:160

環境問題①:158

環境問題①:165

環境問題①:159

環境問題①:166

環境問題①:157 環境問題①:161 環境問題①:163
環境問題

世界遺産:196

情報と私たちの暮らし:150

世界遺産:189

世界遺産:187 世界遺産:191

世界遺産:194 世界遺産:188

世界遺産:192

世界遺産:195

世界遺産:190

世界遺産:193

世界遺産

環境問題②:167

貿易・運輸:137

自然災害

自然災害:186

自然災害:185

沖縄のくらし:42
沖縄

沖縄のくらし:46 沖縄のくらし:48
沖縄のくらし:43

沖縄のくらし:47

沖縄のくらし:41

沖縄のくらし:49

沖縄のくらし:45

沖縄のくらし:50

自然災害:183

自然災害:182 自然災害:181 自然災害:179

自然災害:180

自然災害:184

自然災害:178

自然災害:177

情報と私たちの暮らし:151

食生活

これからの食生活:103
これからの食生活:101 これからの食生活:99
これからの食生活:96

これからの食生活:100

これからの食生活:97

これからの食生活:95 これからの食生活:104

これからの食生活:98

これからの食生活:102

沖縄のくらし:44

国土の様子①:1

情報と私たちの暮らし:154

漁業:87

漁業:85

漁業:92

漁業:86

稲作:57

漁業:89

稲作:55

稲作:54

漁業:91

稲作:59

稲作:53

稲作:58

稲作:60

稲作:56

稲作:51

野菜・果物・畜産:67

稲作稲作:52

漁業:84

漁業:80

漁業:75

漁業:88 漁業:82

漁業:90

漁業:81

漁業:78 漁業:76

漁業

漁業:83

漁業:79 漁業:77

漁業:94

漁業:93

環境問題②:175

環境問題②:174

環境問題②:169

環境問題②:170

環境問題②:171

環境問題②:168 環境問題②:172

環境問題②:173

環境問題②:176

環境問題

自動車:105

自動車:109

自動車:112

自動車:107

自動車:106

自動車:115

自動車:113 自動車:111
自動車:110

自動車:108 自動車:114

自動車

野菜・果物・畜産:70

野菜・果物・畜産:65
農畜産業

野菜・果物・畜産:63 野菜・果物・畜産:71

野菜・果物・畜産:66野菜・果物・畜産:62

野菜・果物・畜産:73

野菜・果物・畜産:72

野菜・果物・畜産:64野菜・果物・畜産:68 野菜・果物・畜産:61

野菜・果物・畜産:69 野菜・果物・畜産:74

図 5.2: 小学 5 年社会の知識間関係ネットワーク

小学 6 年社会

平安時代② 鎌倉時代①:65 平安時代② 鎌倉時代①:58
平安時代② 鎌倉時代①:64 平安時代② 鎌倉時代①:61
平安時代② 鎌倉時代①:59

平安・鎌倉時代

平安時代② 鎌倉時代①:51平安時代② 鎌倉時代①:53

平安時代② 鎌倉時代①:54

平安時代② 鎌倉時代①:52

平安時代② 鎌倉時代①:55 平安時代② 鎌倉時代①:62

平安時代② 鎌倉時代①:63

江戸時代④:136 江戸時代④:137 江戸時代④:134
江戸時代④:139

江戸時代④:132

江戸時代④:135

江戸時代④:138 江戸時代④:140

江戸時代④:133
江戸時代

平安時代② 鎌倉時代①:57

平安時代② 鎌倉時代①:60

明治・大正時代

明治時代④ 大正時代:189 明治時代④ 大正時代:179
明治時代④ 大正時代:181 明治時代④ 大正時代:184 明治時代④ 大正時代:185
明治時代④ 大正時代:188

明治時代④ 大正時代:180

明治時代④ 大正時代:183

明治時代④ 大正時代:182

明治時代④ 大正時代:190

明治時代④ 大正時代:186

明治時代④ 大正時代:187

平安時代② 鎌倉時代①:56
室町時代
鎌倉時代② 室町時代①:70 鎌倉時代② 室町時代①:71
鎌倉時代② 室町時代①:74 鎌倉時代② 室町時代①:81
鎌倉時代② 室町時代①:73 鎌倉時代② 室町時代明治①時代:6①6:149
鎌倉時代② 室町時代①:79 鎌倉時代② 室町時代①:69
鎌倉時代② 室町時代①:77 鎌倉時代② 室町時代①:68
鎌倉時代② 室町時代①鎌:倉72時代② 室町時代①:78 鎌倉時代② 室町時代①:76
鎌倉時代② 室町時代①:80

平安時代①:50
奈良時代:28 奈良時代:27

奈良時代:33

奈良時代:36

奈良時代

奈良時代:25 奈良時代:30

奈良時代:35 奈良時代:32

奈良時代:26

奈良時代:34

奈良時代:29

奈良時代:31

室町時代② 安土桃山時代①:92
室町時代② 安土桃山時代①:87 室町時代② 安土桃山時代①:84
室町時代② 安土桃山時代①:82 室町時代② 安土桃山時代①:86
室町時代② 安土桃山時代①:85

鎌倉時代② 室町時代①:75 鎌倉時代② 室町時代①:67

室町時代② 安土桃山時代①:91 室町時代② 安土桃山時代①:88 室町時代② 安土桃山時代①:83
室町時代② 安土桃山時代①:90
室町時代② 安土桃山時代①:89
室町・安土桃山時代

室町時代② 安土桃山時代①:94

室町時代

平安時代①:38

平安時代①:46

平安時代①:49 平安時代①:45

平安時代①:43

平安時代①:40

平安時代①:39

平安時代①:44

平安時代①:41

室町時代② 安土桃山時代①:93

平安時代①:42

平安時代①:48

平安時代①:47

奈良時代:37 飛鳥時代:23

飛鳥時代:15

飛鳥時代:22

飛鳥時代:17

飛鳥時代:24 飛鳥時代:20

飛鳥時代:18

飛鳥時代:19

旧石器・縄文・弥生・古墳時代:7

旧石器・縄文・弥生・古墳時代:9

旧石器・縄文・弥生・古墳時代:0

旧石器・縄文・弥生・古墳時代:3

旧石器・縄文・弥生・古墳時代:1

旧石器・縄文・弥生・古墳時代:2

旧石器・縄文・弥生・古墳時代:14

旧石器・縄文・弥生・旧古石墳器時・代縄:文10・弥生・古墳時代:13 旧石器・縄文・弥生・古墳時代:4
旧石器・縄文・弥生旧・石古器墳・時縄代文:5・弥生・古墳時代:11 旧石器・縄文・弥生旧・石器古・縄墳文時・弥代生・:1古2墳時代:6

昭和時代①:198

江戸時代③:129

江戸時代

江戸時代③:124

江戸時代③:123

江戸時代③:126

江戸時代③:116 江戸時代③:127

江戸時代③:120 江戸時代③:119
江戸時代③:118

江戸時代③:121

江戸時代③:122

江戸時代③:117

江戸時代③:131

昭和時代①:199

昭和時代①:193

昭和時代①:194

昭和時代①:195 昭和時代①:201

昭和時代①:200

昭和時代①:191

昭和時代①:196

昭和時代①:192 昭和時代①:197

昭和時代

江戸時代③:125

江戸時代③:130

安土桃山・江戸時代
安土桃山時代② 江戸時代①:101
安土桃山時代② 江戸時代①:96安土桃山時代② 江戸時代①:95 安土桃山時代② 江戸時代①:98
安土桃山時代② 江戸時代①:103 安土桃山時代② 安江土戸桃時山代時①代:1②0 2江戸時代①:99
安土桃山時代② 江戸時代①:104
安土桃山時代② 江戸時代安①土:1桃0山5 時代② 江戸時代①:100 安土桃山時代② 江戸時代①:97

江戸時代③:128

明治時代③:175

明治時代③:171

明治時代③:169

明治時代③:168

明治時代③:166 明治時代③:177
明治時代③:174 明治時代③:176
明治時代③:172 明治時代③:173 明治時代③:170
明治時代③:167

明治時代①:145

飛鳥時代:21

飛鳥時代:16

明治時代①:142

明治時代①:144

明治時代①:150 明治時代①:146
明治時代①:143 明治時代①:15明2治時代①:148
明治時代①:141

明治時代①:147

明治時代①:151

明治時代①:153

明治時代

旧石器・縄文・弥生・古墳時代:8
旧石器・縄文 ・弥生時代
明治時代②:163

明治時代③:178
明治時代

江戸時代②:109

江戸時代

江戸時代②:113 江戸時代②:112
江戸時代②:108

江戸時代②:106 江戸時代②:110
江戸時代②:111

江戸時代②:107 江戸時代②:115
江戸時代②:114

明治時代②:162

明治時代②:157

明治時代②:158

明治時代②:159 明治時代②:165

明治時代②:155 明治時代②:164

明治時代②:156 明治時代②:160

明治時代②:154 明治時代②:161

明治時代

図 5.3: 小学 6 年社会の知識間関係ネットワーク

64

小学 6 年社会のネットワークを図 5.3 に示す．ノードは内容ごとでクラスタを形 64

第 5 章 実験

65

成している．特に，クラスタは各時代を表現しているが，逆に，江戸時代や明治 時代等の一部の時代は 1 つのクラスタを形成しているというわけではない．

中学地理

世界と日本のネットワーク:293
世界と日本のネットワーク世界と日本のネットワーク:288
世界と日本のネットワーク:295 世界と日本のネットワーク:294
世界と日本のネットワーク:292 世界と日本のネットワーク:291
世界と日本のネットワーク:289 世界と日本のネットワーク:290

日本の農林水産業:274
日本の農林水産業:272 日本の農林水産業:275
日本の農林水産業:278 日本の農林水産業:277 日本の農林水産業:273 日本の農林水産業:276

日本の農林水産業

日本の農林水産業:271

日本の農林水産業:269

北アメリカ

北アメリカ②:126 北アメリカ②:130 北アメリカ②:132

北アメリカ②:125 北アメリカ②:133
北アメリカ②:127

北アメリカ②:134

北アメリカ②:128

北アメリカ②:129

北アメリカ②:131

南アメリカ

南アメリカ:145 南アメリカ:142南アメリカ:141 南アメリカ:138

南アメリカ:136 南アメリカ:137

南アメリカ:147

南アメリカ:146

南アメリカ:143

南アメリカ:139

南アメリカ:144

アフリカ:88

南アメリカ:135 南アメリカ:140

北アメリカ北アメリカ①:118

北アメリカ①:124

北アメリカ①:114

北アメリカ①:121 北アメリカ①:112

北アメリカ①:115

北アメリカ①:117

北アメリカ①:116

北アメリカ①:119

北アメリカ①:122

北アメリカ①:120

アフリカ:109

北アメリカ①:111

アフリカ:108

北アメリカ①:113

アフリカ:89

アフリカ:100 アフリカ:110

アフリカ:91

アフリカ:101

アフリカ:106

アフリカ:90 アフリカ:104

アフリカ:95

アフリカ:97

アフリカ:98 アフリカ:103

アフリカ:96

ヨーロッパ

ヨーロッパ①:66

ヨーロッパ①:67

ヨーロッパ①:68 ヨーロッパ①:72

ヨーロッパ①:74

ヨーロッパ①:77

ヨーロッパ①:71

ヨーロッパ①:69

ヨーロッパ①:70

ヨーロッパ①:75

ヨーロッパ①:73

ヨーロッパ①:65

日本の農林水産業:270

日本の農林水産業:268

日本の工業と商業・サービス業:283

諸地域の調査:169 諸地域の調査:168

諸地域の調査:165

諸地域の調査:163

諸地域の調査:166 諸地域の調査:170

諸地域の調査:164

世界と日本の地形:206

アフリカ:99

アフリカ:102

アフリカ:107

世界と日本の地形:195

世界と日本の地形:194

アフリカ:94 ヨーロッパ①:76

世界と日本の地形:197

諸地域の調査:171 世界と日本の地形:216

日本の農林水産業:279 日本の工業と商業・サービス業:285

日本のすがた:182

日本のすがた:173

日本のすがた:176

日本のすがた:177 日本のすがた:179

日本のすがた:178

日本のすがた:181

日本のすがた:174

世界と日本の地形:209 世界と日本の地形:214

世界と日本の地形:205

世界と日本の地形:193 世界と日本の地形:196

世界と日本の地形:198

世界と日本の気候・自然災害:240

日本のすがた:172

日本のすがた:180

日本のすがた:175
世界と日本の気候・自然災害:226 世界と日本の気候・自然災害:231

世界と日本の地形:203

世界と日本の地形:201

諸地域の調査:167

世界と日本の地形:199

世界と日本の地形:213 世界と日本の気候・自然災害:239
日本の工業と商業・サービス業:281 日本の工業と商業・サービス業:286

世界と日本の気候・自然災害:235

日本の工業と商業・サービス業:282

世界と日本の気候・自然災害:229 世界と日本の気候・自然災害:236

世界と日本の気候・自然災害:227 世界と日本の気候・自然災害:237 世界と日本の気候・自然災害:238

アフリカ:93

世界と日本の地形:204

世界と日本の地形:215

北アメリカ①:123

世界と日本の地形:202

世界と日本の地形:212

世界と日本の地形:207

世界と日本の気候・自然災害:220 世界と日本の気候・自然災害:234

世界と日本の気候・自然災害:221

世界と日本の気候・自然災害:225

世界と日本の気候・自然災害:217

世界と日本の気候・自然災害:224 世界と日本の気候・自然災害:222

世界と日本の気候・自然災害:223

日本の地域区分:183

世界と日本の地形:211

日本の地域区分:187 日本の地域区分:186
日本の地域区分:185

アフリカ:105 アジア①:42
アジア①:45

アフリカ:92

世界と日本の気候・自然災害:219 日本の工業と商業・サービス業:284

日本の地域区分:188

日本の地域区分:192 日本の地域区分:191 日本の地域区分:189
日本の地域区分:190

ヨーロッパ

ヨーロッパ②:79 ヨーロッパ②:82ヨーロッパ②:86

ヨーロッパ②:84 ヨーロッパ②ヨ:ー78ロッパ②:81

ヨーロッパ②:83

ヨーロッパ②:85 ヨーロッパ②:80
ヨーロッパ②:87

アジア①:46

アジア①:50アジア①:53

アジア①:43

アジア①:48

諸地域に暮らす人々:24
諸地域に暮らす人々:22 諸地域に暮らす人々:31 諸地域に暮らす人々:21

諸地域に暮らす人々:30 諸地域に暮らす人々:29

諸地域に暮らす人々:28 諸地域に暮らす人々:27

諸地域に暮らす人々:26

諸地域に暮らす人々:20
地域の人々

諸地域に暮らす人々:23

諸地域に暮らす人々:25

アジア①:51

世界の衣食住・宗教:36

アジア①:52

アジア①:47 アジア①:44

世界の衣食住・宗教:41

世界の衣食住・宗教:40

世界の衣食住・宗世界教の:3衣3食住・宗教:39 世界の衣食住・宗教:32
世界の衣食住・宗教:38

世界の衣食住・宗教:34

世界の衣食住・宗教:35

世界の衣食住・宗教:37

世界と日本の気候・自然災害:232

世界と日本の気候・自然災害:230

世界と日本の地形:200

世界と日本の気候・自然災害:233 世界と日本の地形:208

世界と日本の気候・自然災害:228

世界と日本の地形:210

世界の地域区分と特色:12

オセアニア:158

日本の地域区分:184

世界と日本の気候・自然災害:218

世界と日本の人口:242 世界と日本の人口:254

世界の地域区分と特色:16

世界の地域区分と特色:15 世界の地域区分と特色:18

地球のすがた:3

世界の地域区分と特色:19 世界の地域区分と特色:11世界の地域区分と特色:10

世界の地域区分と特色:14

世界の地域区分と特色:13 世界の地域区分と特色:17

世界と日本の資源・エネルギー:266

世界と日本の資源・エネルギー:265

世界と日本の資源・エネルギー:260

世界と日本の資源・エネルギー:267

日本の工業と商業・サービス業:280

オセアニア:153

地球のすがた:1

地球の姿

地球のすがた:7

地球のすがた:9

地球のすがた地:球8 のすがた:6

地球のすがた:5

地球のすがた:2

地球のすがた:0 地球のすがた:4

アジア①:49

世界と日本の資源・エネルギー:261
世界と日本の資源・エネルギー:256 世界と日本の資源・エネルギー:259
世界と日本の資源・エネルギー:257

世界と日本の人口:248

オセアニア:160

オセアニア:162

アジア②:61

九州地方:303

世界と日本の資源・エネルギー:263 世界と日本の資源・エネルギー:255
世界と日本の資源・エネルギー:262 世界と日本の資源・エネルギー:258
世界と日本の資源・エネルギー:264

九州地方:300 世界と日本の人口:250
九州地方:304

世界と日本の人口:241 世界と日本の人口:251 世界と日本の人口:243

世界と日本の人口:247

世界と日本の人口:246

世界と日本の人口:244 世界と日本の人口:249

世界と日本の人口:245

世界と日本の人口:252

オセアニア:148

オセアニア:151 オセアニア:149
オセアニア:154

オセアニア:156

オセアニア:161

オセアニア:159 オセアニア:150

オセアニアオセアニア:157

オセアニア:152

オセアニア:155

アジア②:58

世界と日本の人口:253

九州地方:297 九州地方:296

日本の工業と商業・サービス業:287 九州地方:305

アジア

アジア②:64

アジア②:62

アジア②:54 アジア②:57

アジア②:59

アジア②:60

アジア②:56 アジア②:55

アジア②:63

九州地方:299 九州地方:306

九州地方:298

九州地方:301 九州地方:302

九州地方:307

図 5.4: 中学地理の知識間関係ネットワーク

中学地理のネットワークを図 5.4 に示す．多くのノードが内容ごとでクラスタを 形成している．特に，ヨーロッパ，南アメリカ，アジア，オセアニア等，世界の各 地域の内容はそれぞれでクラスタを形成している．また，中央のオレンジから右 上にかけて緩やかに結合しているノード群は日本あるいは日本と世界との関連に ついての内容となっている．
中学歴史 中学歴史のネットワークを図 5.5 に示す．多くのノードが内容ごとでクラスタを
形成している一方で，中央にノードが雑多な形で集まっている．中央の雑多なノー ド群は主に安土桃山時代，江戸時代，ルネサンス時代，大航海時代，市民革命，産 業革命等に関するものであるが，日本の安土桃山時代（1573 年から 1603 年），江
65

第 5 章 実験

室町時代②:267

室町時代②:264

室町時代②:265

室町時代

室町時代②:268
室町時代②:272 室町時代②:271
室町時代②:270

室町時代②:279

室町時代②:280

室町時代②:273

室町時代②:266 室町時代②:263

室町時代②:277

江戸時代④:11

室町時代②:269 室町時代①:254

室町時代

室町時代①:261

室町時代①:2室60町時代①:258 室町時代①:262

室町時代①:253

室町時代①:256

室町時代①:255

室町時代①:252

室町時代①:251 室町時代②:278

鎌倉時代②:250

鎌倉時代②:232

鎌倉時代②:244

鎌倉時代②:239 鎌倉時代②:234

鎌倉時代②:247

鎌倉時代②:233

鎌倉時代②:241 鎌倉時代②:242

鎌倉時代②:245 鎌倉時代②:249

鎌倉時代②:240 鎌倉時代②:248

鎌倉時代②:235

鎌倉時代②:243

鎌倉時代

鎌倉時代②:246

江戸時代

江戸時代④:7 江戸時代④:13
江戸時代④:4

江戸時代④:10 江戸時代④:3

江戸時代④:8

江戸時代④:2

江戸時代④:0

江戸時代④:9 江戸時代④:6

江戸時代④:5

大和時代②:170 大和時代②:171

大和時代②:167

大和時代②:166 大和時代②:168

江戸時代⑤:28 大和時代②:165

大和時代②:169

大和時代②:162

江戸時代④:12

大和時代①:147

大和時代②:159

大和時代①:149 大和時代①:156

大和時代②:163

大和時代①:155

大和時代①:157

大和時代①:153

大和時代①:150

江戸時代⑤:27

江戸時代⑤:20

江戸時代⑤:25

江戸時代⑤:29

江戸時代⑤:17 江戸時代⑤:19

江戸時代⑤:22

江戸時代⑤:21

江戸時代⑤:30

江戸時代⑤:18 江戸時代⑤:15
江戸時代⑥:42

欧米の市民革命:56

欧米の市民革命:53

欧米の市民革命:52 欧米の市民革命:55

欧米の市民革命:48 欧米の市民革命:47
欧米の市民革命:54

欧米の市民革命:51

欧米の産業革命:60 欧米の市民革命:57

欧米の市民革命:49

江戸時代⑤:14

欧米の産業革命:67

ルネサンスと大航海時代:291

欧米の産業革命:63

欧米の産業革命:68

欧米の産業革命:65

ルネサンスと大航海時代:281 欧米の産業革命:59

欧米の産業革命:62

欧米の産業革命:61

欧米の産業革命:69

安土桃山時代:317 安土桃山時代:312
安土桃山時代:303

安土桃山時代:314

安土桃山時代安:3土1桃5山時代:311

安土桃山時代:308

欧米の市民革命:46

安土桃山時代:309 江戸時代⑤:26

江戸時代⑤:31

室町時代②:275 安土桃山時代:306

安土桃山時代:316

欧米の産業革命:64

欧米の市民革命:50

ルネサンスと大航海時代:283

安土桃山時代:302

大和時代②:164

欧米の産業革命:58

欧米の産業革命:66

大和時代②:161

欧米の産業革命:70

世界文明の発生:117 明治時代①:97

室町時代①:257 室町時代①:259
旧石器・縄文

世界文明の発生:123 世界文明の発生:124

世界文明の発生:116

世界文明の発生:126 世界文明の発生:115

世界文明の発生:120

世界文明の発生:122

世界文明の発生:125

世界文明の発生:119

世界文明の発生:121

江戸時代⑤:23

世界文明の発生:118

旧石器・縄文・弥生時代:132 世界文明の発生:112
旧石器・縄文・弥生時代:128 世界文明の発生:114

・弥生時代

旧石器・縄文・弥生時代:145

旧石器・縄文・弥生時代:140

旧石器・縄文・弥旧生石時器代・:1縄4文4 ・弥生時代:143

旧石器・縄文・弥生時代:137

旧石器・縄文・弥生時代:134 旧石器・縄文・弥生時代:139

旧石器・縄文・弥生時代:141

旧石器・縄文・弥生時代:133

旧石器・縄文・弥生時代:142 旧石器・縄文・弥生時代:138

旧石器・縄文・弥生時代:130

旧石器・縄文・弥生時代:129

旧石器・縄文・弥生時代:127 旧石器・縄文・弥生時代:131

旧石器・縄文・弥生時代:136

大和時代①:152

大和時代①:148

大和時代①:151

江戸時代⑥:40

大和時代①:154

安土桃山時代:310 大和時代②:160

江戸時代⑦:85 江戸時代⑦:76

安土桃山時代:304

安土桃山時代:313

ルネサンスと大航海時代:290 ルネサンスと大航海時代:282

ルネサンスと大航海時代:299

安土桃山時代:305 ルネサンスと大航海時代:289 ルネサンスと大航海時代:300

ルネサンスと大航海時代:295

ルネサンスと大航海時代:292 ルネサンスと大航海時代:301

室町時代②:274

江戸時代②:340

世界文明の発生:113

江戸時代⑤:24

明治時代②:101

ルネサンスと大航海時代:286

安土桃山時代ル:3ネ07サンスと大航海時代:294ルネサンスと大航海時代:288

江戸時代②:332

ルネサンスと大航海時代:284

ルネサンスと大航海時代:285

ルネサンスと大航海時代:296

ルネサンスと大航海時代:293

江戸時代⑤:16 ルネサンスと大航海時代:297

明治時代①:94

室町時代②:276

旧石器・縄文・弥生時代:135

鎌倉時代②:237

鎌倉時代②:236

鎌倉時代②:238

大和時代②:158

江戸時代④:1

江戸時代⑦:72 大和時代①:146

江戸時代①:322

江戸時代①:323

江戸時代①:325 江戸時代①:328
江戸時代①:329

江戸時代①:319 江戸時代③:360

ルネサンスと大航海時代:298 江戸時代②:337 江戸時代②:339

江戸時代①:324

江戸時代③:351

平安時代②:217

平安時代②:202 ルネサンスと大航海時代:287

江戸時代①:318

江戸時代①:321

江戸時代②:334 欧米の産業革命:71

江戸時代①:327

江戸時代①:320

江戸時代①:326

江戸時代②:336

江戸時代②:331

江戸時代②:333

江戸時代③:346

江戸時代②:342

江戸時代②:335

江戸時代③:354

江戸時代③:362

明治時代①:95

明治時代①:98 明治時代①:99

明治時代①:90
明治時代①:93 明治時代①:89

明治時代①:91

明治時代①:88 明治時代①:96
平安時代②:208

江戸時代②:341

明治時代②:111

平安時代②:210

平安時代②:204 平安時代②:211
明治時代①:92

平安時代②:215

平安時代②:212

平安時代②:213 平安時代②:216
平安時代②:214

平安時代②:209

平安時代②:203

平安時代②:205

平安時代②:206

平安時代②:207

平安時代

江戸時代⑦:82

江戸時代⑦:78 江戸時代⑦:73
江戸時代⑦:74

江戸時代⑦:75

江戸時代⑦:87 江戸時代⑦:86
江戸時代⑦:79

江戸時代⑦:77

江戸時代⑦:80

江戸時代⑦:81

江戸時代 江戸時代⑦:83

鎌倉時代①:224

江戸時代⑦:84

鎌倉時代①:228

鎌倉時代①:225

鎌倉時代①:218

鎌倉時代①:220

鎌倉時代①:222

鎌倉時代①:230 鎌倉時代①:231

鎌倉時代①:223 鎌倉時代①:221
鎌倉時代①:229 鎌倉時代①:227
鎌倉時代

鎌倉時代①:226 江戸時代③:356

江戸時代③:359

明治時代②:107

江戸時代③:352

江戸時代③:345 江戸時代③:343

江戸時代③:353 江戸時代③:358
江戸時代②:338

江戸時代②:330

江戸時代③:355 江戸時代③:348

江戸時代③:349

江戸時代③:350 江戸時代③:344
江戸時代③:347

明治時代②:100

江戸時代③:363
明治時代②:103 明治時代②:105
明治時代②:104 明治時代②:102 明治時代②:108
江戸時代③:357 明治時代②:110

明治時代②:109 明治時代②:106

鎌倉時代①:219

奈良時代:174

江戸時代③:361

奈良時代:173

奈良時代:190

奈良時代:176

奈良時代:180

奈良時代:177

奈良時代:172
奈良時代 奈良時代:175

奈良時代:182 奈良時代:189

奈良時代:183

奈良時代:185

奈良時代:184 奈良時代:188 奈良時代:187
奈良時代:186 奈良時代:179

奈良時代:181

奈良時代:178

江戸時代⑥:43 江戸時代⑥:37

平安時代
平安時代①:192

江戸時代⑥:44 江戸時代⑥:39

江戸時代⑥:34

江戸時代⑥:36

江戸時代⑥:32

平安時代①:191

平安時代①:195 平安時代①:197

平安時代①:200 平安時代①:201 平安時代①:198
平安時代①:196

平安時代①:194

平安時代①:193 平安時代①:199

江戸時代⑥:41

江戸時代⑥:45

江戸時代⑥:35
江戸時代江戸時代⑥:38

江戸時代⑥:33

図 5.5: 中学歴史の知識間関係ネットワーク

66

戸時代（1603 年から 1867 年）の年代と，欧米諸国のルネサンス時代（14 世紀か ら 16 世紀），大航海時代（15 世紀から 17 世紀），市民革命（18 世紀），産業革命 （18 世紀から 19 世紀）の年代が概ね合致していることが興味深い．
次に，手続き的的知識について知識間関係ネットワークを順に可視化していく．

小学 4 年算数
小学 4 年算数のネットワークを図 5.6 に示す．一部のノードがクラスタを形成し ている．小学 4 年社会や小学 5 年社会のネットワークと比べると，クラスタの形成 度合いは小さいように見られる．特に，青色のノードが中央に寄っていて，外側 に出ているノードはオレンジや赤色のノードが多いことも 1 つの特徴であると考 えられる．このことは，着手される順序が遅い問題の方がネットワークの中心に なく，つまり影響を与える問題が少ないことを示唆している．

小学 5 年算数 小学 5 年算数のネットワークを図 5.7 に示す．全体としてノードは複雑に結合し
ており，モジュール性は低そうである．また，ごく一部のノードが他のノードと 66

第 5 章 実験

67

式と計算②:160

式と計算②:158

式と計算

式と計算②:156

式と計算②:155

式と計算②:157

式と計算②:154

式と計算②:153 式と計算②:151

式と計算②:150 式と計算②:152

いろいろな四角形②:64 いろいろな四角形②:65

四角形

いろいろな四角形②:63

いろいろな四角形②:62 いろいろな四角形②:67

いろいろな四角形②:61 いろいろな四角形②:66

いろいろな四角形②:60
２けたでわるわり算②:119 ２けたでわるわり算②:118 ２けたでわるわり算②:116
２けたでわるわり算②:117
２けたでわるわり算②:115

小数

小数②:95

おれ線グラフ②:33 おれ線グラフ②:32
おれ線グラフ②:31

角②:41

角②:43 角②:47

角②:44 角②:46

小数②:94

いろいろな四角形①:53

いろいろな四角形①:50

いろいろな四角形①:52

いろいろな四角形①:51

いろいろな四角形①:54

いろいろな四角形①:56

いろいろな四角形①:57 角②:42

いろいろな四角形①:49 小数②:93 ２けたでわるわり算①:104

おれ線グラフ①:20

おれ線グラフ①:21 おれ線グラフ①:お25れ線グラフ①:24

おれ線グラフ①:22 おれ線グラフ②:29

おれ線グラフ②:30

おれ線グラフ①:26

おれ線グラフ①:28

おれ線グラフ①:27

２けたでわるわり算②:110

がい数②:139

おれ線グラフ①:23 大きい数①:9

がい数②:133

角②:45
２けたでわるわり算②:114 いろいろな四角形②:58 ２けたでわるわり算②:113

式と計算②:159

２けたでわるわり算②:11い2 ろいろな四角形①:55

２けたでわるわり算②:111

いろいろな四角形②:59

２けたでわるわり算①:106 ２けたでわるわり算①:108
２けたでわるわり算①:107

２けたでわるわり算①:105
式と計算①:140 式と計算①:144

２けたでわるわり算①:102

がい数②:137

大きい数②:10

いろいろな四角形①:48

２けたでわるわり算①:109

式と計算①:143

２けたでわるわり算①:103 大きい数①:5

大きい数①:1

大きい数①:8

大きい数①:2

大きい数②:15

大きい数①:0

大きい数②:11 大きい数①:7

がい数②:132

がい数②:135 がい数②:136

がい数②:134

がい数②:138

がい数②:131

がい数②:130

大きい数①:4

大きい数②:18 大きい数②:19

小数②:99

小数②:98

小数②:101

小数②:96

小数②:97 式と計算①:142

小数②:100

式と計算①:148

式と計算①:141

式と計算①:149

式と計算①:145 式と計算①:147

式と計算①:146

角①:35

角①:34

角①:38

1けたでわるわり算①:68

角①:36 角①:40

角①:39

角①:37

小数②:92

大きい数①:6 大きい数①:3
がい数①:120

大きい数②:17

大きい数②:16

大きい数②:13 大きい数②:12
大きい数②:14

がい数①:124

がい数①:129

がい数①:123 がい数①:125

がい数①:127 がい数①:128

がい数①:122

がい数①:126

がい数①:121

1けたでわるわり算①:69

1けたでわるわり算①:711けたでわるわり算②:74

1けたでわるわり算①:70

小数①:91 1けたでわるわり算②:75

小数①:86

小数①:89

小数①:83

1けたでわるわり算①:73 1けたでわるわり算②:76 1けたでわるわり算②:77

小数

小数①:90

小数①:85

小数①:87 小数①:84
小数①:88

小数①:82

1けたでわるわり算②:78 1けたでわるわり算②:79 1けたでわるわり算②:81
1けたでわるわり算②:80
一桁の割算

1けたでわるわり算①:72

面積①:170

面積①:163 面積①:167

面積①:164 面積①:162
面積②:172
面積①:161

面積①:168

面積①:165

面積

面積①:169 面積①:166
面積①:171

面積②:177

面積②:173

面積②:175

面積面積②:181

面積②:176

面積②:174

面積②:180 面積②:178

面積②:179

図 5.6: 小学 4 年算数の知識間関係ネットワーク

倍数・約数・比例・割合

倍数と約数(1):113 倍数と約数(1):112

比例(2):201

倍数と約数(1):110

倍数と約数(1):111 割合とグラフ(2):248

分数のかけ算とわり算(2):171

分数のかけ算とわり算(1):159 分数のかけ算とわり算(1):161
分数のかけ算とわり算(1):158 分数のかけ算とわり算(1):162
分数のかけ算とわり算(1):160

分数のかけ算とわり算(1):164
分数の積と商分数のかけ算とわり算(1):165 分数のかけ算とわり算(1):166
分数のかけ算とわり算(2):169 分数のかけ算とわり算(1):163 分数のかけ算とわり算(1):167

分数のかけ算とわり算(2):168

図形の面積(1):176 図形の面積(1):178

倍数と約数(1):114

倍数と約数(1):109

図形の面積(1):175

比例(2):205

小数のわり算(1):7小3 数のわり算(1):70

小数のわり算(1):71 小数のわり算(1):75

小数のわり算(1):74

小数のわり算(1):72

小数のわり算(1):76

単位量当たりの大きさ:28
小数のわり算(2):81 単位量当たりの大きさ:23
単位量当たりの大きさ単:2位5 量当たりの大きさ:27 単位量当たりの大きさ:29

正多角形と円(1):215

正多角形と円(2):217

立体(2):238

分数(2):128 分数(2):130

割合とグラフ(1):240

分数(1):126 分数(1):121

分数(1):125 分数(1):127
分数分数(1):124
分数(1):122

図形の面積(1):180

図形の面積(1):177

図形の面積(1):184

図形の面積(1):181

図形の面積(1):179

倍数と約数(1):108

図形の面積(1):183

図形の面積(1):182

図形の面積(2):189

図形の面積(2):192

割合とグラフ(1):245

小数のわり算(1):77

小数のわり算(1):79

小数のわり算(1):78

図形の面積(2):190

立体(1):226

単位量当たりの大きさ:22

小数のわり算(2):80

単位量当たりの大きさ:20

単位量当たりの大きさ:26

図形の面積(2):188 割合とグラフ(2):250

単位量当たりの大きさ:24 単位量当たりの大きさ:21

図形の面積(2):191

比例(2):198

立体(2):232

小数のわり算(2):82

平均:18

平均:16 平均:15

平均:17 平均:19

分数(2):129 正多角形と円(2):220

分数(2):131

分数(2):136

分数(2):132 分数(2):133

分数(2):135

分数(1):120

正多角形と円(1):208

分数(2):134 正多角形と円(1):211

分数(1):123

割合とグラフ(1):241

小数のかけ算(2):48

小数のかけ算(2):47

小数のかけ算(2):45

小数のかけ算(2):46

小数のかけ算(2):49

小数のかけ算(2):41 立体(2):233

正多角形と円(1):206 分数のたし算とひき算(1):138

平均:11

平均:14 平均:12

平均:13

正多角形と円(2):222

分数のかけ算とわり算(2):170

三角形と四角形の角:69

三角形と四角形の角:68

三角形と四角形の角:67 三角形と四角形の角:65

三角形と四角形の角:66

三角形と四角形の角:64

小数のかけ算(2):43

立体(1):224

小数のかけ算(2):40

小数のかけ算(2):42

小数のかけ算(2):44

小数のかけ算(1):35

小数のかけ算(1):37

図形の面積(2):187

平均:10

比例(2):200

小数のかけ算(1):36

割合とグラフ(1):239

小数のかけ算(1):39 割合とグラフ(2):251
割合とグラフ(2):247 割合とグラフ(2):252 正多角形と円(2):219
比例(2):202

正多角形と円(2):216

図形の面積(2):186

図形の合同と角:51

割合とグラフ(1):246

割合とグラフ(1):244

図形の合同と角:52

正多角形と円(1):207 立体(1):230

割合とグラフ(1):242

分数のかけ算とわり算(2):172

正多角形と円(2):218

正多角形と円(1):213 分数のたし算とひき算(2):157

図形の合同と角:50 分数のかけ算とわり算(2):173
割合とグラフ(2):253

分数のたし算とひき算(1):139 三角形と四角形の角:62

三角形と四角形の角:63 正多角形と円(2):221

三角形と四角形の角:60

三角形と四角形の角:61

小数のかけ算(1):30

小数のかけ算(1):31 小数のかけ算(1):34
小数のかけ算(1):32

立体(2):236

比例(2):199

図形の合同と角:54

倍数と約数(1):107

小数と整数:9

倍数と約数(2):115 小数のかけ算(1):38 倍数と約数(2):118

割合とグラフ(2):255
分数のたし算とひき算(1):137 立体(2):237

分数のたし算とひき算(2):151 分数のたし算とひき算(2):153

分数のたし算とひき算(1):141

割合とグラフ(2):254

分数のたし算とひき算(1):145

分数のたし算とひき算(1):142

小数のかけ算(1):33 比例(2):203

図形の面積(2):185 比例(1):194

割合とグラフ(2):249

正多角形と円(1):210

体積(1):90

倍数と約数(2):117 倍数と約数(2):116
倍数と約数(2):119

割合とグラフ(2):256

図形の合同と角:53

正多角形と円(1):212

立体(1):227

分数のたし算とひき算(2):152

図形の合同と角:55

分数のたし算とひき算(2):155

分数のたし算とひき算(1):143 分数のたし算とひき算(2):154

分数のたし算とひき算(1):144 分数のたし算とひき算(1):146

小数のわり算(2):84 小数のわり算(2):83
小数のわり算(2):86
正多角形と円(2):223
分数のたし算とひき算(1):140

比例(1):195 比例(1):196

比例(1):197

立体(2):235

立体(1):225

比例(2):204

小数と整数:5

小数と整数:7 小数と整数:6

小数と整数:8 分数のたし算とひき算(2):147

小数と整数:1 割合とグラフ(1):243

比例(1):193

小数と整数:4 小数と整数:2
小数と整数:0

立体(1):229

分数のかけ算とわり算(2):174

体積(1):98

体積(1):92 体積(1):95

体積(1):97 体積(1):96

正多角形と円(1):209

図形の合同と角:56 分数のたし算とひき算(2):150

分数のたし算とひき算(2):149

正多角形と円(1):214

図形の合同と角:57

分数のたし算とひき算(2):148

図形の合同と角:58 図形の合同と角:59

立体(2):231 体積(1):99

立体(1):228

分数のたし算とひき算(2):156

小数のわり算(2):85

小数の商

小数のわり算(2):88 小数のわり算(2):87 小数のわり算(2):89

体積(2):105

体積(2):106 体積(2):104
体積

立体(2):234

小数と整数:3

体積(1):91

体積(1):94

体積(2):103

体積(2):100

体積(2):102

体積(2):101

体積(1):93

図 5.7: 小学 5 年算数の知識間関係ネットワーク

比べて大きく，つまり，出力次数が大きい．このことは，これらの大きいノードに よって表現される知識は多くの知識の獲得に影響を与えていることを示唆してい る．特に，大きいノードは平均や小数，整数に関する問題で，かつ，着手順序が
67

第 5 章 実験

68

早いものであることも大きな特徴である．クラスタという観点では，小さなクラ スタを形成しているノード群は小数や分数，あるいは体積に関するノードである ことが特徴的である．

小学 6 年算数

小数と分数の計算(2):104 小数と分数の計算(2):106
小数と分数の計算(2):105 小数と分数の計算(2):102

小数と分数

小数と分数の計算(2):101

小数と分数の計算(2):103

小数と分数の計算(2):100

比例と反比例(1比):例20と9反比例(1):207 比例と反比例(1比):例20と8反比例(1):210

分数のわり算(2):75

分数のわり算(2):77 分数のわり算分(数2)の:7わ9 り算(2):78

分数のわり算(2):74
分数の商

分数のわり算(2):70

分数のわり算(2):76

分数のわり算(2):71

分数のわり算(2):73

分数のわり算(1):64

分数のわり算(1):67

分数のわり算(1):68

分数のわり算(1):65

分数のわり算(1):60

分数のわり算(1):62

分数のわり算(1):69

分数のわり算(1):66

分数のわり算(1):61

分数のわり算(1):63
分数の商

分数のわり算(2):72 量と単位(2):241

倍と割合:82

倍と割合:80

円の面積(2):124
円の面積(2):123
円の面積(2):122 円の面積(2):121

円の面積(2):125

円の面積(1):112

円の面積(1):113

円の面積(1):114

円の面積(1):111

円の面積(2):120 円の面積(2):119
円の面積(2):118

立体の体積(2):167

円の面積(1):115 円の面積(1):117

円の面積(1):110

円の面積(1):109

量と単位(2):239

円の面積(1):116

円の面積(1):108

比例と反比例(1):204

比例と反比例(1):203

文字と式(2):39 文字と式(2):38

文字と式(2):35

文字と式(2):37

量と単位(2):237

比例と反比例(1):205

文字と式(2):36 文字と式(2):33

比例と反比例(1):206

比例と反比例(1):211

拡大図と縮図(1):188

量と単位(1):232

文字と式(2):34

文字と式(2):32

量と単位(2):240

量と単位(2):238

資料の調べ方:220 立体の体積(2):165

立体の体積(1):158

立体の体積(1):160 立体の体積(1):159

立体の体積(1):15立7体の体積(1):156

文字と式(2):31

資料の調べ方:219 分数のかけ算(2):52

量と単位(2):244 分数のかけ算(2):51

量と単位(2):242

立体の体積(2):164

分数のかけ算(2):50

立体の体積(2):161

資料の調べ方:223

円の面積(1):107

立体の体積(2):162

分数のかけ算(2):55

分数のかけ算(2):54

分数のかけ算(2):53

分数のかけ算(2):58

分数のかけ算(2):59

分数のかけ算(2):57

分数のかけ算(2):56

量と単位(2):243

資料の調べ方:225

立体の体積(2):163 資料の調べ方:221

量と単位(1):231

文字と式(1):26

文字と式(1):25

小数と分数の計算(1):90

立体の体積(2):166

拡大図と縮図(1):187

比とその利用(2):178

文字と式(2):30

文字と式(1):29

資料の調べ方:226

比とその利用(2):177

比とその利用(2):184 資料の調べ方:224

比とその利用(2):183

文字と式(1):27

拡大図と縮図(1):193 比とその利用(2):179
量と単位(1):229
比とその利用(2):181 拡大図と縮図(1):185
資料の調べ方:222
比とその利用(2):180

速さ(2):152

速さ(2):155

速さ(2):151

速さ(2):154

速さ(2):150

速さ

速さ(2):153

速さ(1):149 速さ(1):148

速さ(1):144

速さ(1):147 速さ(1):146
速さ(1):143

速さ(1):145

速さ(1):142

拡大図と縮図(2):197

拡大図と縮図(2):198

拡大図と縮図(2):199

拡大図と縮図(2):200 拡大図と縮図(2):201

拡大図と縮図(2):195

拡大図と縮図(2):194

拡大図と縮図(1):190

拡大図と縮図(2):196

拡大図と縮図(1):189

拡大図と縮図(1):186 拡大図と縮図(1):192

線対称:1 比例と反比例(1):202
量と単位(1):227

線対称:8

線対称:9 量と単位(2):235

拡大図と縮図(1):191

量と単位(1):228

線対称:3

線対称:7

線対称:6

線対称:5

線対称:0

線対称:4
点対称:14

線対称:2 点対称:11

比とその利用(1):174

比とその利用(1):168 比とその利用(1):171

比とその利用(1):169 比とその利用(1):175 比とその利用(1):173 比とその利用(1):176

点対称:16 点対称:10

点対称:12

点対称:13

点対称:15

比例と反比例(2):212

点対称:17

点対称:18

点対称:19

比とその利用(1):172

比とその利用(1):170

倍と割合:83

倍と割合:81

倍と割合 倍と割合:85

倍と割合:84 倍と割合:89

倍と割合:87

倍と割合:86

小数と分数の計算(1):92

倍と割合:88 小数と分数の計算(1):91

小数と分数の計算(1):94

小数と分数の計算(1):98

小数と分数の計算(1):93

小数と分数の計算(1):95

小数と分数の計算(1):97 小数と分数の計算(1):96
小数と分数

小数と分数の計算(1):99

文字と式(1):24

量と単位(1):233

文字と式(1):28

文字と式(1):23

文字と式(1):22

文字と式(1):20

比とその利用(2):182

分数のかけ算(1):40

量と単位(2):236

文字と式(1):21

ならべ方と組み合わせ方(2):136

ならべ方と組み合わせ方(2):135

分数のかけ算(1):44

量と単位(1):230 量と単位(1):234

比例と反比例(2):214 比例と反比例(2):215

比例と反比例(2):216 比例と反比例(2):213

比例と反比例(2):218 比例と反比例(2):217

ならべ方と組み合わせ方(1):126

ならべ方と組なみら合べわ方せと方組(2み):合14わ1せ方(2):140 ならべ方と組み合わせ方(2):139
ならべ方と組み合なわらせべ方方(2と):1組3み7 合わせ方(2):138

ならべ方と組み合わせ方(1):130

ならべ方と組み合わせ方(1):134

ならべ方と組み合わせ方(1):1な2ら7 べ方と組み合わせ方(1):128

ならべ方と組み合わせ方(1):129

ならべ方と組み合わせ方(1):133

順列と組み合わせ

ならべ方と組み合わせ方(1):132

ならべ方と組み合わせ方(1):131

分数のかけ算(1):42

分数のかけ算(1):43

分数のかけ算(1):41

分数のかけ算(1):45

分数のかけ算(1):48

分数の積分数のかけ算(1):46 分数のかけ算(1):47

分数のかけ算(1):49

図 5.8: 小学 6 年算数の知識間関係ネットワーク

小学 6 年算数のネットワークを図 5.8 に示す．全体としてノードは複雑に結合し ているが，一方で一部は小さなクラスタを形成している．特にクラスタを形成す るノード群の内容は左のクラスタのノード群が小数や分数，それらの積や商の活 用が求められる内容で，下のクラスタのノード群が順列と組み合わせに関する内 容で，右上のクラスタのノード群が速さに関する内容となっている．また，中央の ごく一部ノードが青色で他のノードと比べて大きいことも大きな特徴である．こ のことは，最初に獲得した知識が他の多くの知識の獲得に影響をもつことを示唆 している．

68

第 5 章 実験

加法と減法の混じった式:47

比例式:158

比例式:162 比例式とその活用:160

加法と減法の混じった式の計算:49

加法と減法の混じった計算:48

比例式とその解き方:157 方程式と比:155

方程式と比:159

1次方程式の利用:147

1次方程式の利用:150

方程式の利用:149

方程式の活用:154

1次方程式の利用:151

加法と法則:24

方程式と比:161

四則の混じった式の計算:75

いろいろな計算:69 いろいろな計算:68

除法:74

四則の混じった計算:76

加法:23

四則の混じった計算:77

正の数，負の数の利用:51

加法:19

加法:20

加法と減法の混じった計算:46

数の大小:16

加法:22

加法:21

反対向きの性質をもった数量:6

加法:25

反対の性質をもつ量:0 正の数・負の数で量を表すこと:7

プラスとマイナス:1

比例式:156

減法:38

方程式と比:163

方程式の活用(1):146

正の数・負の数の加法，減法:36

度数の分布:340

加法と減法の混じった式の計算（１）:42

加法と減法の混じった計算:43 加法と減法の混じった式の計算:44

加法:27

立体の投影図:282 度数の分布:338
立体の体積:324

1次方程式の利用:153

方程式の活用:148

度数の分布:339

減法の規則:35

近似値と有効数字:362

範囲と代表値:352

方程式の利用:152

四則の混じった式の計算:72 四則の混じった式の計算:73

数の大小:13

反比例:203

式の表し方:79

符号のついた数:2

符号のついた数:5

比例のグラフ:186

数の大小:18

球の体積と表面積 回転体の体積:331 立体の展開図:299

加法と減法の混じった式の直計線算と:4角5:236

直線と角:239

乗法:53

２平面の関係 面の動き:277

２平面の関係 面の動き:278 減法の規則:33

立体の展開図:303

範囲と代表値:354 近似値と有効数字:358

度数の分布:341

減法:34 ２平面の関係 面の動き:279

減法:39

減法:41

加法:28

減法:40

近似値と有効数字:363

関係を表す式:127

不等式

文字を使った式の利用:128 関係を表す式:126

関係を表す式:123

大小の関係を表す式:125

大小関係を表す式:129

基本の作図:242 乗法と除法:67
四則:71

０より小さい数:3

比例の式の求め方:197
乗法と除法:66 関係を表す式:122

数の大小:11 乗法:55

乗法:57

数の集合と四則:78 数の大小:17

四則の混じった計算:70 累乗の計算:58

乗法:52

除法:63

乗法:60

数の大小:12

数の大小:15

数の大小:10 比例の式の求め方:194 乗法:54

乗法:59

比例の式を求める:196 移動させた図形ともとの図形:232

移動:228

立体の体積:322 いろいろな移動:238

図形の基礎:229

減法:32

立体の展開図:304 立体の投影図:288

近似値と有効数字:364 立体の展開図:298

いろいろな立体:253

立体の展開図:293 立体の投影図:284

立体の展開図:295 円とおうぎ形 いろいろな作図:252

立体の投影図:283

減法:37

立体の体積:317

減法:31

座標:181

図形の移動:234

近似値と有効数字:355 移動:235

特別な多面体:258 いろいろな立体:257

いろいろな立体:260

除法:65 正の数・負の数の乗法，除法:64

乗法:61

数の大小:8

数の大小:14

1次式と数の乗法，除法:106 正の数，負の数の利用:50
累乗の計算:56

対称移動:237 商の表し方:87 基本の作図:245

いろいろな作図:251 球の体積と表面積 回転体の体積:326 球の体積と表面積 回転体の体積:325
立体の投影図:289
直線と角:231 立体の展開図:297

基本の作図:241

いろいろな立体:255

おうぎ形:250

比例の式を求める:198

除法:62

直線や平面の平行と垂直:261

立体の表面積:305
立体の投影図:286 円とおうぎ形 いろいろな作図:248

加法:29

加法:26

立体の表面積:308

立体の投影図:287

加法:30 球の体積と表面積 回転体の体積:329

範囲と代表値:349 立体の展開図:292

範囲と代表値:345

図形の基礎:249

立体の投影図:285

立体の表面積:312

２平面の関係 面の動き:271

多角形で囲まれた立体:259

２平面の関係 面の動き:275 度数の分布:336

２平面の関係 面の動き:274 立体の表面積:306

立体の表面積:310

近似値と有効数字:356

等式と不等式:124

文字式の活用:104 1次式の計算(2):112

1次式と数の乗法:121 1次式と数の乗法:120 １次式と数との乗法:118

1次式の加法と減法:111

1次式の項と係数:109

1次式の加法，減法:110

1次式と数の乗法，除法:116

文字式と数の乗法，除法:119 1次式の計算(2):117

１次式を数でわる除法:113 1次式の計算(2):115

1次式の四則演算

1次式の加法，減法:108

数の大小:9
式を書くときの約束（１）:82 いろいろな作図:244
比例の式を求めること:189

1次式の計算(2):114 １次式の計算:107
式の値:99

１次式:105

直線や平面の平行と垂直:267 立体の展開図:301

方程式とその解:130
移動:233

いろいろな作図:247 座標:185

図形の移動:230 反比例する量:202 ２平面の関係 面の動き:273

いろいろな立体:256 範囲と代表値:353

座標:184

立体の体積:318

度数の分布:342

立体の展開図:296

いろいろな立体:254 比例の式を求めること:192

1次方程式の利用:145

度数の分布:343

近似値と有効数字:361

立体の体積:315

反比例のグラフ:213

立体の表面積:313

反比例のグラフ:214

立体の展開図:291

球の体積と表面積 回転体の体積:330

立体の表面積:311

２平面の関係 面の動き:272

数の集合と四則:4 いろいろな作図:246
方程式とその解:131

直線や平面の平行と垂直:263

比例のグラフ:187

文字式の表し方:86

座標:183

度数の分布:337 範囲と代表値:346

比例の式の求め方:191

文字式の表し方(2):88 球の体積と表面積 回転体の体積:327

反比例する量:200

比例のグラフ:188

反比例のグラフ 反比例の式を求める:209

反比例のグラフ（１）:210 反比例のグラフ:212

立体の体積:319 反比例のグラフ:217

反比例のグラフ 反比例の式を求める:211

反比例のグラフ:216 反比例のグラフ:215

方程式とその解:136

反比例の式:199

比例:176

直線や平面の平行と垂直:268 等式の性質:135

作図のしかた 垂直二等分線の作図:240

２平面の関係 面の動き:276

等式の性質:134

文字式の表し方:90

比例と反比例の利用:220

２平面の関係 面の動き:280

等式の性質:133

直線や平面の平行と垂直:270

直線や平面の平行と垂直:264 反比例する量:206

範囲と代表値:347

1次方程式の解き方(1):137 直線や平面の平行と垂直:262

等式の性質:132 いろいろな数量と文字式:91

範囲と代表値:348

いろいろな数量と文字式:98

数量の表し方:92

立体の体積:316 直線や平面の平行と垂直比:例26の5表，式，グラフの活用:227

いろいろな数量と文字式:89

反比例する量:205

近似値と有効数字:359

比例の式を求める:195 線分の垂直二等分線:243

反比例の式:201

比例と反比例の利用:219

立体の体積:321 立体の展開図:302

座標:182 立体の体積:320
立体の表面積:307 範囲と代表値:350

身のまわりの問題への利用:221 比例と反比例の利用:222

式の値:100

文字式の表し方(2):93 立体の投影図:290

反比例の式:204

度数の分布:344

度数の分布:335

関数:164

比例と反比例の利用:225

文字の利用、文字式の表し方(1):83

球の体積と表面積 回転体の体積:328

直線や平面の平行と垂直:269

文字を使った式の表し方:80

近似値と有効数字:360

立体の体積:323

反比例する量:207

比例:179

ともなって変わる２つの量:165 立体の展開図:294

反比例のグラフ:218

比例と反比例の活用:223

いろいろな数量と文字式／代入と式の値:102

式の値:103

文字式の表し方:84 文字の利用、文字式の表し方(1):85

文字式の表し方:95 球の体積と表面積 回転体の体積:332

反比例する量:208

比例の式を求める:193

立体の展開図:300

比例:190

比例と反比例の活用:224

いろいろな方程式:140

直線や平面の平行と垂直:266

式の値:101

文字式の表し方:97

立体の投影図:281

立体の表面積:314

比例する量:180 球の体積と表面積 回転体の体積近:33似3値と有効数字:357

いろいろな方程式:138 いろいろな方程式:139
方程式の解き方／いろいろな方程式:141
1次方程式の解き方:143 分数をふくむ１次方程式の解き方:142 いろいろな方程式:144
色々な方程式

式の表す意味:96

式の表し方:81

立体の表面積:309

比例:178

数量の表し方:94 球の体積と表面積 回転体の体積:334

比例する量:177

範囲と代表値:351

比例，反比例の活用:226

関数:166

関数:171

関数:170 関数:169

関数:167 関数:168

関数:174

比例する量:173

関数:175

２つの数量の関係の調べ方:172

図 5.9: 中学 1 年数学の知識間関係ネットワーク

69

中学 1 年数学
中学 1 年数学のネットワークを図 5.9 に示す．全体としてノードは複雑に結合し ており，小さなクラスタはほとんど存在しない．特筆すべき点は中央オレンジ色 の「方程式とその解」の内容を扱うノードが非常に大きく，出力次数が大きいこ とである．このことは，方程式とその解に関する知識が中学 1 年数学の学習にお いて非常に重要な位置付けにあることを示唆している．小さなクラスタを形成し ているノード群は不等式，1 次式の四則演算，色々な方程式に関する内容を扱うも のであった．

中学 2 年数学
中学 2 年数学のネットワークを図 5.10 に示す．全体としてノードは密に結合し ているものの，一部で緩やかにクラスタを形成している．連立方程式の活用や 1 次関数の活用がクラスタとなっている．活用に関する知識は，ある種特殊な事例 を扱うためほかへの適用可能性が低くモジュール性が高いのかもしれない．また， 右上の大きなノードが仮定や結論，証明に関する内容を扱うものであり，またそ の近傍にあるノード群が三角形の合同証明，2 線の並行証明等，証明の活用事例に
69

第 5 章 実験

多角形の外角:158

多角形の角:159

多角形の角

多角形の角:160

多角形の角:163

多角形の角:157

多角形の外角の和を求めよう:162

等式の変形:51

等式の変形:46

いろいろな連立方程式:66 かっこ，少数，分数をふくむ連立方程式:65
いろいろな連立方程式:68
連立方程式の解き方:63

連立方程式の解き方:59

いろいろな連立方程式:67 連立方程式の解き方:62

加減法による解き方:60 いろいろな四角形:244

連立方程式の解き方:61 連立方程式とその解:56

連立方程式の解き方:57

二等辺三角形になるための条件 定理の逆:202 平行線と面積:257
連立方程式とその解、連立方程式の解き方(1):53

いろいろな連立方程式:64

平行四辺形になる条件:235

多角形の内角と外角:155

等式の変形:45

三角形の角:149

二等辺三角形になるための条件 定理の逆:207 平行四辺形の性質:220

等式の変形:47

等式の変形:52

等式の変形:49

平行線と面積:251

多角形の内角と外角:156 多角形の角:146

連立方程式の活用

平行線と面積:253

特別な平行四辺形:243 2元1次方程式のグラフ:113

平行四辺形になる条件:234

連立方程式とその解:55

ことがらの起こりやすさ 確率の求め方(1):263 連立方程式とその解:54

２元１次方程式のグラフ:110

確率の求め方(2):266

多角形の角:161

平行線と面積:256

等式の変形:50

二等辺三角形になるための条件 定理の逆:198

平行四辺形の性質:218

直角三角形の合同:211

二等辺三角形:188 平行線と面積:248

等式の変形:48 二等辺三角形であるための条件:201 確率の求め方(2):267

平行四辺形:217 二等辺三角形になるための条件:205

証明のすすめ方(1):173

特別な平行四辺形:238

二等辺三角形であるための条件:199

証明のすすめ方(2):186

証明のすすめ方:184

ことがらの起こりやすさ 確率の求め方(1):258

二等辺三角形の性質:195

図形の性質の確かめ方:181 証明のすすめ方:178 直角三角形の合同条件:215

証明とそのしくみ:174

二等辺三角形になるための条件 定理の逆:204

証明のしくみ:185

証明のすすめ方:176

証明のすすめ方(1):177

多角形の内角と外角:154

二等辺三角形の性質:196 図形の性質の確かめ方:182

連立方程式の活用:73 連立方程式の活用(1):71
連立方程式の利用:72

連立方程式を使った問題の解き方:70

連立方程式の活用:81

連立方程式の活用:74

連立方程連式立の方活程用式:8の0 利用(2):77

連立方程式の利用:69

1次関数、1次関数の値の変化:86

1次関数:84

1次関数のグラフの特徴:91

1次関数の値の変化とグラフ:85

11次次関関数数:9の0グラフのかき方:108いろいろな四角形:241

方程式とグラフ:111

いろいろな四角形:246

確率の求め方(2):270

確率の求め方(2):265 三角形の角:150

いろいろな確率:277 いろいろな確率:274

直角三角形の合同:216

証明のすすめ方(2):179

三角形の角:148特別な平行四辺形:242

三角形の角:145

式による説明:41

文字を使った説グ明ラ:4フ4 と連立方程式:122

いろいろな三角形:189 平行四辺形の性質:2特2別4 な平行四辺形:245

二等辺三角形になるための条件 定図理形のの逆性:質20と8補助線:153

１次関数の表・式・グラフ:109

平行四辺形になる条件:233

文字を使った説明:43 特別な平行四辺形:239

平行四辺形:226

二等辺三角形になるための条件:206
仮定と結論:175

二等辺三角形:191 証明のしくみ:180
合同な図形:167

連立方程式の活用(2):78

2元1次方程式のグラフ:115

1次関数の式の求め方:107

直角三角形の合同条件:214

平行四辺形の性質:222

ことがらの起こりやすさ 確率の求め方(1):262

連立方程式の活用:76

１次関数のグラフ:95

１次関数のグラフ:98

1次関数:87 １次関数のグラフ:88

1次関数:83

二等辺三角形:190

平行線と面積:252

平行四辺形になるための条件:236

式の活用:39 文字式による説明:40

平行線と面積:250

直角三角形の合同条件:213

いろいろな角:135

連立方程式とグラフ:120

連立方程式の利用(2):75

いろいろな確率:275

連立方程式の活用(2):79

1次関数:89

一次関数のグラフ:96

2元1次方程式のグラフ:114

一次関数のグラフ:93

1次関数のグラフ(2):99 1次関数を表す式とグラフ:92
1次関数の値の変化とグラフ:97

一次関数のグラフ:101

いろいろな確率:273

一次関数:82 二等辺三角形:200

1次関数の式の求め方:103

いろいろな確率:276 1次関数の値の変化とグラフ:94

1次関数のグラフ(2):100

文字式の利用:42

一次関数の式を求めること:106

直線の式の求め方:105

１次関数のグラフのかき方:104

1次関数の求め方:102

二等辺三角形の性質:192

二等辺三角形の性質:197

平行四辺形:221 平行四辺形になる条件:230

平行四辺形になる条件:231

二等辺三角形:203

平行線と面積:249 確率の求め方(2):27平2行四辺形になるための条件:227

文字式による説明:38

直角三角形の合同条件:212

単項式と多項式、同類項:2

図形の性質の確かめ方:183

いろいろな四角形:247 平行四辺形になる条件:2三28角形の内角と外角:152

確率の求め方(2):264

角と平行線:139 連立方程式の解とグラフ:119
三角形の角:147

二等辺三角形:193 多角形の角:144 平行四辺形になるための条件:232

直角三角形の合同:209 合同な図形:164

証明
三角形の合同条件:171 合同な図形:165
合同な図形:166

三角形の合同:169 合同な図形:168

方程式とグラフ:112

式の値:36 いろいろな多項式の計算:37

三角形の角:194

証明のすすめ方(2):187

連立方程式の解き方(2):58

グラフと連立方程式:118

直角三角形の合同条件:210 確率の求め方(2):271
平行線と面積:255

ことがらの起こりやすさ 確率の求め方(1):259 連立方程式とグラフ:121

平行四辺形の性質:225

連立方程式とグラフ:117 連立方程式の解とグラフ:123 いろいろな多項式の計算:16 確率の求め方(2):269
特別な平行四辺形:237

特別な平行四辺形:240 平行線と角:142

ことがらの起こりやすさ 確率の求め方(1):260 単項式と多項式:1

式の乗法・除法:23

角と平行線:136 平行線と角:151
平行線と角:134 直線と角:138

平行線と角:137

平行四辺形:223

ことがらの起こりやすさ 確率の求め三方角(1形):の26合1同条件:172 平行線と角:141

合同な図形、三角形の合同条件:170

1次関数の利用:132

多項式と数との計算:13 平行線と面積:254

単項式の乗法，除法:34 2元1次方程式のグラフ:116

同類項:4

式の乗法・除法:22 単項式の乗法と除法、式の値:30

単項式と多項式:0

平行線と角:140

多項式と数の乗法，除法:14 単項式の乗法と除法:28

平行線と角:143

表，式，グラフの活用:125

1次関数の利用:130

１次関数と実験:126

一次関数の利用:124

１次関数の活用:131

式の加法，減法:5 単項式と多項式、同類項:8

多項式の計算:15

単項式の乗法と除法、式の値:29
多項式の計算(2):24 平行四辺形になるための条件:229

平行四辺形の性質:219

単項式の乗法と除法、式の値:32

多項式の計算(1):12

確率の求め方(2):268

１次関数の活用:127

１次関数の活用:128

1次関数の利用:129
1次関数の活用

1次関数の活用:133

式の乗法・除法:21 多項式の加法，減法:9

多項式の計算(2):26 多項式の計算(1):19 単項式と多項式、同類項:7 いろいろな計算:25
多項式の計算:18 多項式の加法，減法:6

同類項:3

多項式の計算:17 多項式の計算(2):27

単項式の乗法と除法:33

単項式の乗法，除法:31

単項式の乗法，除法:35

多項式の計算:10

多項式の計算(1):11

いろいろな多項式の計算:20

図 5.10: 中学 2 年数学の知識間関係ネットワーク

70

関する内容を扱うものであることも興味深い．証明という一般的な手続き的知識 が合同や並行への理解に大きな影響を与えることを示唆している．

中学 3 年数学
中学 3 年数学のネットワークを図 5.10 に示す．全体としてノードは複雑に結合 しており，一部が密になっているというようなクラスタはほとんど存在しない．中 央の青色のノードが非常に大きく，出力次数が大きい．このノードは単項式と多 項式の乗法除法に関する内容を扱うものであり，したがって，中学 3 年数学にお いて単項式と多項式に乗法除法に関する知識は非常に重要な位置付けにあること を示唆している．
以上，個々の知識間関係ネットワークを可視化した．全体として，ノードは内 容の関連度が大きいノードと結合しており，これらのネットワークは，確かに，知 識獲得における知識構造を表現しているものと考えられる．

70

第 5 章 実験

円周角の定理の逆 円周角と弧:312

式の活用:39

因数分解の公式(2):37 式の計算の利用:44
三平方の定理 三平方の定理の逆:270

標本調査とその利用:337

平行線と比:220

三平方の定理 三平方の定理の逆:266

因数分解:21

三角形の相似条件:207 円周角の定理相:3似05の利用:214

相似の活用:210

縮図の活用:215

中点連結定理:231

因数分解:20

相似の活用:212

平面図形への利用:274

三平方の定理 三平方の定理の逆:269

式の計算の利用:40

因数分解:27 相似な図形の面積比:250

関数y＝ａｘ^2の活用:1関7数0ｙ＝ａｘ^2の活用:174

相似な図形の相似比と面積比:252

相似な立体の表面積の比，体積の比:254 乗法の公式:17

2次方程式の活用:134

式の計算の利用:42

式の活用:41

関数y＝ａｘ^2:146

相似な立体の表面積の比，体積の比:262

関数y=ax^2の利用(2) いろいろな関数:２18次5方程式と問題づくり:130

2次方程式の活用:135

文字を使った証明:43

因数分解の公式:35

因数分解の公式:36

円と作図 円の接続:320

平方根:45

２次方程式とその解:95

測量への利用:213

乗法公式:13

2次方程式とその解:96

乗法公式の活用:19

三角形と平行線(1):221 いろいろな2次方程式:127

因数分解の公式:34 平面図形への利用:279

図形の証明

円周角の定理:301 円周角の定理:308
図形の相似:188

相似な図形:189

円周角の定理:306

平面図形への利用:275

円周角の定理の逆 円周角と弧:309

円周角の定理:299

中点連結定理:226 三角形の相似条件:200

関数 ｙ＝ａｘ^2:144

縮図の活用:211

多項式と単項式の乗除:2

平方根の考えを使った解き方:103 単項式と多項式の乗法，除法:1
平行線と線分の比:222

円と相似:327

関数ｙ＝ａｘ^2の値の変化:167 乗法公式:15

相似な図形とその性質:194

相似な図形の面積比:248

相似な立体の表面積の比や体積の因比:2数58分解の公式(2):32

相似の利用:209 関数ｙ＝ａｘ^2の変化の割合:166

公式による因数分解:28

相似の利用:208

平行線と線分の比:235 乗法の公式:10

関数y=ax^2の利用(1):171 展開の公式:16

相似な図形の性質:195 平方根の乗法、除法(2)／平方根の近似値:83 関数y=ax^2の利用(2) いろいろな関数:178

乗法公式の活用:18

公式による因数分解:30

相似な立体の表面積の比や体積の比:261 相似な立体の表面積の比や体積の比:260

相似な立体の体積:257 因数分解:33

三角形と比:223 関数ｙ＝ａｘ^2の活用:187

関数y=ax^2の利用(1):175

因数分解の公式の活用:38
平方根の乗法と除法:81 平面図形への利用:277
標本調査とその利用:342

三角形と比:219

相似の位置:191

平行線と線分の比:233

円周角の定理:304 相似な立体の表面積と体積:256

三角形の相似条件:206

円周角の定理の逆 円周角と弧:313

平面図形への利用:273

相似な図形の性質:193

円と相似:326

円周角の定理:303

標本調査とその利用:336

三角形の相似条件:204

三平方の定理 三平方の定理の逆:268

円周角の定理:302 相似な図形の相似比と面積比:243
平行線と比:234

相似な図形の面積比:246

(ｘ＋ａ)(ｘ­ａ)の展開:14

関数y=ax^2の利用(2) いろいろな関数:183

三角形の相似条件:202 三角形の相似条件:203
三角形の相似条件:199
三角形の相似条件:198

変化の割合の意味:168 単項式と多項式の乗法，除法:0

単項式と多項式の乗法、除法／多項式の乗因法数:5分解の公式:31 単項式と多項式の乗法，除法:3
相似な図形の面積:249
単項式と多項式の乗法，除法:6

相似な図形:197

三平方の定理 三平方の定理の逆:263

単項式と多項式の乗法，除法:4関数 ｙ＝ａｘ^2の利用:172

いろいろな問題:295 平方根とその表し方:50

相似な図形:190

平行線と線分の比:237

多項式の乗法:7

乗法公式:12

因数分解の公式:29

中点連結定理:227

多項式の乗法:8

中点連結定理:228 関数y=ax^2の利用(2) いろいろな関数:179

関数y=ax^2の利用(2) いろいろな関数:180

2次方程式の利用:136 二次方程式の利用:133

中点連結定理:232

円と作図 円の接続:319

因数分解の公式(1):22

因数分解を使った解き方:100 因数分解の公式:23

いろいろな2次方程式:122

２次方程式といろいろな問題:131
2次方程式の解き方（2）:118 二次方程式と因数分解:119

2次方程式の解き方（2）:121 円と相似:325 標本調査とその利用:334 中点連結定理:230
公式による因数分解:26
いろいろな２次方程式:125 標本調査とその利用:333
中点連結定理:229

素因数分解:63

素因数分解:68 素因数分解:66
三平方の定理 三平方の定理の逆:264

素因数分解:64

素因数分解:65

素因数分解:62

公式を利用する因数分解:24

素因数分解:69 因数分解の公式:25

いろいろな2次方程式:120

相似な図形:196

円周角の定理の逆 円周角と弧:311

相似な図形:192 三角形の相似条件:201

関数y=ax^2の利用(1):173 相似な立体の表面積の比や体積の比:253

三角形と比:217

円と相似:324

三角形の相似条件:205 平行線と線分の比:218
空間図形への利用:281

平行線と線分の比:216

関数y=ax^2の利用(2) いろいろな関数:184

三角形と比の定理の逆:225

相似な立体の表面積の比，体積の比:255
円周角の定理の逆 円周角と弧:315 2乗に比例する関数 y=ax^2:143

関数y=ax^2の値の変化と変域:163

根号をふくむ式の加法と減法:85 関数 ｙ＝ａｘ^2の値の変化:158

円と相似:322

平行線と線分の比:236

関数y=ax^2の変化の割合と平均の速さ:169

乗法公式:9

平方根の乗法，除法:72

関数y=ax^2の値の変化と変域:164

円周角の定理:298

空間図形への利用:280

^2乗に比例する関数:139

関数ｙ＝ａｘ^2のグラフ:151

平行線と比:241

^2乗に比例する関数:138

関数y=ax^2の利用(2) いろいろな関数:182 平方根の加法と減法:86 関数 ｙ＝ａｘ^2の値の変化:161

三平方の定理 三平方の定理の逆:267

関数ｙ＝ａｘ^2の値の変化:177

平方根の加法と減法:87

平行線と比:240
根号をふくむ式の計算:88 円周角の定理の逆 円周角と弧:310

平方根とその表し方:46

関数y=ax^2の利用(2) いろいろな関数:181

関数ｙ＝ａｘ^2の値の変化:162 乗法の公式:11

いろいろな問題:290

平面図形への利用:278

平行線と線分の比:239

三角形と比:224

円周角の定理:307

相似な図形の相似比と面積比:245

いろいろな問題:292

相似な平面図形の面積:247 円周角の定理:300

2次方程式の利用:128 平行線と線分の比:238

いろいろな問三題平:2方94の定理 三平方の定理の逆:265

円と相似:323

標本調査とその利用:340 三平方の定理 三平方の定理の逆:271

相似な図形の相似比と面積比:244

いろいろな２次方程式:126

2次方程式の活用:132

根号をふくむ式の乗法，除法:74

いろいろな2次方程式:123

いろいろな2次方程式:124

2次方程式の解き方（1）:104 平方根の考えを使った解き方:106

2次方程式とその解／因数分解による解き方:101
平方根の乗法・除法:84 空間図形への利用:286
平方根の性質:76

因数分解による解き方（２）:97

いろいろな問題:293 平方根の考え方を使った解き空間方図:形1へ0の5利用:282

2次方程式の活用:129 因数分解による解き方:99

因数分解による解き方:98

根号をふくむ式の乗法，除法:67

相似な図形の面積比:251 円周角の定理の逆 円周角と弧:314
平方根の乗法・除法:79

相似な立体の表面積の比，体積の比:259

円と三平方の定理:331
根号をふくむ式の乗法，除法:82 2次方程式の解き方（1）:115
二次方程式の解の公式:116 平方根の考えを使った解き方:107
空間図形への利用:288

関数y＝ａｘ^2のグラフ:152 関数 ｙ＝ａｘ^2:140
関数ｙ＝ａｘ^2のグラフ:148 関数ｙ＝ａｘ^2のグラフ:157

三角形の角の二等分線と比:242

平方根:48

空間図形への利用:283 平方根の乗法，除法:70

平方根:51

平方根:47

円と相似:328

平方根の考えを使った解き方:110 関数ｙ＝ａｘ^2の活用:186

いろいろな問題:2912次方程式の解き方（1）:109

関数ｙ＝ａｘ^2のグラフ:154 関数ｙ＝ａｘ^2:141
2乗に比例する関数 y=ax^2:147
関数y＝ａｘ^2:145 関数y＝ａｘ^2のグラフ:155

ｙ＝ａｘ^2のグラフ:156

２乗に比例する関数:142 標本調査とその利用:339

関数 ｙ＝ａｘ^2の値の変化:160

平方根の乗法，除法:73

円と作図 円の接続:321

関数ｙ＝ａｘ^2の値の変化:165

標本調査とその利用:335

関数y=ax^2の利用(1):176

平方根のいろいろな計算:90 根号をふくむ式のいろいろな計算:89

いろいろな問題:296

関数y＝ａｘ^2のグラフ:150

関数ｙ＝ａｘ^2のグラフ:149

円周角の定理の逆 円周角と弧:317

関数ｙ＝ａｘ^2のグラフ:153

根号をふくむ式のいろいろな計算:91

関数 ｙ＝ａｘ^2の値の変化:159 円と三平方の定理:平33方2根の大小／有理数と無理数:53

平方根:52

平方根の性質:71

空間図形への利用:284 根号をふくむ式の乗法と除法:75

平方根:49

有理数と無理数:58

円と作図 円の接続:318

円と三平方の定理:330

標本調査とその利用:341

2次方程式とその解／因数分解による解き方:102

解の公式:113

二次方程式の解の公式:114

平方根の乗法・除法:80

二次方程式の解の公式:117

平方根の考え方を使った解き方:108

平方根の考えを使った解き方:112 平方根の考えを使った解き方:111

根号をふくむ式の加減:93 根号をふくむ式の計算:92

空間図形への利用:285

平方根の加法，減法:94 円周角の定理の逆 円周角と弧:316
平面図形への利用:276

平方根の大小:57

いろいろな問題:297 平方根の値とその大小:54

空間図形への利用:289

円と三平方の定理:329

有理数と無理数:59 有理数と無理数:56
平方根の大小／有理数と無理数:55

空間図形への利用:287

平方根の乗法，除法:77

標本調査とその利用:338 平方根の乗法と除法:78

2次方程式の利用:137

有理数:60 平面図形へ平の方利根用の:大27小2／有理数と無理数:61

図 5.11: 中学 3 年数学の知識間関係ネットワーク

71

表 5.3: 各ネットワークにおける構造指標

ネットワーク

分類

科目

宣言的知識 の知識間関係 ネットワーク

地理・社会 歴史・社会

手続き的知識
の知識間関係 算数・数学 ネットワーク

学年 小学 4 年 小学 5 年
中学 小学 6 年
中学 小学 4 年 小学 5 年 小学 6 年 中学 1 年 中学 2 年 中学 3 年

モジュラリティ 値 平均
0.698 0.801 0.759 0.759 0.808 0.728 0.660 0.602 0.688
0.602 0.566 0.559 0.538

フロー階層 値 平均 0.579 0.541 0.633 0.627 0.607 0.774 0.590 0.757 0.705
0.756 0.805 0.830 0.847

GRC 値 平均 0.787 0.679 0.603 0.690 0.613 0.768 0.683 0.901 0.875
0.816 0.803 0.818 0.861

5.3.3 ネットワーク構造の分析
宣言的知識の知識構造を表現する 5 つのネットワークと手続き的知識の知識構 造を表現する 6 つのネットワークのモジュラリティとフロー階層，GRC を算出し，
71

第 5 章 実験

72

知識獲得における知識構造について，宣言的知識のモジュール性が手続き的知識 のモジュール性より統計的に有意に高く，逆に，手続き的知識の階層性が宣言的 知識の階層性より統計的に有意に高いことを示す．
表 5.3 に各ネットワークにおける各構造指標を整理した．まず，モジュラリティ について，いずれの宣言的知識の知識間関係ネットワークのモジュラリティもい ずれの手続き的知識の知識間関係ネットワークのモジュラリティよりも高かった． また，特に，手続き的知識の知識間関係ネットワークにおいては，学年が高いほ ど，モジュラリティが低い傾向にあり，つまり，難易度が高いほど知識のモジュー ル性が低い傾向にあることを示唆している．逆説的に，難易度がより高い問題と は扱われる知識のモジュール性がより低いということなのかもしれない．
次に，フロー階層について，手続き的知識の知識間関係ネットワークのフロー階 層の平均は宣言的知識の知識間関係ネットワークのフロー階層の平均と比べ，高 かった．このことは，手続き的知識の知識構造の方が宣言的知識の知識構造より も循環構造が少ないことを示唆している．また，手続き的知識と宣言的知識に限 らず，フロー階層は学年が高いほど高い傾向にあり，このことは，知識はその獲 得の難易度が高いほど循環構造が少ない傾向にあるか，あるいは，知識獲得の順 序性が強い傾向にあることを示唆している．
最後に，GRC について，手続き的知識の知識間関係ネットワークの GRC の平 均は宣言的知識の知識間関係ネットワークの GRC の平均と比べ，高かった．これ はフロー階層と同様である．一方で，GRC においてはフロー階層で見られた学年 の傾向は現れていないようである．
また，3 つの指標において，小学 4 年算数の知識間関係ネットワークの構造は他 の学年の算数や数学の知識間関係ネットワークの構造とは大きく異なる．具体的 には，小学 4 年算数の知識間関係ネットワークのモジュラリティは高く，フロー階 層と GRC は低かった．
さらに，宣言的知識の知識間関係ネットワークと手続き的知識の知識間関係ネッ トワークにおけるモジュラリティ，フロー階層，GRC それぞれについて，t 検定 を実施し統計的に有意な差があるかを検証した．モジュラリティにおける p 値は 0.00106 で，フロー階層における p 値は 0.0482 で，GRC における p 値は 0.0470 で あった．したがって，いずれの指標においても有意水準 0.05 で有意な差が認めら

72

第 5 章 実験

73

れた．このことは知識獲得における知識構造について，宣言的知識のモジュール 性が手続き的知識のモジュール性より統計的に有意に高く，逆に，手続き的知識 の階層性が宣言的知識の階層性より統計的に有意に高いことを示している．
以上，実験について述べた．次章では，考察について述べる．

73

第6章 考察
本章では，実験結果を踏まえた考察を述べる．
6.1 データセットと知識構造
データセットと知識構造について考察する．データセットの作成に利用する問 題回答ログデータの要件を述べる際，科目が同じでも難易度が高いと，目的志向 の知識である手続き的知識の有無が問題回答の正誤に影響を与える可能性が高く， 知識構造もより階層的になる可能性が高いことを説明し，データの要件として，問 題群が難しすぎないことを挙げた．また，それを満足するデータの収集対象とし て勉強サプリを選択し，手続き的知識の獲得を主目的とする 6 講座（小学 4 年算 数，小学 5 年算数，小学 6 年算数，中学 1 年数学，中学 2 年数学，中学 3 年数学） から 6 データセットを作成した．
しかし，この中でも，特に，小学 4 年算数のデータセットは難しすぎないとい う点では十分だったかもしれないが，難易度が低すぎた，あるいは内容があまり 適切でなかったかもしれない．小学 4 年算数のデータセットから構築したネット ワークは，モジュラリティについては宣言的知識についての全てのネットワーク のものより小さかったものの，その中で最も小さかった小学 4 年社会のものと大 きな差があるというわけではなく，フロー階層および GRC については，宣言的知 識についての全てのネットワークのものよりも小さい組み合わせが複数存在する． つまり，モジュール性が大きく階層性が小さかったということである．
このことは，小学 4 年算数が手続き的知識の学習を主目的としていないという こと指しているのではないと考える．小学 4 年算数の問題例を示した図 4.7 は四則 演算の問題であり，これは数字という宣言的知識への手続きを用いて達成される ものである．小学 4 年算数の知識間関係ネットワークを示した図 5.6 ではいくつか
74

第 6 章 考察

75

のクラスタが抽出されている．これらのクラスタ内ではある程度の階層性が存在 するが，一方で，クラスタ間については，その内容が強く関連しているというわ けではなく，したがって，ネットワーク全体としてはモジュール性が高く，また， 階層性が低くなってしまっているのだと推察する．

6.2 知識構造分析手法の他 MOOCs への適用可能性
知識構造の分析手法の他 MOOCs への適用可能性について考察する．本研究で 用いた知識構造の分析手法は 1) データセット作成，2) 知識間関係行列の算出，3) ネットワーク構築および指標による構造評価の 3 つの要素から構成されていた． MOOCs で収集される問題回答ログデータは大規模であると考えられ，また，ネッ トワーク構築および指標による構造評価は Deep Knowledge Tracing（以下，DKT） で知識間関係を抽出できるかに依存する．したがって，知識構造の分析手法の他 MOOCs への適用可能性は，DKT の適用可能性に依存すると考えられる．
そこで，DKT の予測性能について考察する．[Piech et al., 2015] では，数学に 関するデータセットにおいてのみ，DKT の有効性が検証されていた．本研究の実 験では，算数や数学に関するデータセットと地理や歴史に関するデータセットは， Bayesian Knowledge Tracing からの精度向上という点では大きな差はなかった．し たがって，DKT の適用可能性は科目に依らないのかもしれない．
また，[Piech et al., 2015] では，モデルへの入力次元には問題に割り当てられた タグが利用されており，DKT の有効性はタグを用いた場合のみ，検証されていた． 本研究の実験では，モデルへの入力次元にはタグを利用せず，個々の問題を利用 し特に算数や数学に関する 6 データセットのうち 5 データセットで AUC が 0.8 を 超えていた．したがって，DKT の適用可能性には必ずしもタグが必要というわけ ではないのかもしれない．
一方で，難易度という点では，例えば，高等教育水準の学習内容を理解するた めには，初等教育や中等教育水準の学習内容をあらかじめ理解している必要があ るため，モデルの訓練と予測の両方において，初等教育や中等教育水準の内容を 理解している人と理解していない人を同様のデータとして扱うことは難しい可能 性がある．つまり，知識獲得の予測は，当該講座の内容の学習に際してあらかじ
75

第 6 章 考察

76

め必要とされる知識を獲得している学習者に対して適用されるべきであり，そう でない学習者がいる割合が相対的に大きいと推察される高等教育水準の内容を扱 う MOOCs においては，DKT の適用は限定的である可能性もある．
以上，考察を踏まえると，適用できるとする側面と，適用が限定的であるとい う側面があり，DKT の適用可能性については検証実験を行う必要があると考えら れる．
本論文では，知識獲得における宣言的知識と手続き的知識の構造の違いを分析 するために，初等中等教育向けの MOOCs を用いた．もし，Coursera をはじめと する大学講座を扱う多くの MOOCs の問題回答ログデータに対しても適用できる ということであれば，大学講座を扱う多くの MOOCs では非常に多様な科目が提 供されているため，それらの講座で扱われる知識の構造を分析することで，知識 獲得と内容や教材についてより詳細に分析できるかもしれない．

6.3 今後の展望
本研究の今後の展望について大きく 2 つの方針を述べる．1 つは対象データの 多様化，結合，長期化についてであり，1 つは知識間関係の抽出に用いた Deep Knowledge Tracing の拡張についてである．
6.3.1 対象データの多様化，結合，長期化
まず，対象データの多様化について述べる．対象データの多様化は多様な科目 や難易度についても学習者の知識獲得を予測しその知識構造を分析するという研 究方針である．本研究では算数，数学，地理，歴史の知識構造について分析した． 科目という点では，論理的思考，外国語，プログラミング等多くの科目について は知識構造を分析しておらず，難易度という点では，大学水準のものについては 知識構造を分析していない．知識獲得に関する知見は従来より指導や学習の設計 に活用されており，他の多様なデータに対してもその知識構造を明らかにするこ とは重要であると考える．

76

第 6 章 考察

77

次に，対象データの結合について述べる．対象データの結合は，異なる科目間 で同じ学習者の知識獲得を予測しその知識構造を分析するという研究方針である． 本研究では算数，数学，地理，歴史の知識構造についてそれぞれ独立に用いて分 析した．例えば，数学や歴史は内容の関連性は低いだろうと考えるが，数学と理 科は知識獲得という点で密接に関係していると考える．しかし，そうした科目間 の知識構造を定量的に分析した研究もまだない．対象データを結合した研究は科 目間の知識構造を定量的に分析することで，科目内の指導や学習の設計だけでな く科目間も考慮した設計に貢献すると考えられる．
最後に，対象データの長期化について述べる．対象データの長期化は，同じ学 習者の知識獲得を長期間に渡って測定し，同じ科目で，あるいは，科目をまたい で，知識獲得を予測し，その知識構造を分析するという研究方針である．本研究 では，データセットの対象期間は 1 年弱であった．しかし，学習者の知識獲得は既 に獲得している知識に依存しており，できるだけ長い期間のデータを利用する方 が，よりよく知識獲得を予測できる可能性が高い．つまり，より知識構造を明瞭 に抽出でき，長期的な視点で科目を横断した指導や学習の設計に活用できる可能 性が高い．

6.3.2 知識間関係抽出手法の拡張
知識間関係の抽出に用いた Deep Knowledge Tracing の拡張について 2 つ述べる． 1 つ目は，モデルの学習の際に長期的なログがある学習者の優先度をあげるとい う研究である．知識獲得は既に獲得している知識に依存しており，したがって，既 に獲得している知識について多くわかっていた方が予測しやすい．つまり，長期的 なログのある学習者を優先的に考慮した方が抽出される知識構造はいいものにな る可能性がある．こうした研究に関連するものとして，カリキュラム学習という ものがある．カリキュラム学習は 2009 年に Bengio らが提案した研究領域 [Bengio et al., 2009] である．カリキュラム学習はモデルの学習に際して，学習に用いるデー タをカリキュラムに基づいて制御するという学習方法である．例えば，手書き文 字認識では文字列が短い画像から学習させていき徐々に長い文字列の画像を含め て学習させることで，最終的に得られるモデルの性能が向上することが報告され
77

第 6 章 考察

78

ている [Louradour and Kermorvant, 2014]．こうした手法でよりよい予測モデル を構築することで，抽出される知識構造も知識間関係をよく表現したものになる 可能性がある．
2 つ目は，予測の過程でタグを生成し知識の構造化に利用するという研究であ る．データセットによっては同じ知識を複数の別の問題で繰り返し学習させると いう学習支援システムから収集されたものもあると考えられる．例えば，数学の 演習問題 2x + 1 = 0 と 3x − 4 = 0，−3x + 5 = 0 はほとんど同じ知識を問う問題で あると考えられる．こうした場合，抽出した知識間関係ネットワークは必ずしも， ノード数という点で解釈しやすいものであるとは限らず，また，同じ知識を扱う 問題群は相互に影響を与え合うため，環状構造を構築しやすい．したがって，そ うしたネットワークでは，階層性の評価は難しくなる可能性があると考えられる． こうした問題を解決するためには，ほとんど同じ内容を扱っている問題にタグを 割り当て，タグを 1 つのノードとして扱うようなネットワークを構築する必要が あり，また，そのためには，抽出する知識間関係行列の各行，各列がタグを表現 するようになっている必要があると考えられる．
こうした抽象的な関係を捉えるということに深層学習における埋め込みに関す る技法が利用できる可能性がある．従来専門家がよいとしてきたタグと予測する 過程で深層学習モデルが獲得するタグを比較することで，知識の粒度について新 たな知見を得ることができるかもしれない．また，タグを自動で抽出できるよう になれば，これまで専門家が手で行っていた問題へのタグの割り当てとタグ間の 関係の定義の 2 つの難しいタスクを深層学習の手法によりできるようになるとい うことであり，学習科学の研究はこれまでにないほど進展するだろう．
以上，考察について述べた．次章では，結論を述べる．

78

第7章 結論
本論文では，心理学で議論されていた宣言的知識と手続き的知識の獲得におけ る知識構造の違いを定量的に分析し，知識獲得における宣言的知識の知識構造は 手続き的知識の知識構造と比べてよりモジュール性が高く，逆に，手続き的知識 の知識構造は宣言的知識の知識構造と比べてより階層性が高いことを検証した．
検証過程で得られた知見に基づいて，本研究で用いた知識構造の分析手法の他 MOOCs への適用可能性について議論し，講座の科目や問題へのタグの有無に依 らず知識構造を分析できる可能性があること，および，特に，大学水準の難易度 を扱う MOOCs については検証実験を行う必要があることを指摘した．
また，本研究の拡張として，適用対象の拡張という点で対象データの多様化，結 合，長期化の 3 つの拡張を述べた．また，知識間関係抽出法である Deep Knowledge Tracing の拡張という点で，カリキュラム学習による拡張，および，スキルタグ自 動抽出による拡張の 2 つについて述べた．
本研究は MOOCs の登場，ネットワーク分析の発展，深層学習の躍進等，ここ 数年の幅広い領域のさまざまな成果によって，初めてその実施が可能になったも のである．本研究が，人間の学習や知能の解明の一助になると信じている.
79

参考文献
[Abelson, 2008] Abelson, H. (2008). The creation of opencourseware at mit. Journal of Science Education and Technology, 17(2):164–174.
[Anderson, 1982] Anderson, J. R. (1982). Acquisition of cognitive skill. Psychological review, 89(4):369.
[Anderson, 1990] Anderson, J. R. (1990). The adaptive character of thought. Psychology Press.
[Anderson, 1993] Anderson, J. R. (1993). Problem solving and learning. American Psychologist, 48(1):35.
[Bahdanau et al., 2015] Bahdanau, D., Chorowski, J., Serdyuk, D., Brakel, P., and Bengio, Y. (2015). End-to-end attention-based large vocabulary speech recognition. arXiv preprint arXiv:1508.04395.
[Bastian et al., 2009] Bastian, M., Heymann, S., Jacomy, M., et al. (2009). Gephi: an open source software for exploring and manipulating networks. ICWSM, 8:361–362.
[Bastien et al., 2012] Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., and Bengio, Y. (2012). Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.
[Bengio et al., 2009] Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In Proceedings of the 26th annual international conference on machine learning, pages 41–48. ACM.
80

参考文献

81

[Bengio et al., 1994] Bengio, Y., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient descent is diﬃcult. Neural Networks, IEEE Transactions on, 5(2):157–166.
[Bergstra and Bengio, 2012] Bergstra, J. and Bengio, Y. (2012). Random search for hyper-parameter optimization. The Journal of Machine Learning Research, 13(1):281–305.
[Bergstra et al., 2010] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio, Y. (2010). Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientiﬁc Computing Conference (SciPy). Oral Presentation.
[Biswas et al., 2015] Biswas, S., Chadda, E., and Ahmad, F. (2015). Sentiment analysis with gated recurrent units. Advances in Computer Science and Information Technology.
[Block et al., 1971] Block, J. H., Airasian, P. W., Bloom, B. S., and Carroll, J. B. (1971). Mastery learning: Theory and practice. Holt, Rinehart and Winston New York.
[Bloom, 1968] Bloom, B. S. (1968). Learning for mastery. instruction and curriculum. regional education laboratory for the carolinas and virginia, topical papers and reprints, number 1. Evaluation comment, 1(2):n2.
[Bock and O DEA, 2013] Bock, M. and O DEA, V. (2013). Virtual educators critique the value of moocs for k-12. Education Week, 32(20):10.
[Buzydlowski et al., 2002] Buzydlowski, J. W., White, H. D., and Lin, X. (2002). Term co-occurrence analysis as an interface for digital libraries. In Visual interfaces to digital libraries, pages 133–144. Springer.
[Cauley, 1986] Cauley, K. M. (1986). Studying knowledge acquisition: Distinctions among procedural, conceptual and logical knowledge. the Annual Meeting of the

81

参考文献

82

American Educational Research Association (67th, San Francisco, CA, April 16-20, 1986).
[Chen et al., 2008] Chen, N.-S., Wei, C.-W., Chen, H.-J., et al. (2008). Mining elearning domain concept map from academic articles. Computers & Education, 50(3):1009–1021.
[Cho et al., 2014] Cho, K., Van Merri¨enboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., and Bengio, Y. (2014). Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.
[Choi et al., 2015] Choi, E., Bahadori, M. T., and Sun, J. (2015). Doctor ai: Predicting clinical events via recurrent neural networks. arXiv preprint arXiv:1511.05942.
[Chung et al., 2014] Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555.
[Chung et al., 2015] Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2015). Gated feedback recurrent neural networks. arXiv preprint arXiv:1502.02367.
[Clevert et al., 2015] Clevert, D.-A., Unterthiner, T., and Hochreiter, S. (2015). Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289.
[Cohen and Hyman, 1979] Cohen, S. A. and Hyman, J. S. (1979). Learning for mastery: Ten conclusions after 15 years and 3,000 schools. Educational Leadership, 37(2):104–9.
[Coleman and Coleman, 1994] Coleman, J. S. and Coleman, J. S. (1994). Foundations of social theory. Harvard university press.

82

参考文献

83

[Corbett and Anderson, 1994] Corbett, A. T. and Anderson, J. R. (1994). Knowledge tracing: Modeling the acquisition of procedural knowledge. User modeling and user-adapted interaction, 4(4):253–278.
[Daniel, 2012] Daniel, J. (2012). Making sense of moocs: Musings in a maze of myth, paradox and possibility. Journal of interactive Media in education, 2012(3):Art–18.
[De Jong and Ferguson-Hessler, 1996] De Jong, T. and Ferguson-Hessler, M. G. (1996). Types and qualities of knowledge. Educational psychologist, 31(2):105– 113.
[Dong et al., 2015] Dong, D., Wu, H., He, W., Yu, D., and Wang, H. (2015). Multi-task learning for multiple language translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. ACL.
[Dong et al., 2012] Dong, Y., Tang, J., Wu, S., Tian, J., Chawla, N. V., Rao, J., and Cao, H. (2012). Link prediction and recommendation across heterogeneous social networks. In Data Mining (ICDM), 2012 IEEE 12th International Conference on, pages 181–190. IEEE.
[FALAKMASIR et al., 2015] FALAKMASIR, M., Yudelson, M., Ritter, S., and Koedinger, K. (2015). Spectral bayesian knowledge tracing. In Proceedings of the 8th International Conference on Educational Data Mining., OC Santos, JG Boticario, C. Romero, M. Pechenizkiy, A. Merceron, P. Mitros, JM Luna, C. Mihaescu, P. Moreno, A. Hershkovitz, S. Ventura, and M. Desmarais, Eds. Madrid, Spain, pages 360–364.
[Gersten and Chard, 1999] Gersten, R. and Chard, D. (1999). Number sense rethinking arithmetic instruction for students with mathematical disabilities. The Journal of special education, 33(1):18–28.

83

参考文献

84

[Glorot and Bengio, 2010] Glorot, X. and Bengio, Y. (2010). Understanding the diﬃculty of training deep feedforward neural networks. In International conference on artiﬁcial intelligence and statistics, pages 249–256.
[Graves and Schmidhuber, 2009] Graves, A. and Schmidhuber, J. (2009). Oﬄine handwriting recognition with multidimensional recurrent neural networks. In Advances in Neural Information Processing Systems, pages 545–552.
[Hagberg et al., 2008] Hagberg, A. A., Schult, D. A., and Swart, P. J. (2008). Exploring network structure, dynamics, and function using NetworkX. In Proceedings of the 7th Python in Science Conference (SciPy2008), pages 11–15, Pasadena, CA USA.
[Hidasi et al., 2015] Hidasi, B., Karatzoglou, A., Baltrunas, L., and Tikk, D. (2015). Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939.
[Hiebert, 2013] Hiebert, J. (2013). Conceptual and procedural knowledge: The case of mathematics. Routledge.
[Hinton et al., 2012] Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A.-r., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T. N., et al. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Processing Magazine, IEEE, 29(6):82–97.
[Hochreiter, 1998] Hochreiter, S. (1998). The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107–116.
[Hochreiter and Schmidhuber, 1997] Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8):1735–1780.
[Jacomy, 2009] Jacomy, M. (2009). Force-atlas graph layout algorithm. URL: http://gephi. org/2011/forceatlas2-the-new-version-of-our-home-brew-layout.

84

参考文献

85

[Jordan, 2013] Jordan, K. (2013). Mooc completion rates: The data. Availabe at: http://www. katyjordan. com/MOOCproject. html.[Accessed: 27/08/2014].
[Karpathy et al., 2015] Karpathy, A., Johnson, J., and Li, F.-F. (2015). Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078.
[Keller, 1968] Keller, F. S. (1968). Good-bye, teacher... Journal of applied behavior analysis, 1(1):79.
[Kingma and Ba, 2014] Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
[Krueger and Memisevic, 2015] Krueger, D. and Memisevic, R. (2015). Regularizing rnns by stabilizing activations. arXiv preprint arXiv:1511.08400.
[Kushner and Yin, 2003] Kushner, H. J. and Yin, G. (2003). Stochastic approximation and recursive algorithms and applications, volume 35. Springer Science & Business Media.
[Larochelle et al., 2007] Larochelle, H., Erhan, D., Courville, A., Bergstra, J., and Bengio, Y. (2007). An empirical evaluation of deep architectures on problems with many factors of variation. In Proceedings of the 24th international conference on Machine learning, pages 473–480. ACM.
[Le et al., 2015] Le, Q. V., Jaitly, N., and Hinton, G. E. (2015). A simple way to initialize recurrent networks of rectiﬁed linear units. arXiv preprint arXiv:1504.00941.
[LeCun et al., 1998] LeCun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324.
[Lipton et al., 2015] Lipton, Z. C., Kale, D. C., Elkan, C., and Wetzell, R. (2015). Learning to diagnose with lstm recurrent neural networks. arXiv preprint arXiv:1511.03677.

85

参考文献

86

[Liyanagunawardena et al., 2013] Liyanagunawardena, T., Williams, S., and Adams, A. (2013). The impact and reach of moocs: A developing countries perspective. eLearning Papers, (33).
[Louradour and Kermorvant, 2014] Louradour, J. and Kermorvant, C. (2014). Curriculum learning for handwritten text line recognition. In Document Analysis Systems (DAS), 2014 11th IAPR International Workshop on, pages 56–60. IEEE.
[Luo and Magee, 2011] Luo, J. and Magee, C. L. (2011). Detecting evolving patterns of self-organizing networks by ﬂow hierarchy measurement. Complexity, 16(6):53–61.
[MacHardy and Pardos, 2015] MacHardy, Z. and Pardos, Z. A. (2015). Toward the evaluation of educational videos using bayesian knowledge tracing and big data. In Proceedings of the Second (2015) ACM Conference on Learning@ Scale, pages 347–350. ACM.
[McAuley et al., 2010] McAuley, A., Stewart, B., Siemens, G., and Cormier, D. (2010). The mooc model for digital practice.
[McCormick, 1997] McCormick, R. (1997). Conceptual and procedural knowledge. International journal of technology and design education, 7(1-2):141–159.
[Mikolov, 2012] Mikolov, T. (2012). Statistical language models based on neural networks. Presentation at Google, Mountain View, 2nd April.
[Mones et al., 2012] Mones, E., Vicsek, L., and Vicsek, T. (2012). Hierarchy measure for complex networks. PloS one, 7(3):e33799.
[Nair and Hinton, 2010] Nair, V. and Hinton, G. E. (2010). Rectiﬁed linear units improve restricted boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 807–814.
[Newman, 2006] Newman, M. E. (2006). Modularity and community structure in networks. Proceedings of the National Academy of Sciences, 103(23):8577–8582.
86

参考文献

87

[Page et al., 1999] Page, L., Brin, S., Motwani, R., and Winograd, T. (1999). The pagerank citation ranking: bringing order to the web.
[Pappano, 2012] Pappano, L. (2012). The year of the mooc. The New York Times, 2(12):2012.
[Pascanu et al., 2013] Pascanu, R., Mikolov, T., and Bengio, Y. (2013). On the diﬃculty of training recurrent neural networks. arXiv preprint arXiv:1211.5063.
[Pavlik Jr et al., 2009] Pavlik Jr, P. I., Cen, H., and Koedinger, K. R. (2009). Performance factors analysis–a new alternative to knowledge tracing. Online Submission.
[Pezeshki, 2015] Pezeshki, M. (2015). Sequence modeling using gated recurrent neural networks. arXiv preprint arXiv:1501.00299.
[Piech et al., 2015] Piech, C., Bassen, J., Huang, J., Ganguli, S., Sahami, M., Guibas, L. J., and Sohl-Dickstein, J. (2015). Deep knowledge tracing. In Advances in Neural Information Processing Systems, pages 505–513.
[Putnam, 1993] Putnam, R. D. (1993). The prosperous community: social capital and public life. The american prospect, (13).
[Resnick, 1977] Resnick, L. B. (1977). Assuming that everyone can learn everything, will some learn less?
[Rittle-Johnson and Alibali, 1999] Rittle-Johnson, B. and Alibali, M. W. (1999). Conceptual and procedural knowledge of mathematics: Does one lead to the other? Journal of educational psychology, 91(1):175.
[Rivard, 2013] Rivard, R. (2013). Measuring the mooc dropout rate. Inside Higher Ed, 8:2013.
[Robbins and Monro, 1951] Robbins, H. and Monro, S. (1951). A stochastic approximation method. The annals of mathematical statistics, pages 400–407.

87

参考文献

88

[Ryle, 1945] Ryle, G. (1945). Knowing how and knowing that: The presidential address. In Proceedings of the Aristotelian Society, pages 1–16. JSTOR.
[Sak et al., 2015] Sak, H., Senior, A., Rao, K., and Beaufays, F. (2015). Fast and accurate recurrent neural network acoustic models for speech recognition. arXiv preprint arXiv:1507.06947.
[Schein et al., 2002] Schein, A. I., Popescul, A., Ungar, L. H., and Pennock, D. M. (2002). Methods and metrics for cold-start recommendations. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, pages 253–260. ACM.
[Schroﬀ et al., 2015] Schroﬀ, F., Kalenichenko, D., and Philbin, J. (2015). Facenet: A uniﬁed embedding for face recognition and clustering. arXiv preprint arXiv:1503.03832.
[Siemens, 2013] Siemens, G. (2013). Massive open online courses: Innovation in education. Open educational resources: Innovation, research and practice, 5.
[Srivastava et al., 2014] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overﬁtting. The Journal of Machine Learning Research, 15(1):1929– 1958.
[Sun et al., 2011] Sun, Y., Barber, R., Gupta, M., Aggarwal, C. C., and Han, J. (2011). Co-author relationship prediction in heterogeneous bibliographic networks. In Advances in Social Networks Analysis and Mining (ASONAM), 2011 International Conference on, pages 121–128. IEEE.
[Sutskever et al., 2014] Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104–3112.

88

参考文献

89

[Szegedy et al., 2014] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. (2014). Going deeper with convolutions. arXiv preprint arXiv:1409.4842.
[Ten Berge and Van Hezewijk, 1999] Ten Berge, T. and Van Hezewijk, R. (1999). Procedural and declarative knowledge an evolutionary perspective. Theory & Psychology, 9(5):605–624.
[Trucano et al., 2013] Trucano, M., Kendrick, C., and Gashurov, I. (2013). More about moocs and developing countries.
[Unger, 1968] Unger, P. (1968). An analysis of factual knowledge. The Journal of Philosophy, pages 157–170.
[Vinyals et al., 2014] Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2014). Show and tell: A neural image caption generator. arXiv preprint arXiv:1411.4555.
[Werbos, 1990] Werbos, P. J. (1990). Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10):1550–1560.
[Williams and Zipser, 1989] Williams, R. J. and Zipser, D. (1989). A learning algorithm for continually running fully recurrent neural networks. Neural computation, 1(2):270–280.
[Xu et al., 2015] Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., and Bengio, Y. (2015). Show, attend and tell: Neural image caption generation with visual attention. arXiv preprint arXiv:1502.03044.
[Yin et al., 2015] Yin, J., Jiang, X., Lu, Z., Shang, L., Li, H., and Li, X. (2015). Neural generative question answering. arXiv preprint arXiv:1512.01337.
[Yuan et al., 2013] Yuan, L., Powell, S., and CETIS, J. (2013). Moocs and open education: Implications for higher education.

89

参考文献

90

[Yudelson et al., 2013] Yudelson, M. V., Koedinger, K. R., and Gordon, G. J. (2013). Individualized bayesian knowledge tracing models. In Artiﬁcial Intelligence in Education, pages 171–180. Springer.
[Zaremba, 2015] Zaremba, W. (2015). An empirical exploration of recurrent network architectures.
[Zeiler, 2012] Zeiler, M. D. (2012). Adadelta: An adaptive learning rate method. arXiv preprint arXiv:1212.5701.
[Zeiler and Fergus, 2014] Zeiler, M. D. and Fergus, R. (2014). Visualizing and understanding convolutional networks. In Computer Vision–ECCV 2014, pages 818–833. Springer.
[文部科学省, 2011] 文部科学省 (2011). 現行学習指導要領・生きる力：学習指導要領 とは何か？ http://www.mext.go.jp/a_menu/shotou/new-cs/idea/1304372. htm.

90

謝辞
本研究の遂行や本論文の執筆にあたり，非常に多くの方からご指導，ご支援を いただきました．心より御礼申し上げます．
指導教官である 松尾豊特任准教授 には，研究構想の相談や論文の書き方，本論 文の論理構成について，貴重なご指導をいただきました．特に，本論文執筆途中 に頂いた厳しいフィードバックは，本論文の完成に不可欠なものでした．ここに， 深く謝意を表します．
深層学習の実装に関する多くの相談を応じて下さり，また，分析サーバや GPU 解析環境の用意等，物理的な研究環境の構築に多大なご協力を下さった研究室の 教官である 中山浩太郎先生 に，深く感謝致します．
共同研究プロジェクトという形式で本研究の遂行に必要不可欠であった貴重な データをご提供して下さったリクルートマーケティングパートナーズ (株) の社長 の 山口文洋様 には深く感謝申し上げます．特に，共同研究プロジェクトの進行に 際して，さまざまな要望・相談に対応して下さったリクルートマーケティングパー トナーズ (株) の 萩原静厳様 に，深く感謝致します．
経営共創基盤の 川上登福様 と 浜田貴之様 からは，3 年前の共同研究プロジェ クトの発足から現在に至るまで，プロジェクト進行に際してあらゆる観点でご協 力およびご配慮いただきました．深く感謝致します．
松尾研究室や GCI の皆様には，多大なご協力，ご支援いただきました．秘書の 中野佐恵子さん，永本登代子さん，浪岡亮子さんは，日頃から研究室の環境を整 えて下さり，研究生活を支えてくださいました．松尾研究室博士課程の 岩澤有祐 さん，野中尚輝さん，鈴木雅大さん，金子貴輝さん，Edison Marrese Taylor さん，
91

Pablo Loyola さんは，人工知能という競争が激しい過酷な研究領域において，共 に切磋琢磨してくださいました．特に，研究アイディアの相談に乗ってくださり， また，生成モデルや統計検定等，機械学習の理論方面の理解を手助けしてくださ り，研究遂行上重要な技術的な相談に何度も応じてくださった鈴木雅大さんには， 深く感謝いたします．学部生の味曽野雅史君，塩谷碩彬君は，膨大で度々更新さ れるデータの整備を通して，本研究の下支えをしてくださいました．また，河野 慎さん，冨山翔司君，金子貴輝さんは，しばしば飲み会を通じて息抜きさせてく ださいました．ここに，松尾研究室や GCI の皆様へ謝意を表します．
最後に，両親と兄弟に深く深く感謝を申し上げます．多忙を理由に実家に帰ら ず連絡もあまりしない私をたまに帰った時にはいつも通り温かく迎えてくれる家 族のおかげで，これまでこうして研究生活を続けられているのだと深く感じてお ります．また，今後もこれまでと変わらず見守ってくれるであろう家族の存在を 心の支えとして，研究を続けていきたいと考えています．改めて，家族に深く感 謝申し上げます．
東京大学大学院工学系研究科 技術経営戦略学専攻
松尾研究室 修士二年 那須野薫
平成 28 年 3 月
92

発表文献
学会誌論文 • 那須野薫，奥山晶二郎，中西鏡子，松尾豊．(2015)．Twitter における候補者 の選挙地盤に着目した国政選挙の当選者予測．情報処理学会論文誌，56(10)， 2044-2053．
学会発表 • 那須野薫，萩原静厳，井上綾香，松尾豊．(2015)．大規模オンライン講座に おける自己適応学習者に着目した学習項目の理解度予測．人工知能学会全国 大会論文集，29，1-4． • 後藤拓矢，那須野薫，萩原静厳，松尾豊．(2015)．受験向け動画サービスに おける合否結果を加味した教材の推薦手法の提案．人工知能学会全国大会論 文集，29，1-3． • 那須野薫，松尾豊．(2014)．Twitter における候補者の情報拡散に着目した 国政選挙当選者予測．第 28 回人工知能学会全国大会論文集． • 那須野薫，松尾豊．(2013)．2013 年参議院議員選挙における Twitter を用い た当選者予測 (マイクロブログ，第 5 回集合知シンポジウム)．電子情報通信 学会技術研究報告．NLC，言語理解とコミュニケーション，113(338)，25-28． • 那須野薫，上野山勝也，松尾豊．(2013)．次世代プログラミング学習サイト 構築の試み．人工知能学会全国大会論文集，27，1-3． • 榊剛史，那須野薫，柳原正，古賀光，加藤芳隆，那和一成，松尾豊．(2013)． ソーシャルメディアからの予告型の地域イベント及び参加状態の抽出手法の 提案．人工知能学会全国大会論文集，27，1-4．
93

