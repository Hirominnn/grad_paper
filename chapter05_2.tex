\chapter{実験}
\label{chap:result}
\fancyhf{}
\rhead{\thepage}
\lhead{第\ref{chap:result}章　実験}
\cfoot{\thepage}


本章では，実験について述べる．

まず，実験設定について述べ，
その後，実験結果について述べる．


\section{実験設定}

本研究の実験は，大きく以下の３つのブロックに分けられる．
\begin{enumerate}
	\item 知識分類学習モデルによる知識分類の学習
	\item 学習された知識分類の知識獲得予測の性能に関する検証
	\item 学習された知識分類の性質に関する比較分析
\end{enumerate}
以下では，順に，実験設定について述べる．


\subsection{知識分類学習モデルによる知識分類の学習}
\label{sec:section}
生徒の問題回答ログに対し，図\ref{fig:model}に表される知識分類学習モデルを適用し，回答正誤の予測性において最適な知識分類表現を抽出する．
知識タグ空間の次元数は，既存の知識タグの次元数と統一し，
「ASSISTments 2009-2010」では56，
「Bridge to Algebra 2006-2007」では193とした．
実際のモデルにおいては，正答ベクトルと誤答ベクトルを分けてユニットを作るため，
それぞれ２倍のユニット数で表現されている．

ハイパーパラメータについては，
%対象データが多いため学習コストの削減を狙いRNNの部分にはGRNNを用いる．
学習率の初期値を$200$，
モーメントを$0.98$，
1エポックごとに，
減衰率$0.99$として学習率を最小学習率$10$まで減衰させる．
また，勾配のノルムの最大値を$0.00001$として\cite{pascanu2013difficulty}に従い勾配に制約を設けた．
dropoutは\cite{piech2015deep}と同様に${\bf y}_t$の方向にのみかけ，
dropout率は$0.5$とした．
隠れ層のユニット数は$400$として，
各重み行列の初期化は\cite{glorot2010understanding}にしたがった．
時系列方向の誤差逆伝搬は最長で$200$まで伝搬するように制約を設けた．

これらのハイパーパラメータは実験的に高い予測性能を発揮したため設定しており，
網羅的に探索したわけではない．
通常，深層学習の手法はハイパーパラメータの数が非常に大きく，また，
計算コストが大きいため大規模な探索は行えない．
Grid SearchやRandom Search\cite{bergstra2012random}といった探索手法が提案されているが，
専門家が手で調整した方が優れていることが報告されている\cite{larochelle2007empirical, bergstra2012random}．

最適化手法は，
式\ref{eq:prediction_entropy}で表される問題回答予測に関する誤差関数$L_p$と，
式\ref{eq:autoencoder_loss}で表される問題空間と知識タグ空間の最高性誤差を表す誤差関数$L_r$の和である
$L$(式\ref{eq:total_loss})を目的関数として最小化するものである．
学習時は\cite{piech2015deep}と同様にミニバッチごとに確率的勾配降下法で目的関数を最小化する．
評価指標はAUCスコアを採用する．

一般的な機械学習では，モデルの汎化性能を高めるために訓練データと検証データを分けるが，
２つのデータセットいずれにおいても，全ユーザの問題回答ログを訓練データとして，モデルを学習させた．
これは，分類を作成する時点において既知のデータから帰納的に最適な知識分類を作成するという本研究のテーマと，
未知のデータが追加される都度モデルを学習させ，知識分類を更新することが容易であるオンライン教育サービスのプラットフォームの環境を考慮し，
最適な問題設定としたものである．
なお，知識分類の汎用性に関する詳しい考察は第６章で述べる．
%２つのデータセットいずれにおいても，
%訓練：検証：テスト = 8：1：1となるようにユーザを分け，
%訓練ユーザのデータでモデルを構築し，
%検証ユーザのデータでハイパーパラメータを調整し， 
%検証ユーザのデータで精度が最も高かったモデルを
%テストユーザのデータに適用し当該モデルの最終的な精度とした．

実装には
Theanoを用いた\cite{bergstra+al:2010-scipy,Bastien-Theano-2012}．
Theanoは多次元行列を含む数学的表現の定義や計算，最適化を効率的に行えるPythonのライブラリで，
深層学習の研究ではよく利用される．


\subsection{学習された知識分類の知識獲得予測の性能に関する検証}

\ref{sec:section}で得られた問題空間から知識タグ空間への写像行列$P$を知識分類表現と見なしてDKTを行い，
既存の知識分類を用いた場合との精度の比較を行う．
また，本手法で抽出される知識分類と既存の知識分類の差分を明確にするため，
以下の方法で作成された知識分類を用いた場合とも比較を行う．
\begin{itemize}
\item DKTを用いず，一般的な事前学習のAutoencoderによって作成された知識分類 \label{c1}
\item DKTを用いるが，再構成誤差を目的関数に導入しない，一般的な埋め込み(Embedding)によって作成された知識分類 \label{c2}
\end{itemize}

まず，
各手法によって得られた写像行列を，以下の条件に基づいて離散化し，
DKTにおいて最も高い精度を発揮したものをその手法による精度の上界として採用する．
\begin{enumerate}
\item 各問題の写像ベクトルにおいて，値が上位$X$位以内のタグを１とする
\item 各問題の写像ベクトルにおいて，値が閾値$Y$以上のタグを１とする
\item 各問題の写像ベクトルにおいて，1でない要素を0にする
\end{enumerate}

ハイパーパラメータについては，
%対象データが多いため学習コストの削減を狙いRNNの部分にはGRNNを用いる．
学習率の初期値を$200$，
モーメントを$0.98$，
1エポックごとに，
減衰率$0.99$として学習率を最小学習率$10$まで減衰させる．
また，勾配のノルムの最大値を$0.00001$として\cite{pascanu2013difficulty}に従い勾配に制約を設けた．
dropoutは\cite{piech2015deep}と同様に${\bf y}_t$の方向にのみかけ，
dropout率は$0.5$とした．
隠れ層のユニット数は$400$として，
各重み行列の初期化は\cite{glorot2010understanding}にしたがった．
時系列方向の誤差逆伝搬は最長で$200$まで伝搬するように制約を設けた．

最適化手法は，
一般的なDKTと同じく，
式\ref{eq:prediction_entropy}で表される回答正誤予測に関する誤差関数$L_p$
を目的関数として最小化するものである．
学習時は\cite{piech2015deep}と同様にミニバッチごとに確率的勾配降下法で目的関数を最小化する．
評価指標はAUCスコアを採用する．

２つのデータセットいずれにおいても，
訓練：検証：テスト = 8：1：1となるようにユーザを分け，
訓練ユーザのデータでモデルを構築し，
検証ユーザのデータでハイパーパラメータを調整し， 
検証ユーザのデータで精度が最も高かったモデルを
テストユーザのデータに適用し当該モデルの最終的な精度とした．

実装にはTheanoを用いた．


\subsection{学習された知識分類の性質に関する比較分析}

\ref{sec:section}で抽出された知識分類を既存の知識分類を比較分析することで，
その性質を検証する．

まず，各知識タグが回答ログに出現する頻度の分布や，紐づく問題数の分布に着目し，
知識獲得予測の精度を向上させる要因を，データ構造の側面から分析する．
また，既存タグから成る知識間影響ネットワークに抽出タグを配置して可視化することで，
既存タグが抽出タグによってどのように再配置され，どのようなネットワーク構造となったのかを分析する．




以上，実験設定について述べた．



\section{実験結果}
実験結果について述べる．
まず，各手法によって作成された知識分類についての知識獲得予測における予測性能を比較し，
いずれのデータセットにおいても，
提案手法によって学習された知識分類表現を利用することで，
最も良い精度で予測が可能になっていることを定量的に確認する．

さらに，学習された知識分類を，既存の知識分類と比較することにより，
その性質を定性的に分析する．



\subsection{各知識分類の知識獲得予測における予測性能}

%\begin{table}[!htb]
\begin{table}[t]
\caption{各知識分類の知識獲得予測における予測性能}
\label{tab:result1}
\begin{center}
\scalebox{0.9}{
\centerline{
{
\begin{tabular}{c|rrrrrr}\hline
%\multirow{3}{*}{データセット}	&	\multicolumn{5}{c}{AUC}\\\cline{2-6}
% 							&	\multirow{2}{*}{既存タグ(marginal)} 	& \multirow{2}{*}{事前学習タグ} 	&	& \multicolumn{2}{c}{深層学習タグ}\\\cline{5-6}
%							&										& 								&	& Embedding 	& AutoEncoder \\\hline 			 
%ASSISTments 2009-2010  		&				0.72 (0.61) 			& 			0.67 				& 	& 0.67 			& {\bf 0.79}\\
%Bridge to Algebra 2006-2007 &				0.79 (0.70) 			& 			0.76			 	& 	& 0.?? 			& {\bf 0.??}\\
\multirow{3}{*}{データセット}	&	\multicolumn{5}{c}{AUC}\\\cline{2-6}
 							&	\multirow{2}{*}{既存タグ(marginal)} 	& \multirow{2}{*}{事前学習タグ} 	&	& \multicolumn{2}{c}{深層学習タグ}\\\cline{5-6}
							&										& 								&	& Embedding 		& AutoEncoder \\\hline 			 
ASSISTments 2009-2010  		&				0.72 (0.61) 			& 			0.67 (Y=0.70)		& 	& 0.69 (Y=0.70)		& {\bf 0.74} (Y=0.70)\\
Bridge to Algebra 2006-2007 &				0.79 (0.70) 			& 			0.?? (Y=0.80)		& 	& 0.74 (Y=0.80)		& {\bf 0.77} (Y=0.80)\\%100
Bridge to Algebra 2006-2007 &				0.81 (0.72) 			& 			0.?? (Y=0.70)		& 	& 0.?? (Y=0.80)		& {\bf 0.82} (Y=0.85)\\%200
\hline
\end{tabular}
}
}
}
\end{center}
\end{table}


ベースラインとなる既存の知識タグ(既存タグ)と，
知識獲得予測の文脈を考慮しない，一般的な事前学習のAutoencoderによって作成された知識タグ（事前学習タグ），
知識獲得予測の文脈を考慮し，提案手法の知識分類学習モデルによって作成された知識タグ（深層学習タグ）
をそれぞれDeep Knowledge Tracingに適用した結果を表\ref{tab:result1}に示す．
深層学習の「Embedding」と「Autoencoder」はそれぞれ誤差関数に再構成誤差を導入しない場合と導入した場合である．
深層学習タグのスコア横の括弧は，最も良い精度を記録した離散化におけるハイパーパラメータである．
marginalは各問題についてそれぞれ正解の周辺確率を予測結果とするものである．
\cite{piech2015deep}にも記載されていたため，本稿でも同様にベースラインの参考として記載した．
また，値が大きい箇所は太字で記載した．

いずれのデータセットにおいても，
提案手法である「深層学習タグ(Autoencoder)」が，最も高いAUCを記録した．
この結果より，提案手法によって作成された知識分類が，既存の知識分類よりも知識獲得の予測性において優れていることが示された．
%また，深層学習タグの中でも，
%データ数が比較的少ない「ASSISTments 2009-2010」では，Autoencoderのほうが精度が高く
%正則化項として再構成誤差が機能しており，
%逆にデータ数が比較的多い「Bridge to Algebra 2006-2007」では，Embeddingのほうが精度が高く，
%正則化項という制約がなくとも十分に学習が可能なことがわかる．
以下，このタグを「抽出タグ」とする．


\subsection{抽出タグと既存タグの関係の概観}
抽出タグと既存タグの共起関係を概観する．
まず，抽出タグの紐づく問題を媒介として作成した抽出タグと既存タグの共起行列に対し，
TF-IDF法を適用して各抽出タグの特徴を強調し，抽出タグと既存タグの関係性を表す行列(以下，タグ関係行列)を作成した，
このタグ関係行列に基づき，各抽出タグにおいて値が上位３位以内の既存タグを選択し，図\ref{}にまとめた．
括弧内の数字はTF-IDF値であり，この値が高いほど特徴的な既存タグであることを表す．

また，既存タグをノードとする知識間影響ネットワーク（以下，既存タグネットワーク）を，既存のDKTで用いられた手法に基づいて作成し，
%既存タグと抽出タグの共起行列からTF-IDF値を求めて作成した行列を元にノードとエッジを追加したネットワーク図を図\ref{}に示す．
タグ関係行列を元に抽出タグのノードを追加したネットワーク図の概形を図\ref{}に示す．
ここで，既存タグネットワークは，
各既存タグの回答ログにおける出現回数に比例してノードのサイズを設定し，
平均回答順序が早いものほど青く，遅いものほど赤く色を設定し，
各既存タグへの影響度が大きい上位３つの既存タグからエッジを引いている．
また，追加される抽出タグは緑色のノードで表現し，
各抽出タグにとって関係性の強い上位３つの既存タグに対して緑色のエッジを引いている．

以上の処理の流れを図\ref{}にまとめた．


\subsection{抽出タグと既存タグの比較分析}
抽出タグを既存タグと比較することにより，
抽出タグの性質を定性的に確認する．

まず，知識獲得予測の精度を向上させる要因を，データの構造から分析した．
抽出タグと既存タグの各知識タグが回答ログに出現する頻度の分布の比較と，各分布の標準偏差を図\ref{}に表す．
図より，既存タグはタグごとの出現回数の分散が大きい一方で，
抽出タグは分散が小さく，特定の値の周辺に集中していることがわかる．
この分布の違いと予測精度の関係性についても，次章で考察する．

次に，
図\ref{??}のネットワークの局所的な特性に着目し，抽出タグと既存タグの性質が観測できる部分を示す．
まず，既存タグに注目し，各既存タグに抽出タグがどのように紐付いているかを観察すると，
%複数の抽出タグにおいて特徴的と判断されている既存タグが存在する(図\ref{??})一方，
%特定の抽出タグ内にまとめられ，他のタグでは特徴的でないと判断されている既存タグも存在する(図\ref{??})ことがわかる．
出現回数の多い既存タグ(大きいノード)は多くの抽出タグ(緑のノード)が紐付いている(図\ref{??})一方，
出現回数の少ない既存タグ(小さいノード)は特定の抽出タグのみ紐付き，多くは紐付いていない(図\ref{??})ことがわかる．
次に，抽出タグに注目し，各抽出タグがどのような既存タグに紐付いているかを観察すると，
内容的な関係性の強い複数の既存タグに紐付いている抽出タグが存在する{図\ref{??}}ことがわかる．	
このような既存タグと抽出タグの関係性から，どのような性質のタグが抽出されているといえるかは，次章で考察する．



\vvspace
以上，実験について述べた．
次章では，考察について述べる．



